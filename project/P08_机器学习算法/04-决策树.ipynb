{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "课程介绍\n",
    "\n",
    "1. 逻辑回归\n",
    "\n",
    "   分类\n",
    "\n",
    "2. 决策树\n",
    "\n",
    "   分类\n",
    "\n",
    "# 3.1 逻辑回归介绍\n",
    "\n",
    "分类\n",
    "\n",
    "逻辑回归（Logistic Regression）是机器学习中的**一种分类模型**\n",
    "\n",
    "## 1 逻辑回归的应用场景\n",
    "\n",
    "- 广告点击率     \n",
    "- 是否为垃圾邮件    目标  是 否\n",
    "- 是否患病   目标  是 否 \n",
    "- 金融诈骗\n",
    "- 虚假账号\n",
    "\n",
    "分类,  二个  解决二分类问题的利器\n",
    "\n",
    "是=1   正例\n",
    "\n",
    "否=0  负例\n",
    "\n",
    "## 2 逻辑回归的原理\n",
    "\n",
    "线性回归输出是我们逻辑回归输入\n",
    "\n",
    "### 2.2 激活函数\n",
    "\n",
    "sigmoid函数\n",
    "\n",
    "逻辑回归结果  [0,1]\n",
    "\n",
    "二分类   大于阈值  ==>正例\n",
    "\n",
    "​\t\t\t\t小于阈值 ==>负例\n",
    "\n",
    "阈值:  0.5(正常)  不一定 \n",
    "\n",
    "阈值?\n",
    "\n",
    "## 3 损失以及优化\n",
    "\n",
    "逻辑回归的损失，称之为**对数似然损失**\n",
    "\n",
    "优化目标\n",
    "\n",
    "当y=1  **hθ(x)** 越大越好\n",
    "\n",
    "当y=0 hθ(x)** 越小越好\n",
    "\n",
    "### 3.2 优化\n",
    "\n",
    "**提升原本属于1类别的概率，降低原本是0类别的概率。**\n",
    "\n",
    "# 3.2 逻辑回归api介绍\n",
    "\n",
    "sklearn.linear_model.LogisticRegression(solver='liblinear', penalty=‘l2’, C = 1.0)\n",
    "\n",
    "- 对于小数据集来说，“liblinear”是个不错的选择，而“sag”和'saga'对于大型数据集会更快。\n",
    "- 对于多类问题，只有'newton-cg'， 'sag'， 'saga'和'lbfgs'可以处理多项损失;“liblinear”仅限于“one-versus-rest”分类。\n",
    "\n",
    "- penalty：正则化的种类\n",
    "\n",
    "- C：正则化力度\n",
    "\n",
    "- \n",
    "\n",
    "- # 3.3 案例：癌症分类预测-良／恶性乳腺癌肿瘤预测\n",
    "\n",
    "目标: 良性和恶性   二分类   ---逻辑回归\n",
    "\n",
    "建模流程\n",
    "\n",
    "1. 获取数据\n",
    "\n",
    "2. 数据基本处理\n",
    "\n",
    "   2.1 缺失值处理\n",
    "\n",
    "   2.2 确定特征值和目标值\n",
    "\n",
    "   2.3 切割数据\n",
    "\n",
    "3. 特征工程\n",
    "\n",
    "   特征标准化\n",
    "\n",
    "4. 建立模型\n",
    "\n",
    "   逻辑回归\n",
    "\n",
    "5. 模型评估\n",
    "\n",
    "# 3.4 分类评估方法\n",
    "\n",
    " 混淆矩阵\n",
    "\n",
    "ROC AUC\n",
    "\n",
    "## 1.分类评估方法\n",
    "\n",
    "### 1.1 精确率与召回率\n",
    "\n",
    "#### 1.1.1 混淆矩阵\n",
    "\n",
    "准度度: (TP+TN)/(TP+TN +FN+FP)\n",
    "\n",
    "#### 精确率(Precision)\n",
    "\n",
    "TP/(TP+FP)   查的准\n",
    "\n",
    "召回率\n",
    "\n",
    "TP/(TP+FN)  查的全\n",
    "\n",
    "### 1.2 F1-score\n",
    "\n",
    "反映模型的稳健性\n",
    "\n",
    "值越大越好\n",
    "\n",
    "### 1.3 分类评估报告api\n",
    "\n",
    "- sklearn.metrics.classification_report(y_true, y_pred, labels=[], target_names=None )\n",
    "- - y_true：真实目标值\n",
    "  - y_pred：估计器预测目标值\n",
    "  - labels:指定类别对应的数字\n",
    "  - target_names：目标类别名称\n",
    "  - return：每个类别精确率与召回率\n",
    "\n",
    "## 2 ROC曲线与AUC指标\n",
    "\n",
    "选择不同的阈值计算Fpr和TPR值落在二维平面上 \n",
    "\n",
    "寻找最优阈值\n",
    "\n",
    "AUC指标 ROC曲线线下面积\n",
    "\n",
    "取值[0,1]一般[0.5,1]\n",
    "\n",
    "### 2.3 AUC指标\n",
    "\n",
    "取一对正负样本，正样本得分大于负样本得分的概率 (越大越好)\n",
    "\n",
    "AUC的范围在[0, 1]之间，并且越接近1越好，越接近0.5属于乱猜\n",
    "\n",
    "**AUC=1，完美分类器**\n",
    "\n",
    "**0.5<AUC<1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。**\n",
    "\n",
    "### 2.4 AUC计算API\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "- sklearn.metrics.roc_auc_score(y_true, y_score)\n",
    "\n",
    "  - 计算ROC曲线面积，即AUC值\n",
    "  - y_true：每个样本的真实类别，必须为0(反例),1(正例)标记\n",
    "  - y_score：预测得分，可以是正类的估计概率、置信值或者分类器方法的返回值\n",
    "\n",
    "  适合样本不均衡问题\n",
    "\n",
    "  # 3.5 ROC曲线的绘制\n",
    "\n",
    "  1. 计算逻辑回归结果\n",
    "  2. 逻辑回归结果从大到小\n",
    "  3. 设定不同阈值计算FPR和TPR\n",
    "  4. 将FPR和TPR落在二维平面上 \n",
    "\n",
    "  ROC靠近左上角 的阈值 就是最优阈值\n",
    "\n",
    "  适合不均衡样本\n",
    "\n",
    "  # 决策树算法\n",
    "\n",
    "  什么是决策树\n",
    "\n",
    "  1. 是一个树形结构\n",
    "  2. 每个非叶子节点代表的是一个判断\n",
    "  3. 叶子节点代表的是一个分类结果\n",
    "\n",
    "  if -else\n",
    "\n",
    "如何构建决策树\n",
    "\n",
    "​\t1 . 特征重要性前后\n",
    "\n",
    "2. 切割点\n",
    "\n",
    "# 4.2 决策树分类原理\n",
    "\n",
    "如何构树 \n",
    "\n",
    "  1 . 特征重要性前后\n",
    "\n",
    "2. 切割点\n",
    "\n",
    "## 1 熵(**信息熵**)\n",
    "\n",
    "物理学上，**熵 Entropy** 是“混乱”程度的量度。\n",
    "\n",
    "数据有序,熵小\n",
    "\n",
    "数据混乱 熵大\n",
    "\n",
    "构树:  让熵变小的过程\n",
    "\n",
    "![image-20191116111413485](/Users/zhangqingtao/Library/Application Support/typora-user-images/image-20191116111413485.png)\n",
    "\n",
    "\n",
    "\n",
    "## 2 决策树的划分依据\n",
    "\n",
    "1. ID3--信息增益\n",
    "2. C4.5 -信息增益率\n",
    "3. CART-基尼指数\n",
    "\n",
    "### 信息增益(ID3)(熵)\n",
    "\n",
    "**信息增益 = entroy(前) - entroy(后)**\n",
    "\n",
    "根据条件划分决策树 熵值差\n",
    "\n",
    "信息增益越大越好\n",
    "\n",
    "![image-20191116113557970](/Users/zhangqingtao/Library/Application Support/typora-user-images/image-20191116113557970.png)\n",
    "\n",
    "**信息增益(a=\"性别\")**\n",
    "\n",
    "0.0064\n",
    "\n",
    "**信息增益(a=\"活跃度\")**\n",
    "\n",
    "0.6776\n",
    "\n",
    "选择信息增益大的作为第一决策依据\n",
    "\n",
    "**活跃度**\n",
    "\n",
    "信息增益 :选择类别多的属性作为第一决策依据\n",
    "\n",
    "### 信息增益率(C4.5)(熵)\n",
    "\n",
    "对信息增益的改进\n",
    "\n",
    "改进:对类别多的属性有所偏好\n",
    "\n",
    "![image-20191116120747824](/Users/zhangqingtao/Library/Application Support/typora-user-images/image-20191116120747824.png)\n",
    "\n",
    "选择信息增益率大作为第一决策依据\n",
    "\n",
    "while(当前节点\"不纯\")---(熵不为0 )\n",
    "\n",
    "​\t1 .  计算熵值\n",
    "\n",
    "\t2. 计算条件熵\n",
    " \t3. 计算信息增益\n",
    " \t4. 计算信息增益率\n",
    " \t5. 选择增益率大的作为第一属性\n",
    "\n",
    "### 3.3 为什么使用C4.5要好\n",
    "\n",
    "**1.用信息增益率来选择属性**\n",
    "\n",
    "克服信息增益选择类别多的属性作为第一决策依据\n",
    "\n",
    "**2.采用了一种后剪枝方法**\n",
    "\n",
    "从低向上如果减枝效果比不减好--执行减\n",
    "\n",
    "**3.对于缺失值的处理**\n",
    "\n",
    "C4.5比ID3 要好\n",
    "\n",
    "### 基尼值和基尼指数(CART)\n",
    "\n",
    "二叉树\n",
    "\n",
    "**基尼值Gini（D）**\n",
    "\n",
    "越小越好\n",
    "\n",
    "数据的纯度:  值越小纯度越高\n",
    "\n",
    "![image-20191116144351396](/Users/zhangqingtao/Library/Application Support/typora-user-images/image-20191116144351396.png)\n",
    "\n",
    "**基尼指数Gini_index（D）**\n",
    "\n",
    "![image-20191116144512545](/Users/zhangqingtao/Library/Application Support/typora-user-images/image-20191116144512545.png)\n",
    "\n",
    "现在我们来总结一下CART的算法流程\n",
    "\n",
    "1. ```\n",
    "   while(当前节点不纯) ---基尼值不为0\n",
    "   1.遍历每个变量的每一种分割方式，找到最好的分割点----基尼指数值小\n",
    "   2.分割成两个节点N1和N2\n",
    "   每个节点足够“纯”为止\n",
    "   ```\n",
    "\n",
    "### 5.1 常见决策树的启发函数比较\n",
    "\n",
    "#### **5.1.1 ID3 算法**\n",
    "\n",
    "**存在的缺点**\n",
    "\n",
    "1. 选择类别多的属性作为第一决策依据\n",
    "2. 只能构建离散型(男,女....类别型)特征构建树\n",
    "\n",
    "#### **5.1.2 C4.5算法**\n",
    "\n",
    "(1) 用信息增益率来选择属性\n",
    "\n",
    " (2) 可以处理连续数值型属性(年收入)\n",
    "\n",
    "(3)采用了一种后剪枝方法\n",
    "\n",
    "(4)对于缺失值的处理\n",
    "\n",
    "**C4.5算法的优缺点**\n",
    "\n",
    "优点:\n",
    "\n",
    " 易于理解，准确率较高。\n",
    "\n",
    "缺点: \n",
    "\n",
    "算法低效\n",
    "\n",
    "C4.5只适合于能够驻留于内存的数据集(后减枝)\n",
    "\n",
    "#### 5.1.3 CART算法\n",
    "\n",
    "二叉树\n",
    "\n",
    "处理离散型.连续型特征\n",
    "\n",
    "**C4.5不一定是二叉树，但CART一定是二叉树**\n",
    "\n",
    "#### 5.1.4 多变量决策树(multi-variate decision tree)\n",
    "\n",
    "**分类决策不应该是由某一个特征决定的，而是应该由一组特征决定的。**\n",
    "\n",
    "### 5.2 决策树变量的两种类型：\n",
    "\n",
    "1. 数字型  连续型 年收入\n",
    "2. 名称型  离散型 类别型  婚姻状况\n",
    "\n",
    "### **5.3 如何评估分割点的好坏？**\n",
    "\n",
    "找到能让数据最快达到\"纯\"的分割点就是好\n",
    "\n",
    "# 4.3 cart剪枝\n",
    "\n",
    "## 1 为什么要剪枝\n",
    "\n",
    "随着判断节点的增加 训练集效果越好越好\n",
    "\n",
    "​\t\t\t\t\t\t\t\t\t测试集效果 先上升后下降\n",
    "\n",
    "存在过拟合现象\n",
    "\n",
    "**出现这种情况的原因**\n",
    "\n",
    "原因1：噪声、样本冲突，即错误的样本数据。\n",
    "\n",
    "原因2：特征即属性不能完全作为分类标准。\n",
    "\n",
    "原因3：巧合的规律性，数据量不够大。\n",
    "\n",
    "## 2 常用的减枝方法\n",
    "\n",
    "1. 预减枝\n",
    "\n",
    "   1. 指定每一个结点所包含的最小样本数目，\n",
    "   2. 指定高度或深度\n",
    "   3. 指定一个阈值 ,熵小于阈值 就不往下划分\n",
    "\n",
    "2. 后减枝\n",
    "\n",
    "   后剪枝，在已生成过拟合决策树上进行剪枝，可以得到简化版的剪枝决策树。\n",
    "\n",
    "工作:后减枝\n",
    "\n",
    "# 4.4 特征工程-特征提取\n",
    "\n",
    "1. 特征提取\n",
    "2. 特征预处理(标准化)\n",
    "3. 特征降维\n",
    "\n",
    "## 1 特征提取\n",
    "\n",
    "**将任意数据（如文本或图像）转换为可用于机器学习的数字特征**\n",
    "\n",
    "分类\n",
    "\n",
    "1. 字典特征提取(特征离散化)\n",
    "2. 文本特征提取\n",
    "3. 图像特征提取\n",
    "\n",
    "### 1.2 特征提取API\n",
    "\n",
    "```python\n",
    "sklearn.feature_extraction\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## 2 字典特征提取\n",
    "\n",
    "sklearn.feature_extraction.DictVectorizer(sparse=True,…)\n",
    "\n",
    "- DictVectorizer.fit_transform(X)\n",
    "  - X:字典或者包含字典的迭代器返回值\n",
    "  - 返回sparse矩阵\n",
    "- DictVectorizer.get_feature_names() 返回类别名称\n",
    "\n",
    "transfer = DictVectorizer()\n",
    "\n",
    "transfer.fit_transform(x)\n",
    "\n",
    "**sparse 矩阵** 非0 的位置和值\n",
    "\n",
    "稀疏矩阵- 适合用sparse \n",
    "\n",
    "## 3 文本特征提取\n",
    "\n",
    "### 英文文本提取\n",
    "\n",
    "**sklearn.feature_extraction.text.CountVectorizer(stop_words=[])**\n",
    "\n",
    "统计频次 like  2\n",
    "\n",
    "stop_words: 停用词[is,]\n",
    "\n",
    "### 3.3 jieba分词处理\n",
    "\n",
    "import jieba\n",
    "\n",
    "jieba.cut()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树：\n",
    "- 是一种树形结构，其中每个内部节点表示一个属性上的判断，每个分支代表一个判断结果的输出，最后每个叶节点代表一种分类结果，本质是一颗由多个判断节点组成的树。\n",
    "\n",
    "- 系统越有序，熵值越低；系统越混乱或者分散，熵值越高。\n",
    "\n",
    "- 信息增益：以某特征划分数据集前后的熵的差值。熵可以表示样本集合的不确定性，熵越大，样本的不确定性就越大。因此可以使用划分前后集合熵的差值来衡量使用当前特征对于样本集合D划分效果的好坏。\n",
    "\n",
    "- 信息增益 = entroy(前) - entroy(后)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算类别信息熵\n",
    "import numpy as np\n",
    "ent_d = -5/15*np.log2(5/15)-10/15*np.log2(10/15)\n",
    "ent_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954434002924965"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算性别属性的信息熵\n",
    "a = -3/8*(np.log2(3/8)) - 5/8*(np.log2(5/8))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.863120568566631"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = -2/7*np.log2(2/7)-5/7*np.log2(5/7)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006474767163413719"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算性别的信息增益\n",
    "gain1 = ent_d - 8/15*a-7/15*b\n",
    "gain1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log2\n",
      "  \n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算活跃度属性信息熵\n",
    "high = -0/6*np.log2(0/6) - 6/6*np.log2(6/6)\n",
    "high = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7219280948873623"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid = -1/5*np.log2(1/5)-4/5*np.log2(4/5)\n",
    "mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6776531357587021"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算活跃度信息增益\n",
    "gain2 = ent_d - 5/15*mid\n",
    "gain2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 活跃度的信息增益比性别的信息增益大，也就是说，活跃度对用户流失的影响比性别大。在做特征选择或者数据分析的时候，我们应该重点考察活跃度这个指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 决策树的划分依据二----信息增益率\n",
    "- 增益率：增益率是用前面的信息增益Gain(D, a)和属性a对应的\"固有值\"(intrinsic value) [Quinlan , 1993J的比值来共同定义的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "3.2.1 案例一\n",
    "a.计算类别信息熵\n",
    "\n",
    "b.计算性别属性的信息熵(性别、活跃度)\n",
    "\n",
    "c.计算活跃度的信息增益(性别、活跃度)\n",
    "\n",
    "d.计算属性分裂信息度量\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9967916319816366"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算类别信息熵\n",
    "# x性别\n",
    "iv1 = -8/15*np.log2(8/15)-7/15*np.log2(7/15)\n",
    "iv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5655962303576019"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 活跃度\n",
    "iv2 = -6/15*np.log2(6/15)-5/15*np.log2(5/15)-4/15*np.log2(4/15)\n",
    "iv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00649560746265675"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算信息增益率\n",
    "gain_ratio1 = gain1/iv1\n",
    "gain_ratio1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43284029599631674"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain_ratio2 = gain2/iv2\n",
    "gain_ratio2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 案例二\n",
    "- 如下图，第一列为天气，第二列为温度，第三列为湿度，第四列为风速，最后一列该活动是否进行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402859586706311"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 计算类别的信息熵\n",
    "ent = -9/14*np.log2(9/14)-5/14*np.log2(5/14)\n",
    "ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6935361388961918"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算每个属性的信息熵\n",
    "# 天气\n",
    "ent_tq = 5/14*(-2/5*np.log2(2/5)-3/5*np.log2(3/5)) + 5/14*(-3/5*np.log2(3/5)-2/5*np.log2(2/5))\n",
    "ent_tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9110633930116763"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 温度\n",
    "ent_wd = 4/14 *(-2/4*np.log2(2/4)-2/4*np.log2(2/4))+ \\\n",
    "6/14*(-4/6*np.log2(4/6)-2/6*np.log2(2/6))+ \\\n",
    "4/14*(-3/4*np.log2(3/4)-1/4*np.log2(1/4))\n",
    "ent_wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884504573082896"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 湿度\n",
    "ent_sd = 7/14*(-3/7*np.log2(3/7)-4/7*np.log2(4/7))+ \\\n",
    "7/14*(-6/7*np.log2(6/7)-1/7*np.log2(1/7))\n",
    "ent_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380423950607804"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 风速\n",
    "ent_fs = 9/14*(-7/9*np.log2(7/9)-2/9*np.log2(2/9))+\\\n",
    "5/14*(-2/5*np.log2(2/5)-3/5*np.log2(3/5))\n",
    "ent_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24674981977443933"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算每个属性的信息增益\n",
    "gain_tq = ent-ent_tq\n",
    "gain_tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02922256565895487"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain_wd = ent-ent_wd\n",
    "gain_wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15183550136234159"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain_sd = ent-ent_sd\n",
    "gain_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10224356360985076"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain_fs = ent-ent_fs\n",
    "gain_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.569523321093397"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算属性分裂信息度量\n",
    "iv_tq = -5/14*np.log2(5/14)-4/15*np.log2(4/15)-5/14*np.log2(5/14)\n",
    "iv_tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5566567074628228"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_wd = -4/14*np.log2(4/14)-6/14*np.log2(6/14)-4/14*np.log2(4/14)\n",
    "iv_wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_sd = -7/14*np.log2(7/14)-7/14*np.log2(7/14)\n",
    "iv_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402859586706311"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iv_fs = -9/14*np.log2(9/14)-5/14*np.log2(5/14)\n",
    "iv_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15721322293098702"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算信息 增益率\n",
    "gain_r_tq = gain_tq/iv_tq\n",
    "gain_r_tq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018772646222418813"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain_r_wd = gain_wd/iv_wd\n",
    "gain_r_wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15183550136234159"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain_r_sd = gain_sd/iv_sd\n",
    "gain_r_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1087366695918781"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain_r_fs = gain_fs/iv_fs\n",
    "gain_r_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "while(当前节点\"不纯\")：\n",
    "    1.计算当前节点的类别熵(以类别取值计算)\n",
    "    2.计算当前阶段的属性熵(按照属性取值吓得类别取值计算)\n",
    "    3.计算信息增益\n",
    "    4.计算各个属性的分裂信息度量\n",
    "    5.计算各个属性的信息增益率\n",
    "end while\n",
    "当前阶段设置为叶子节点\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 决策树的划分依据三 基尼值和基尼指数\n",
    "x = 1/6*0+5/6*(1-(3/5)**2 - (2/5)**2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第二次大循环\n",
    "# 是否拖欠贷款\n",
    "gini = 1-(3/6)**2-(3/6)**2\n",
    "gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 是否有房\n",
    "gini_in = 2/6*0+4/6*(1-(3/4)**2-(1/4)**2)\n",
    "gini_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 年收入属性 77.5\n",
    "x = 1/6*0+5/6*(1-(3/5)**2 - (2/5)**2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 年收入属性87.5\n",
    "x = 2/6*(1-(1/2)**2-(1/2)**2) + 4/6*(1-(2/4)**2-(2/4)**2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 年收入属性92.5\n",
    "x = 3/6*(1-(1/3)**2-(2/3)**2) + 3/6*(1-(1/3)**2-(2/3)**2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 8/10*(1-(5/8)**2-(3/8)**2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 年收入属性110\n",
    "x = 4/6*(1-(1/4)**2-(3/4)**2) + 2/6*(1-(2/2)**2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 年收入属性172.5\n",
    "x = 5/6*(1-(2/5)**2-(3/5)**2) + 1/6*0\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征提取-特征工程\n",
    "- 字典特征提取\n",
    "\n",
    "```\n",
    "\n",
    "作用：对字典数据进行特征值化\n",
    "\n",
    "sklearn.feature_extraction.DictVectorizer(sparse=True,…)\n",
    "DictVectorizer.fit_transform(X)\n",
    "X:字典或者包含字典的迭代器返回值\n",
    "返回sparse矩阵\n",
    "DictVectorizer.get_feature_names() 返回类别名称\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'city': '北京', 'temperature': 100},\n",
       " {'city': '上海', 'temperature': 60},\n",
       " {'city': '深圳', 'temperature': 30}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jieba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造数据\n",
    "# 数据\n",
    "data = [{'city': '北京','temperature':100},\n",
    "{'city': '上海','temperature':60},\n",
    "{'city': '深圳','temperature':30}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化api\n",
    "transfer = DictVectorizer(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = transfer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转化后\n",
      " [[  0.   1.   0. 100.]\n",
      " [  1.   0.   0.  60.]\n",
      " [  0.   0.   1.  30.]]\n",
      "特征名\n",
      " ['city=上海', 'city=北京', 'city=深圳', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "print(\"转化后\\n\",mydata)\n",
    "print(\"特征名\\n\",transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"life life is short,i like python\",\n",
    "\"life is too long,i dislike python\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer = CountVectorizer(stop_words=['is'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = transfer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 1 0 1 1 0]\n",
      " [1 1 0 1 1 0 1]]\n",
      "['dislike', 'life', 'like', 'long', 'python', 'short', 'too']\n"
     ]
    }
   ],
   "source": [
    "print(mydata.toarray())\n",
    "print(transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中文文本提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。\",\n",
    "            \"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\",\n",
    "            \"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义切割函数\n",
    "def word_cut(text):\n",
    "    return \" \".join(list(jieba.cut(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data:\n",
    "    test_list.append(word_cut(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。',\n",
       " '我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。',\n",
       " '如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 2 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 2 0 1 0 2 1 0 0 0 1 1 0 0 1 0]\n",
      " [0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 3 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 1 0 1]\n",
      " [1 0 0 4 3 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 2 1 0 0 1 0 0 0]]\n",
      "['不会', '不要', '之前', '了解', '事物', '今天', '光是在', '几百万年', '发出', '取决于', '只用', '后天', '含义', '大部分', '如何', '如果', '宇宙', '我们', '所以', '放弃', '方式', '明天', '星系', '晚上', '某样', '残酷', '每个', '看到', '真正', '秘密', '绝对', '美好', '联系', '过去', '还是', '这样']\n"
     ]
    }
   ],
   "source": [
    "transfer = CountVectorizer(stop_words=[\"一种\"])\n",
    "mydata = transfer.fit_transform(test_list)\n",
    "print(mydata.toarray()) # 矩阵\n",
    "print(transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
