{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_mth</th>\n",
       "      <th>bad_ind</th>\n",
       "      <th>uid</th>\n",
       "      <th>td_score</th>\n",
       "      <th>jxl_score</th>\n",
       "      <th>mj_score</th>\n",
       "      <th>rh_score</th>\n",
       "      <th>zzc_score</th>\n",
       "      <th>zcx_score</th>\n",
       "      <th>person_info</th>\n",
       "      <th>finance_info</th>\n",
       "      <th>credit_info</th>\n",
       "      <th>act_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A10000005</td>\n",
       "      <td>0.675349</td>\n",
       "      <td>0.144072</td>\n",
       "      <td>0.186899</td>\n",
       "      <td>0.483640</td>\n",
       "      <td>0.928328</td>\n",
       "      <td>0.369644</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.217949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A1000002</td>\n",
       "      <td>0.825269</td>\n",
       "      <td>0.398688</td>\n",
       "      <td>0.139396</td>\n",
       "      <td>0.843725</td>\n",
       "      <td>0.605194</td>\n",
       "      <td>0.406122</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A1000011</td>\n",
       "      <td>0.315406</td>\n",
       "      <td>0.629745</td>\n",
       "      <td>0.535854</td>\n",
       "      <td>0.197392</td>\n",
       "      <td>0.614416</td>\n",
       "      <td>0.320731</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.448718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A10000481</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.609360</td>\n",
       "      <td>0.366081</td>\n",
       "      <td>0.342243</td>\n",
       "      <td>0.870006</td>\n",
       "      <td>0.288692</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.179487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A1000069</td>\n",
       "      <td>0.406310</td>\n",
       "      <td>0.405352</td>\n",
       "      <td>0.783015</td>\n",
       "      <td>0.563953</td>\n",
       "      <td>0.715454</td>\n",
       "      <td>0.512554</td>\n",
       "      <td>-0.261014</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      obs_mth  bad_ind        uid  td_score  jxl_score  mj_score  rh_score  \\\n",
       "0  2018-10-31      0.0  A10000005  0.675349   0.144072  0.186899  0.483640   \n",
       "1  2018-07-31      0.0   A1000002  0.825269   0.398688  0.139396  0.843725   \n",
       "2  2018-09-30      0.0   A1000011  0.315406   0.629745  0.535854  0.197392   \n",
       "3  2018-07-31      0.0  A10000481  0.002386   0.609360  0.366081  0.342243   \n",
       "4  2018-07-31      0.0   A1000069  0.406310   0.405352  0.783015  0.563953   \n",
       "\n",
       "   zzc_score  zcx_score  person_info  finance_info  credit_info  act_info  \n",
       "0   0.928328   0.369644    -0.322581      0.023810         0.00  0.217949  \n",
       "1   0.605194   0.406122    -0.128677      0.023810         0.00  0.423077  \n",
       "2   0.614416   0.320731     0.062660      0.023810         0.10  0.448718  \n",
       "3   0.870006   0.288692     0.078853      0.071429         0.05  0.179487  \n",
       "4   0.715454   0.512554    -0.261014      0.023810         0.00  0.423077  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Bcard.txt')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018-10-31', '2018-07-31', '2018-09-30', '2018-06-30',\n",
       "       '2018-11-30'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.obs_mth.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data.obs_mth!='2018-11-30'].reset_index().copy()  # 利用前4个月的数据训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = data[data.obs_mth=='2018-11-30'].reset_index().copy()# 最后一个月做跨时间交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取特征列\n",
    "feat_list = ['person_info','finance_info','credit_info','act_info','td_score','jxl_score','mj_score','rh_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[feat_list]\n",
    "y = train_data['bad_ind']\n",
    "\n",
    "val_x = val_data[feat_list]\n",
    "val_y = val_data['bad_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建逻辑回归对象\n",
    "lr_model=LogisticRegression(C=0.1,class_weight='balanced')\n",
    "lr_model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict_proba(x)[:,1]  # 利用训练集的数据 做预测 得到坏人的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lr_train,tpr_lr_train,_ = roc_curve(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4467813756096739"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ks = abs(fpr_lr_train - tpr_lr_train).max()  # 计算训练集的KS值\n",
    "train_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40827938652621015"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr_model.predict_proba(val_x)[:,1]  # 利用训练集的数据 做预测 得到坏人的概率\n",
    "fpr_lr_val,tpr_lr_val,_ = roc_curve(val_y,y_pred)\n",
    "val_ks = abs(fpr_lr_val - tpr_lr_val).max()  # 计算训练集的KS值\n",
    "val_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1659cda60f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(fpr_lr_train,tpr_lr_train,label='train')\n",
    "plt.plot(fpr_lr_val,tpr_lr_val,label='val')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3021397545577489\n",
      "1.9579535743186598\n",
      "1.2899442089163669\n",
      "2.9681708673324287\n",
      "3.2871099722760166\n",
      "3.2864932840089116\n",
      "3.3175087980337827\n",
      "3.2910065791107583\n"
     ]
    }
   ],
   "source": [
    "### 调整参数  vif <5都可以接受   共线性\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# statsmodels 传入numpy 的ndarray\n",
    "X = np.array(x)\n",
    "for i in range(X.shape[1]):\n",
    "    print(variance_inflation_factor(X,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.759467\tvalid_1's auc: 0.753322\n",
      "[2]\ttraining's auc: 0.809023\tvalid_1's auc: 0.805658\n",
      "[3]\ttraining's auc: 0.809328\tvalid_1's auc: 0.803858\n",
      "[4]\ttraining's auc: 0.810298\tvalid_1's auc: 0.801355\n",
      "[5]\ttraining's auc: 0.814873\tvalid_1's auc: 0.807356\n",
      "[6]\ttraining's auc: 0.816492\tvalid_1's auc: 0.809279\n",
      "[7]\ttraining's auc: 0.820213\tvalid_1's auc: 0.809208\n",
      "[8]\ttraining's auc: 0.823931\tvalid_1's auc: 0.812081\n",
      "[9]\ttraining's auc: 0.82696\tvalid_1's auc: 0.81453\n",
      "[10]\ttraining's auc: 0.827882\tvalid_1's auc: 0.813428\n",
      "[11]\ttraining's auc: 0.828881\tvalid_1's auc: 0.814226\n",
      "[12]\ttraining's auc: 0.829577\tvalid_1's auc: 0.813749\n",
      "[13]\ttraining's auc: 0.830406\tvalid_1's auc: 0.813156\n",
      "[14]\ttraining's auc: 0.830843\tvalid_1's auc: 0.812973\n",
      "[15]\ttraining's auc: 0.831587\tvalid_1's auc: 0.813501\n",
      "[16]\ttraining's auc: 0.831898\tvalid_1's auc: 0.813611\n",
      "[17]\ttraining's auc: 0.833751\tvalid_1's auc: 0.81393\n",
      "[18]\ttraining's auc: 0.834139\tvalid_1's auc: 0.814532\n",
      "[19]\ttraining's auc: 0.835177\tvalid_1's auc: 0.815209\n",
      "[20]\ttraining's auc: 0.837368\tvalid_1's auc: 0.815205\n",
      "[21]\ttraining's auc: 0.837946\tvalid_1's auc: 0.815099\n",
      "[22]\ttraining's auc: 0.839585\tvalid_1's auc: 0.815602\n",
      "[23]\ttraining's auc: 0.840781\tvalid_1's auc: 0.816105\n",
      "[24]\ttraining's auc: 0.841174\tvalid_1's auc: 0.816869\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>credit_info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>act_info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>td_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>jxl_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>rh_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>person_info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>finance_info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46</td>\n",
       "      <td>mj_score</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   importance          name\n",
       "2          98   credit_info\n",
       "3          62      act_info\n",
       "4          54      td_score\n",
       "5          50     jxl_score\n",
       "7          50      rh_score\n",
       "0          49   person_info\n",
       "1          47  finance_info\n",
       "6          46      mj_score"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### lightgbm进行特征筛选\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,test_x,train_y,test_y = train_test_split(x,y,random_state=0,test_size=0.2)\n",
    "def lgb_test(train_x,train_y,test_x,test_y):\n",
    "    clf =lgb.LGBMClassifier(boosting_type = 'gbdt',\n",
    "                           objective = 'binary',\n",
    "                           metric = 'auc',\n",
    "                           learning_rate = 0.1,\n",
    "                           n_estimators = 24,\n",
    "                           max_depth = 5,\n",
    "                           num_leaves = 20,\n",
    "                           max_bin = 45,\n",
    "                           min_data_in_leaf = 6,\n",
    "                           bagging_fraction = 0.6,\n",
    "                           bagging_freq = 0,\n",
    "                           feature_fraction = 0.8,\n",
    "                           )\n",
    "    clf.fit(train_x,train_y,eval_set = [(train_x,train_y),(test_x,test_y)],eval_metric = 'auc')\n",
    "    return clf,clf.best_score_['valid_1']['auc'],\n",
    "lgb_model , lgb_auc  = lgb_test(train_x,train_y,test_x,test_y)\n",
    "feature_importance = pd.DataFrame({'name':lgb_model.booster_.feature_name(),\n",
    "                                   'importance':lgb_model.feature_importances_}).sort_values(by=['importance'],ascending=False)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ks :  0.4482453222991063\n",
      "val_ks :  0.4198642457760936\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16583bde978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_lst = ['person_info','finance_info','credit_info','act_info']\n",
    "x = train_data[feature_lst]\n",
    "y = train_data['bad_ind']\n",
    "\n",
    "val_x =  val_data[feature_lst]\n",
    "val_y = val_data['bad_ind']\n",
    "\n",
    "lr_model = LogisticRegression(C=0.1,class_weight='balanced')\n",
    "lr_model.fit(x,y)\n",
    "y_pred = lr_model.predict_proba(x)[:,1]\n",
    "fpr_lr_train,tpr_lr_train,_ = roc_curve(y,y_pred)\n",
    "train_ks = abs(fpr_lr_train - tpr_lr_train).max()\n",
    "print('train_ks : ',train_ks)\n",
    "\n",
    "y_pred = lr_model.predict_proba(val_x)[:,1]\n",
    "fpr_lr,tpr_lr,_ = roc_curve(val_y,y_pred)\n",
    "val_ks = abs(fpr_lr - tpr_lr).max()\n",
    "print('val_ks : ',val_ks)\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(fpr_lr_train,tpr_lr_train,label = 'train LR')\n",
    "plt.plot(fpr_lr,tpr_lr,label = 'evl LR')\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lr_model\n",
    "row_num, col_num = 0, 0\n",
    "bins = 20 #分20箱\n",
    "Y_predict = [s[1] for s in model.predict_proba(val_x)]\n",
    "Y = val_y\n",
    "nrows = Y.shape[0]\n",
    "lis = [(Y_predict[i], Y[i]) for i in range(nrows)]\n",
    "ks_lis = sorted(lis, key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9998810420781638, 0.0),\n",
       " (0.9997557352213052, 1.0),\n",
       " (0.9997142467654432, 0.0),\n",
       " (0.9995800601292381, 0.0),\n",
       " (0.9995441261151846, 1.0),\n",
       " (0.9992667949429288, 0.0),\n",
       " (0.9992422500834002, 0.0),\n",
       " (0.9991624848431582, 0.0),\n",
       " (0.9989768269964682, 0.0),\n",
       " (0.9987501407960664, 1.0),\n",
       " (0.9985508303760025, 0.0),\n",
       " (0.9983528775882653, 0.0),\n",
       " (0.9983247017642491, 0.0),\n",
       " (0.9980729563774176, 0.0),\n",
       " (0.9980504228240851, 0.0),\n",
       " (0.9979132554311255, 1.0),\n",
       " (0.9978547876185625, 0.0),\n",
       " (0.9977443592066718, 0.0),\n",
       " (0.9977137330728414, 1.0),\n",
       " (0.99760644118801, 0.0),\n",
       " (0.997351442188116, 1.0),\n",
       " (0.9973446480732304, 0.0),\n",
       " (0.9970818689296547, 0.0),\n",
       " (0.9965475993114369, 0.0),\n",
       " (0.9964547693794975, 1.0),\n",
       " (0.9964384577633592, 0.0),\n",
       " (0.9963713898739128, 0.0),\n",
       " (0.9961831086180791, 1.0),\n",
       " (0.9959719234226618, 0.0),\n",
       " (0.9958253160311451, 1.0),\n",
       " (0.995691959159134, 1.0),\n",
       " (0.9956309182215204, 0.0),\n",
       " (0.9955223181836217, 0.0),\n",
       " (0.9955209054521454, 0.0),\n",
       " (0.9951877696192433, 0.0),\n",
       " (0.9950855317974946, 0.0),\n",
       " (0.9947095312595658, 0.0),\n",
       " (0.9944703630322588, 0.0),\n",
       " (0.9937936403331827, 1.0),\n",
       " (0.9935930968564137, 1.0),\n",
       " (0.9935696923337786, 0.0),\n",
       " (0.9934081435183219, 0.0),\n",
       " (0.9932479600203366, 0.0),\n",
       " (0.9927305885051647, 0.0),\n",
       " (0.9923071838648475, 0.0),\n",
       " (0.9921217110723531, 0.0),\n",
       " (0.9917603711504621, 0.0),\n",
       " (0.9914052192550882, 1.0),\n",
       " (0.991396021791642, 0.0),\n",
       " (0.9912236626421884, 0.0),\n",
       " (0.9908776247039961, 0.0),\n",
       " (0.9908519276735163, 0.0),\n",
       " (0.990705824447078, 1.0),\n",
       " (0.9906543958366123, 0.0),\n",
       " (0.9901875577302602, 1.0),\n",
       " (0.9899291139704216, 0.0),\n",
       " (0.9895662257258688, 0.0),\n",
       " (0.9891767382445614, 0.0),\n",
       " (0.9888899740685116, 0.0),\n",
       " (0.9887318208223765, 0.0),\n",
       " (0.9887012167896063, 0.0),\n",
       " (0.9886358959017119, 0.0),\n",
       " (0.9886228218177258, 0.0),\n",
       " (0.9884921370659419, 0.0),\n",
       " (0.9884692521980414, 1.0),\n",
       " (0.9883187909666455, 0.0),\n",
       " (0.9883175031960251, 1.0),\n",
       " (0.9881259827185344, 0.0),\n",
       " (0.9880424274452944, 1.0),\n",
       " (0.9880207891535487, 0.0),\n",
       " (0.9878564187807174, 0.0),\n",
       " (0.9877502026897607, 0.0),\n",
       " (0.9875436346966913, 0.0),\n",
       " (0.9874508017424035, 1.0),\n",
       " (0.9873409995896621, 0.0),\n",
       " (0.9873231502060189, 0.0),\n",
       " (0.98726185067149, 0.0),\n",
       " (0.9871903876072765, 1.0),\n",
       " (0.9869946436291556, 0.0),\n",
       " (0.9869431092368451, 0.0),\n",
       " (0.9868186513018475, 0.0),\n",
       " (0.9866544935467474, 0.0),\n",
       " (0.9860606900668377, 0.0),\n",
       " (0.986028909263802, 1.0),\n",
       " (0.9859120497124707, 0.0),\n",
       " (0.9855604031230671, 0.0),\n",
       " (0.9855438747069722, 0.0),\n",
       " (0.9851230760403008, 1.0),\n",
       " (0.9843976393625465, 0.0),\n",
       " (0.9843855945658709, 1.0),\n",
       " (0.9843239457070515, 0.0),\n",
       " (0.9840467855026417, 0.0),\n",
       " (0.98392648967167, 0.0),\n",
       " (0.983694075178052, 1.0),\n",
       " (0.9832975449766744, 0.0),\n",
       " (0.9832334363876513, 0.0),\n",
       " (0.9830646035481194, 0.0),\n",
       " (0.9830219218930867, 1.0),\n",
       " (0.9824808618367056, 0.0),\n",
       " (0.9823865987873108, 0.0),\n",
       " (0.9820936912343979, 0.0),\n",
       " (0.9816613701312225, 0.0),\n",
       " (0.981630306538058, 0.0),\n",
       " (0.9812395251304781, 0.0),\n",
       " (0.981210359658416, 0.0),\n",
       " (0.9811586674498888, 0.0),\n",
       " (0.9805309062569897, 0.0),\n",
       " (0.9803506163856026, 0.0),\n",
       " (0.9799707016561998, 0.0),\n",
       " (0.9795227870976563, 0.0),\n",
       " (0.9790065616319241, 0.0),\n",
       " (0.9788974060878507, 0.0),\n",
       " (0.9786208975641602, 0.0),\n",
       " (0.9783703523389772, 0.0),\n",
       " (0.9782422582562058, 1.0),\n",
       " (0.97821481862732, 0.0),\n",
       " (0.978164256013089, 0.0),\n",
       " (0.9780362260552746, 0.0),\n",
       " (0.9780153157461572, 0.0),\n",
       " (0.9779967222904313, 0.0),\n",
       " (0.9776613087429098, 0.0),\n",
       " (0.9771678074382906, 1.0),\n",
       " (0.9770911657737655, 1.0),\n",
       " (0.9769710795191525, 0.0),\n",
       " (0.9762488298087784, 0.0),\n",
       " (0.9760037787730946, 0.0),\n",
       " (0.9756481962516802, 0.0),\n",
       " (0.9751102606542617, 0.0),\n",
       " (0.9749691512939896, 0.0),\n",
       " (0.9748056010182297, 0.0),\n",
       " (0.9746847972158496, 0.0),\n",
       " (0.974653270696428, 0.0),\n",
       " (0.9743611107584439, 1.0),\n",
       " (0.9741602372208645, 1.0),\n",
       " (0.974158210188113, 0.0),\n",
       " (0.9739797768669626, 0.0),\n",
       " (0.9738421048378751, 0.0),\n",
       " (0.9738022352266021, 1.0),\n",
       " (0.9735776240443266, 0.0),\n",
       " (0.9732639798386261, 0.0),\n",
       " (0.9732336192018508, 0.0),\n",
       " (0.973180036025372, 0.0),\n",
       " (0.973134051496945, 0.0),\n",
       " (0.9729029415020701, 0.0),\n",
       " (0.972631905130663, 0.0),\n",
       " (0.9725771957850746, 0.0),\n",
       " (0.9725132347319885, 0.0),\n",
       " (0.9724219447056749, 0.0),\n",
       " (0.9722146950389224, 1.0),\n",
       " (0.9721644697622682, 0.0),\n",
       " (0.9718272484748377, 0.0),\n",
       " (0.9712445471655254, 0.0),\n",
       " (0.9709370620089092, 0.0),\n",
       " (0.9709292686776894, 0.0),\n",
       " (0.9707632818367999, 0.0),\n",
       " (0.9704384745626684, 0.0),\n",
       " (0.9699822032428799, 0.0),\n",
       " (0.9697940322824684, 0.0),\n",
       " (0.9696813788498228, 0.0),\n",
       " (0.9685196193169203, 0.0),\n",
       " (0.9682096914105766, 0.0),\n",
       " (0.9677380468034534, 0.0),\n",
       " (0.9673642133274567, 0.0),\n",
       " (0.9673240991449518, 0.0),\n",
       " (0.9672546058290387, 0.0),\n",
       " (0.96678168679392, 0.0),\n",
       " (0.9663555194571009, 0.0),\n",
       " (0.9661013581340675, 1.0),\n",
       " (0.9658833837490854, 0.0),\n",
       " (0.9651614342140827, 0.0),\n",
       " (0.9651534036228744, 0.0),\n",
       " (0.9649168521363904, 0.0),\n",
       " (0.9647290356038578, 0.0),\n",
       " (0.9647209991363834, 0.0),\n",
       " (0.9645595866890003, 0.0),\n",
       " (0.9643134888063353, 0.0),\n",
       " (0.964202040442786, 0.0),\n",
       " (0.9639544066520547, 0.0),\n",
       " (0.963716014523755, 0.0),\n",
       " (0.9636183388634619, 0.0),\n",
       " (0.9632307608571251, 1.0),\n",
       " (0.9629422519177082, 0.0),\n",
       " (0.9624851001077589, 0.0),\n",
       " (0.9621874759144177, 1.0),\n",
       " (0.9617086937815068, 0.0),\n",
       " (0.9615502039713967, 0.0),\n",
       " (0.9613838440160721, 0.0),\n",
       " (0.9608613600289658, 0.0),\n",
       " (0.9605289810505094, 0.0),\n",
       " (0.9602935075817979, 0.0),\n",
       " (0.9601843433432004, 0.0),\n",
       " (0.9599975575096813, 0.0),\n",
       " (0.9599440488612823, 0.0),\n",
       " (0.9597394382773194, 0.0),\n",
       " (0.9596387571638262, 0.0),\n",
       " (0.9593283368973029, 0.0),\n",
       " (0.9592811539226989, 0.0),\n",
       " (0.9588975283332132, 1.0),\n",
       " (0.9588386387427648, 0.0),\n",
       " (0.9584756982334597, 0.0),\n",
       " (0.9582182255801593, 0.0),\n",
       " (0.9582013033681557, 0.0),\n",
       " (0.9579327605364079, 0.0),\n",
       " (0.9577335102536877, 0.0),\n",
       " (0.9575653564058882, 0.0),\n",
       " (0.9575086466515631, 1.0),\n",
       " (0.9574807401388195, 0.0),\n",
       " (0.9574734910843137, 0.0),\n",
       " (0.9574603756059846, 0.0),\n",
       " (0.9573937527280076, 0.0),\n",
       " (0.9570303880137885, 0.0),\n",
       " (0.9569318682809934, 0.0),\n",
       " (0.9566963329530067, 0.0),\n",
       " (0.9564978703875903, 0.0),\n",
       " (0.9562104175190634, 0.0),\n",
       " (0.955862508454051, 0.0),\n",
       " (0.9557783313260081, 0.0),\n",
       " (0.9555600474553445, 1.0),\n",
       " (0.9553692925064506, 0.0),\n",
       " (0.9553274673420766, 0.0),\n",
       " (0.9552999148157347, 0.0),\n",
       " (0.9550133890775595, 0.0),\n",
       " (0.9549613791989422, 0.0),\n",
       " (0.9548593857874773, 0.0),\n",
       " (0.9548278509186593, 1.0),\n",
       " (0.9546289345036248, 0.0),\n",
       " (0.9545811019869975, 0.0),\n",
       " (0.954382584474746, 0.0),\n",
       " (0.9543479217900939, 0.0),\n",
       " (0.9543441615247713, 1.0),\n",
       " (0.9543068051209679, 0.0),\n",
       " (0.9530070012393642, 0.0),\n",
       " (0.9529533877074489, 0.0),\n",
       " (0.9528220722825879, 0.0),\n",
       " (0.9516392445736727, 0.0),\n",
       " (0.9515552656117746, 0.0),\n",
       " (0.951153559067079, 0.0),\n",
       " (0.9509385115873169, 0.0),\n",
       " (0.9504789937490213, 1.0),\n",
       " (0.9502453202970228, 0.0),\n",
       " (0.9502175916714696, 0.0),\n",
       " (0.9501688460217899, 0.0),\n",
       " (0.9500602220501481, 0.0),\n",
       " (0.9491559715694909, 0.0),\n",
       " (0.9491466415373999, 0.0),\n",
       " (0.9489513093487809, 0.0),\n",
       " (0.948844303643647, 0.0),\n",
       " (0.9485223504951715, 1.0),\n",
       " (0.9476399714129681, 0.0),\n",
       " (0.9474116197637158, 0.0),\n",
       " (0.9470405554827066, 0.0),\n",
       " (0.9470104481957653, 0.0),\n",
       " (0.946904846299916, 0.0),\n",
       " (0.9466826648457782, 0.0),\n",
       " (0.946327646559604, 0.0),\n",
       " (0.946124803170117, 0.0),\n",
       " (0.945833961738699, 0.0),\n",
       " (0.9457763337369612, 0.0),\n",
       " (0.9456038394554823, 0.0),\n",
       " (0.9455923450834417, 1.0),\n",
       " (0.9455547519771653, 0.0),\n",
       " (0.9454140120613762, 0.0),\n",
       " (0.9452980009600785, 0.0),\n",
       " (0.9448269284234165, 1.0),\n",
       " (0.944294853534994, 0.0),\n",
       " (0.9440869266493207, 0.0),\n",
       " (0.9440216333829754, 1.0),\n",
       " (0.9438895229599961, 0.0),\n",
       " (0.9438891670363774, 0.0),\n",
       " (0.9438536463408406, 0.0),\n",
       " (0.943817973764567, 0.0),\n",
       " (0.9438118829665076, 0.0),\n",
       " (0.9437670189673892, 1.0),\n",
       " (0.9437584550562296, 1.0),\n",
       " (0.9437134410618229, 0.0),\n",
       " (0.9432274109851205, 0.0),\n",
       " (0.9428856771311552, 0.0),\n",
       " (0.9428787437579624, 0.0),\n",
       " (0.9427402227862067, 0.0),\n",
       " (0.9425621537993704, 0.0),\n",
       " (0.942312003987809, 0.0),\n",
       " (0.9422959718150941, 0.0),\n",
       " (0.9422731790310047, 0.0),\n",
       " (0.9421000714797819, 0.0),\n",
       " (0.941971826093452, 0.0),\n",
       " (0.9417683918719404, 0.0),\n",
       " (0.9417109373103089, 0.0),\n",
       " (0.9416788258876874, 0.0),\n",
       " (0.9410926338317918, 0.0),\n",
       " (0.9410193783693328, 0.0),\n",
       " (0.9409008730571848, 0.0),\n",
       " (0.9408753966651786, 0.0),\n",
       " (0.9408637181642845, 0.0),\n",
       " (0.9405953285276143, 0.0),\n",
       " (0.9405531401754363, 0.0),\n",
       " (0.9402572455446332, 1.0),\n",
       " (0.9401760803098996, 0.0),\n",
       " (0.9397994712388374, 0.0),\n",
       " (0.9395707414884025, 0.0),\n",
       " (0.9394571823955317, 0.0),\n",
       " (0.9394384590012471, 0.0),\n",
       " (0.9391883455406527, 0.0),\n",
       " (0.9389473621342893, 0.0),\n",
       " (0.9387712690595191, 0.0),\n",
       " (0.9384290395107232, 0.0),\n",
       " (0.9384277271615219, 0.0),\n",
       " (0.9383853319711746, 0.0),\n",
       " (0.9382465658837426, 0.0),\n",
       " (0.9379818904301848, 0.0),\n",
       " (0.9377519880453125, 0.0),\n",
       " (0.9375550043141907, 0.0),\n",
       " (0.9374488203525303, 0.0),\n",
       " (0.9373751838923031, 0.0),\n",
       " (0.9372993459986569, 0.0),\n",
       " (0.9371737297767074, 0.0),\n",
       " (0.9370082059295608, 0.0),\n",
       " (0.9369872973965441, 0.0),\n",
       " (0.9368844617962406, 0.0),\n",
       " (0.9363654296148666, 0.0),\n",
       " (0.9360798924699576, 0.0),\n",
       " (0.9360497479106639, 0.0),\n",
       " (0.9360439769865773, 0.0),\n",
       " (0.9357120226765349, 0.0),\n",
       " (0.9356907293589948, 0.0),\n",
       " (0.9355596459138756, 0.0),\n",
       " (0.9353230446884695, 1.0),\n",
       " (0.9352244296880876, 0.0),\n",
       " (0.9348616670443104, 0.0),\n",
       " (0.9347152337978584, 0.0),\n",
       " (0.9342814375875707, 0.0),\n",
       " (0.9341949740211748, 0.0),\n",
       " (0.9340578245181773, 0.0),\n",
       " (0.9339344803560397, 0.0),\n",
       " (0.9339258922844615, 0.0),\n",
       " (0.9338821791203973, 0.0),\n",
       " (0.9338197252182193, 0.0),\n",
       " (0.9337277682117531, 0.0),\n",
       " (0.9335620342435991, 0.0),\n",
       " (0.9335030280491041, 0.0),\n",
       " (0.9334675567903453, 0.0),\n",
       " (0.9329979850335317, 0.0),\n",
       " (0.9325327344021563, 0.0),\n",
       " (0.93246037045505, 0.0),\n",
       " (0.9322677158635527, 0.0),\n",
       " (0.932110824409196, 0.0),\n",
       " (0.9320198281267046, 0.0),\n",
       " (0.9318981271853024, 0.0),\n",
       " (0.9317419248392621, 0.0),\n",
       " (0.9316707272161797, 0.0),\n",
       " (0.9312518401597231, 0.0),\n",
       " (0.9312236473968287, 0.0),\n",
       " (0.9310394270324457, 0.0),\n",
       " (0.9308527923912414, 0.0),\n",
       " (0.9305645143376903, 0.0),\n",
       " (0.9305336413951322, 1.0),\n",
       " (0.9305148552187393, 0.0),\n",
       " (0.9296789688294446, 1.0),\n",
       " (0.9295435249305484, 0.0),\n",
       " (0.9293288849113971, 0.0),\n",
       " (0.9291938656302041, 0.0),\n",
       " (0.9288972111052582, 0.0),\n",
       " (0.9284975049449494, 0.0),\n",
       " (0.9283980909172445, 0.0),\n",
       " (0.9282956093828633, 0.0),\n",
       " (0.9281762279232498, 0.0),\n",
       " (0.9279947150791896, 0.0),\n",
       " (0.927800694560458, 0.0),\n",
       " (0.9276170354644627, 0.0),\n",
       " (0.9274127068015413, 0.0),\n",
       " (0.9273365782986138, 0.0),\n",
       " (0.9272790030820189, 0.0),\n",
       " (0.9272370575671617, 0.0),\n",
       " (0.9271225738086085, 1.0),\n",
       " (0.9270888513730905, 0.0),\n",
       " (0.9270803000805762, 0.0),\n",
       " (0.9269432754699526, 0.0),\n",
       " (0.9269037326036821, 1.0),\n",
       " (0.9267538225320172, 0.0),\n",
       " (0.9263752308178621, 0.0),\n",
       " (0.9263712750597667, 0.0),\n",
       " (0.9261027507945205, 0.0),\n",
       " (0.9257910959471336, 1.0),\n",
       " (0.9257824093503784, 0.0),\n",
       " (0.9257476549933283, 0.0),\n",
       " (0.9257456097839909, 0.0),\n",
       " (0.9256746080682065, 0.0),\n",
       " (0.9255145620399052, 0.0),\n",
       " (0.9255078547405342, 0.0),\n",
       " (0.925505868103631, 1.0),\n",
       " (0.9254915130236046, 0.0),\n",
       " (0.925479828182399, 1.0),\n",
       " (0.9253887349286738, 0.0),\n",
       " (0.9251217817100442, 0.0),\n",
       " (0.9249546721182604, 0.0),\n",
       " (0.9248976450042397, 0.0),\n",
       " (0.9247868410884849, 1.0),\n",
       " (0.924505582605817, 0.0),\n",
       " (0.9243926508895611, 0.0),\n",
       " (0.92432631903324, 0.0),\n",
       " (0.9242582406098874, 0.0),\n",
       " (0.9242573662838348, 0.0),\n",
       " (0.9241513131950171, 0.0),\n",
       " (0.9240584484455484, 0.0),\n",
       " (0.9237396280163848, 0.0),\n",
       " (0.9234591579534609, 0.0),\n",
       " (0.9234136888243151, 0.0),\n",
       " (0.9233722976622983, 0.0),\n",
       " (0.9231457052821028, 0.0),\n",
       " (0.9231026783390075, 0.0),\n",
       " (0.9230999117886558, 0.0),\n",
       " (0.9230140164802011, 0.0),\n",
       " (0.9226688194906535, 0.0),\n",
       " (0.9225442378473955, 0.0),\n",
       " (0.922396159011373, 1.0),\n",
       " (0.9223055557095786, 0.0),\n",
       " (0.9219608545844716, 1.0),\n",
       " (0.9219446936585841, 0.0),\n",
       " (0.921843082677254, 0.0),\n",
       " (0.9217874197804737, 0.0),\n",
       " (0.9216977656114633, 0.0),\n",
       " (0.9216887418821461, 0.0),\n",
       " (0.921550588990189, 0.0),\n",
       " (0.9215323694921572, 0.0),\n",
       " (0.9214930055865925, 1.0),\n",
       " (0.9214712863507334, 0.0),\n",
       " (0.9211468109917124, 0.0),\n",
       " (0.9210382579504982, 0.0),\n",
       " (0.920855055657421, 0.0),\n",
       " (0.9205115872593723, 0.0),\n",
       " (0.9204998980535244, 1.0),\n",
       " (0.9201619550578555, 0.0),\n",
       " (0.9201308619643471, 0.0),\n",
       " (0.9200272387212755, 0.0),\n",
       " (0.9195252667435767, 0.0),\n",
       " (0.919397426930147, 0.0),\n",
       " (0.919226610298203, 0.0),\n",
       " (0.9191811329534991, 0.0),\n",
       " (0.918357545107682, 0.0),\n",
       " (0.9180154495913351, 0.0),\n",
       " (0.917981799267153, 1.0),\n",
       " (0.9177245580244148, 0.0),\n",
       " (0.9176961644868149, 1.0),\n",
       " (0.917636283809391, 0.0),\n",
       " (0.9176260300666778, 0.0),\n",
       " (0.9175604311073005, 0.0),\n",
       " (0.9175521998229719, 0.0),\n",
       " (0.9173184392217725, 0.0),\n",
       " (0.9172001595690102, 0.0),\n",
       " (0.9170779967320598, 0.0),\n",
       " (0.9168556488537309, 0.0),\n",
       " (0.9168069190146944, 0.0),\n",
       " (0.9165692204427657, 0.0),\n",
       " (0.9164242492762488, 0.0),\n",
       " (0.9163727513267806, 0.0),\n",
       " (0.9161797475577228, 0.0),\n",
       " (0.9160223098407331, 0.0),\n",
       " (0.9160184071151173, 0.0),\n",
       " (0.915974436379117, 1.0),\n",
       " (0.9158451941573922, 0.0),\n",
       " (0.9149776061975844, 0.0),\n",
       " (0.9148842182253528, 0.0),\n",
       " (0.9147232730496891, 0.0),\n",
       " (0.914522134479332, 0.0),\n",
       " (0.9144827082971104, 0.0),\n",
       " (0.9140378665841172, 0.0),\n",
       " (0.9138436570577781, 0.0),\n",
       " (0.9137775756420259, 0.0),\n",
       " (0.9137464171938111, 0.0),\n",
       " (0.9136155693613268, 0.0),\n",
       " (0.9136029879324497, 0.0),\n",
       " (0.9135415000223125, 0.0),\n",
       " (0.9134797442766552, 0.0),\n",
       " (0.9130077801079328, 0.0),\n",
       " (0.9129637471071672, 0.0),\n",
       " (0.9127447166879453, 0.0),\n",
       " (0.9124913759518027, 0.0),\n",
       " (0.9122277287980575, 0.0),\n",
       " (0.911951646442883, 0.0),\n",
       " (0.9118667034628348, 0.0),\n",
       " (0.9118661383450012, 0.0),\n",
       " (0.9115288078806075, 0.0),\n",
       " (0.9114285136165081, 0.0),\n",
       " (0.9110862981300638, 0.0),\n",
       " (0.9109716619837745, 0.0),\n",
       " (0.9104023876655651, 0.0),\n",
       " (0.9101039303859789, 0.0),\n",
       " (0.9095324177852, 0.0),\n",
       " (0.909416634645891, 0.0),\n",
       " (0.9093124848989586, 0.0),\n",
       " (0.9092728175502632, 0.0),\n",
       " (0.9091269230593595, 0.0),\n",
       " (0.9091041633239424, 0.0),\n",
       " (0.9089724677667309, 0.0),\n",
       " (0.9088993898832506, 0.0),\n",
       " (0.9086870102148712, 0.0),\n",
       " (0.9085494738037545, 0.0),\n",
       " (0.9082139822899491, 0.0),\n",
       " (0.9075016583017471, 0.0),\n",
       " (0.9074519653464471, 0.0),\n",
       " (0.9073702203707297, 0.0),\n",
       " (0.9072498298412912, 0.0),\n",
       " (0.9072069080432156, 0.0),\n",
       " (0.9071648682318573, 1.0),\n",
       " (0.907091427822544, 0.0),\n",
       " (0.9070340931755952, 0.0),\n",
       " (0.9066974644914503, 0.0),\n",
       " (0.9065584584791513, 0.0),\n",
       " (0.9061842391305654, 0.0),\n",
       " (0.906069707867246, 0.0),\n",
       " (0.9060374029703938, 0.0),\n",
       " (0.9059625903379809, 0.0),\n",
       " (0.9058204880290688, 0.0),\n",
       " (0.9054974025338143, 0.0),\n",
       " (0.9054375595039656, 0.0),\n",
       " (0.9054128983220232, 1.0),\n",
       " (0.9053275288231191, 0.0),\n",
       " (0.9052449763741799, 0.0),\n",
       " (0.9051806914616524, 1.0),\n",
       " (0.9050572112728691, 0.0),\n",
       " (0.9049177051634549, 0.0),\n",
       " (0.9045680686892996, 0.0),\n",
       " (0.9035827872293577, 0.0),\n",
       " (0.9033950212429502, 0.0),\n",
       " (0.9033511182381694, 0.0),\n",
       " (0.9033412424664861, 0.0),\n",
       " (0.9033338813916213, 0.0),\n",
       " (0.9031621784005849, 0.0),\n",
       " (0.9028618559841729, 0.0),\n",
       " (0.9028584652630546, 0.0),\n",
       " (0.9023924516512003, 0.0),\n",
       " (0.9022354433506289, 0.0),\n",
       " (0.9021627464136684, 0.0),\n",
       " (0.9021260710148093, 0.0),\n",
       " (0.9017900288287766, 0.0),\n",
       " (0.9016068396574202, 0.0),\n",
       " (0.9015382713840108, 0.0),\n",
       " (0.9013726830733585, 0.0),\n",
       " (0.9013363942547641, 1.0),\n",
       " (0.9013014315162955, 0.0),\n",
       " (0.9012664761409184, 0.0),\n",
       " (0.9011733342132421, 0.0),\n",
       " (0.9008980609515828, 0.0),\n",
       " (0.9006374952956843, 0.0),\n",
       " (0.9005640767786636, 1.0),\n",
       " (0.9000672252683137, 0.0),\n",
       " (0.8997179376274157, 0.0),\n",
       " (0.8993453386128617, 0.0),\n",
       " (0.8992615421390059, 0.0),\n",
       " (0.8990428201843366, 0.0),\n",
       " (0.8988713345627599, 0.0),\n",
       " (0.8984270097064714, 0.0),\n",
       " (0.8977629360187731, 0.0),\n",
       " (0.8976321277101003, 0.0),\n",
       " (0.8975678178954044, 0.0),\n",
       " (0.8974349512978921, 0.0),\n",
       " (0.8974202926844149, 0.0),\n",
       " (0.8973843128042043, 0.0),\n",
       " (0.8968863313588666, 0.0),\n",
       " (0.8967597692764453, 0.0),\n",
       " (0.8960982038531609, 0.0),\n",
       " (0.8960155093306933, 0.0),\n",
       " (0.8958892627059605, 0.0),\n",
       " (0.8958456509244995, 0.0),\n",
       " (0.8958018743220202, 0.0),\n",
       " (0.8957320750803505, 0.0),\n",
       " (0.8955387943719589, 0.0),\n",
       " (0.8954204517988503, 0.0),\n",
       " (0.8954048309874698, 0.0),\n",
       " (0.8949735829605124, 0.0),\n",
       " (0.8943964660771422, 0.0),\n",
       " (0.8943033788995435, 0.0),\n",
       " (0.8938214408204573, 0.0),\n",
       " (0.8938116993583795, 0.0),\n",
       " (0.8937957124217831, 0.0),\n",
       " (0.8935890162857266, 1.0),\n",
       " (0.8935473473671163, 0.0),\n",
       " (0.8934497589510918, 0.0),\n",
       " (0.893385684621097, 0.0),\n",
       " (0.8933575976413916, 0.0),\n",
       " (0.8932467505201573, 0.0),\n",
       " (0.8931675660538949, 0.0),\n",
       " (0.8927605526377805, 0.0),\n",
       " (0.8926538275978669, 0.0),\n",
       " (0.8926352417905415, 0.0),\n",
       " (0.8925443688633398, 0.0),\n",
       " (0.8923488197794687, 0.0),\n",
       " (0.8920282890771425, 0.0),\n",
       " (0.8920017423464801, 0.0),\n",
       " (0.8918602081229992, 0.0),\n",
       " (0.8917787212004382, 1.0),\n",
       " (0.8917182496422976, 0.0),\n",
       " (0.8914634100881917, 0.0),\n",
       " (0.8914164489616921, 0.0),\n",
       " (0.8907359170077286, 0.0),\n",
       " (0.8907348840027441, 0.0),\n",
       " (0.8904560760327553, 0.0),\n",
       " (0.8904124411465222, 0.0),\n",
       " (0.8903876122831229, 0.0),\n",
       " (0.8901267719363494, 0.0),\n",
       " (0.8897947363109379, 0.0),\n",
       " (0.889762438309338, 0.0),\n",
       " (0.8896172081605183, 0.0),\n",
       " (0.8895012834025932, 0.0),\n",
       " (0.8894366490174078, 0.0),\n",
       " (0.8893996137785785, 0.0),\n",
       " (0.8893550272355392, 0.0),\n",
       " (0.8893400842004034, 0.0),\n",
       " (0.8886132277634148, 0.0),\n",
       " (0.888491763614442, 0.0),\n",
       " (0.8884395671912507, 0.0),\n",
       " (0.8882609699863772, 0.0),\n",
       " (0.8876295510797064, 0.0),\n",
       " (0.8874738868470933, 0.0),\n",
       " (0.8872703373763706, 0.0),\n",
       " (0.887189631313046, 0.0),\n",
       " (0.8871290467660442, 0.0),\n",
       " (0.8869102972380891, 0.0),\n",
       " (0.886902410750383, 0.0),\n",
       " (0.8867769932712832, 0.0),\n",
       " (0.886405807856025, 0.0),\n",
       " (0.8863452341061561, 0.0),\n",
       " (0.88608710792716, 1.0),\n",
       " (0.885759804354169, 0.0),\n",
       " (0.8852662552106013, 0.0),\n",
       " (0.8851792194371029, 1.0),\n",
       " (0.8851450272536295, 0.0),\n",
       " (0.8850772963612984, 0.0),\n",
       " (0.8848775101269671, 0.0),\n",
       " (0.8848600484214786, 0.0),\n",
       " (0.8846232375627886, 0.0),\n",
       " (0.8846155360453011, 1.0),\n",
       " (0.8845516842468648, 0.0),\n",
       " (0.8843724886831994, 0.0),\n",
       " (0.8841532227552918, 1.0),\n",
       " (0.8837136683325544, 0.0),\n",
       " (0.8834867963238286, 0.0),\n",
       " (0.8831876875032206, 0.0),\n",
       " (0.8831097164331134, 0.0),\n",
       " (0.882772223573825, 0.0),\n",
       " (0.8826430121567072, 0.0),\n",
       " (0.8825633563814269, 0.0),\n",
       " (0.8825316645336165, 0.0),\n",
       " (0.8821326958748636, 0.0),\n",
       " (0.8817719321243418, 0.0),\n",
       " (0.8815373035835204, 0.0),\n",
       " (0.8814008526608542, 0.0),\n",
       " (0.8812969438884726, 0.0),\n",
       " (0.8804223221254822, 1.0),\n",
       " (0.8804072536655472, 0.0),\n",
       " (0.8803487077190374, 0.0),\n",
       " (0.880342883841035, 0.0),\n",
       " (0.8800671072424224, 0.0),\n",
       " (0.8798295007242436, 0.0),\n",
       " (0.8797635462613089, 0.0),\n",
       " (0.8796526423956762, 1.0),\n",
       " (0.8794579346563963, 0.0),\n",
       " (0.8792915768761901, 0.0),\n",
       " (0.8790649933051171, 0.0),\n",
       " (0.8788269040765768, 0.0),\n",
       " (0.878364105488601, 0.0),\n",
       " (0.8782535046243414, 0.0),\n",
       " (0.8779024573911922, 0.0),\n",
       " (0.8776308733009799, 0.0),\n",
       " (0.8774396074868017, 0.0),\n",
       " (0.8772570624817647, 0.0),\n",
       " (0.8768932955213641, 0.0),\n",
       " (0.8768324421282695, 0.0),\n",
       " (0.8768135857520475, 0.0),\n",
       " (0.8766413792688298, 0.0),\n",
       " (0.8765582336999025, 0.0),\n",
       " (0.8765272810265835, 0.0),\n",
       " (0.8765092694552608, 0.0),\n",
       " (0.8764155283899495, 0.0),\n",
       " (0.8761590814934721, 0.0),\n",
       " (0.8756625862595322, 0.0),\n",
       " (0.8753020995535554, 0.0),\n",
       " (0.8742584662617358, 0.0),\n",
       " (0.8741295540332502, 0.0),\n",
       " (0.8740533999354382, 0.0),\n",
       " (0.8740211026360132, 0.0),\n",
       " (0.8740110667951839, 0.0),\n",
       " (0.8738310859153555, 0.0),\n",
       " (0.8737911994082517, 0.0),\n",
       " (0.8736527303003158, 1.0),\n",
       " (0.873620446808141, 0.0),\n",
       " (0.8734670430604307, 0.0),\n",
       " (0.8732925852254182, 0.0),\n",
       " (0.8727394027693299, 0.0),\n",
       " (0.8725962606768927, 0.0),\n",
       " (0.8724200230692464, 0.0),\n",
       " (0.8721766966728078, 0.0),\n",
       " (0.8721595600474038, 0.0),\n",
       " (0.8718049224694471, 0.0),\n",
       " (0.8716780294793024, 0.0),\n",
       " (0.871229084662885, 0.0),\n",
       " (0.8709414483394943, 0.0),\n",
       " (0.8708061750729336, 0.0),\n",
       " (0.8706015116054154, 0.0),\n",
       " (0.8704849134079742, 0.0),\n",
       " (0.8700757832134776, 1.0),\n",
       " (0.8697283831188105, 0.0),\n",
       " (0.8694043496552772, 0.0),\n",
       " (0.8693213527731107, 0.0),\n",
       " (0.8691793527460956, 0.0),\n",
       " (0.8690050050887392, 0.0),\n",
       " (0.868677500520647, 0.0),\n",
       " (0.8686295853308309, 0.0),\n",
       " (0.8676681552118417, 1.0),\n",
       " (0.8675848713243718, 0.0),\n",
       " (0.8675769848249001, 0.0),\n",
       " (0.8675532538180436, 0.0),\n",
       " (0.8673616155704343, 0.0),\n",
       " (0.8672381050206246, 0.0),\n",
       " (0.8671314998141658, 0.0),\n",
       " (0.8669772268894891, 0.0),\n",
       " (0.8668445962295035, 0.0),\n",
       " (0.8664678763365509, 0.0),\n",
       " (0.866454410402012, 0.0),\n",
       " (0.8661066963713093, 0.0),\n",
       " (0.8660690016994648, 0.0),\n",
       " (0.8659754151677882, 0.0),\n",
       " (0.8657373109910173, 0.0),\n",
       " (0.865434230688457, 0.0),\n",
       " (0.8653084444032565, 0.0),\n",
       " (0.8648497356947599, 0.0),\n",
       " (0.8647945328306978, 0.0),\n",
       " (0.8646987444547015, 0.0),\n",
       " (0.8642358729028053, 1.0),\n",
       " (0.8641717618918813, 1.0),\n",
       " (0.8640500155519788, 0.0),\n",
       " (0.8639743178238424, 0.0),\n",
       " (0.8634221392667492, 0.0),\n",
       " (0.86335250185806, 0.0),\n",
       " (0.8629998943004306, 0.0),\n",
       " (0.8624704547326447, 0.0),\n",
       " (0.8617820538832613, 0.0),\n",
       " (0.8616286063221679, 0.0),\n",
       " (0.8616252207662114, 0.0),\n",
       " (0.8613099441564698, 0.0),\n",
       " (0.8612097195493796, 0.0),\n",
       " (0.861109115283726, 0.0),\n",
       " (0.8601635170957006, 0.0),\n",
       " (0.8600210299330817, 0.0),\n",
       " (0.8600205653097387, 0.0),\n",
       " (0.8596583556309928, 0.0),\n",
       " (0.8593954983746506, 0.0),\n",
       " (0.8593741165272416, 0.0),\n",
       " (0.8593401716045447, 0.0),\n",
       " (0.8592496312285055, 0.0),\n",
       " (0.8591507923851187, 0.0),\n",
       " (0.8591445731497585, 0.0),\n",
       " (0.8590718654070391, 0.0),\n",
       " (0.8590426323856926, 0.0),\n",
       " (0.8587799464041062, 0.0),\n",
       " (0.8586493312701602, 0.0),\n",
       " (0.8583982096335196, 1.0),\n",
       " (0.8576208637888016, 0.0),\n",
       " (0.8574569595141802, 0.0),\n",
       " (0.8573758889859924, 0.0),\n",
       " (0.857344638395613, 0.0),\n",
       " (0.8573425556661775, 0.0),\n",
       " (0.857318371414263, 0.0),\n",
       " (0.8570850390213716, 0.0),\n",
       " (0.8570560403059032, 0.0),\n",
       " (0.857035580046367, 0.0),\n",
       " (0.8569173091560529, 0.0),\n",
       " (0.8568581618205957, 0.0),\n",
       " (0.8568213545863493, 0.0),\n",
       " (0.8568124270693781, 0.0),\n",
       " (0.8567088017118155, 1.0),\n",
       " (0.8564269534339356, 0.0),\n",
       " (0.8563987065878367, 0.0),\n",
       " (0.8562768390594038, 0.0),\n",
       " (0.8562587174298545, 1.0),\n",
       " (0.8560468155397954, 0.0),\n",
       " (0.8559785926435394, 0.0),\n",
       " (0.8558670521260185, 0.0),\n",
       " (0.8557888399824374, 0.0),\n",
       " (0.8556254483668619, 0.0),\n",
       " (0.8552383759919873, 0.0),\n",
       " (0.8552059256076328, 0.0),\n",
       " (0.855077080516525, 0.0),\n",
       " (0.8550647860921768, 0.0),\n",
       " (0.8548148772414934, 0.0),\n",
       " (0.8546714105815458, 0.0),\n",
       " (0.8546202435126948, 0.0),\n",
       " (0.8545060605176474, 0.0),\n",
       " (0.8544116621832782, 0.0),\n",
       " (0.8543942338938829, 0.0),\n",
       " (0.8543357658849521, 0.0),\n",
       " (0.8541670935241642, 0.0),\n",
       " (0.8541001160173263, 0.0),\n",
       " (0.8540970577615495, 0.0),\n",
       " (0.853910502045639, 0.0),\n",
       " (0.8536575141798501, 0.0),\n",
       " (0.8534001863378884, 0.0),\n",
       " (0.8533228046441294, 0.0),\n",
       " (0.8533126566989934, 0.0),\n",
       " (0.8532133685263629, 0.0),\n",
       " (0.8525098976064411, 0.0),\n",
       " (0.8519777406832386, 0.0),\n",
       " (0.8519443200544172, 1.0),\n",
       " (0.8516792754886334, 0.0),\n",
       " (0.8516105524851625, 0.0),\n",
       " (0.8516063161272986, 0.0),\n",
       " (0.8512640019631088, 0.0),\n",
       " (0.8512178757470424, 0.0),\n",
       " (0.8511118613062261, 0.0),\n",
       " (0.850933110180296, 0.0),\n",
       " (0.850349855575232, 1.0),\n",
       " (0.850343681131793, 1.0),\n",
       " (0.8500505403432116, 0.0),\n",
       " (0.8498781979848405, 0.0),\n",
       " (0.8497760835599991, 0.0),\n",
       " (0.8497535673770937, 0.0),\n",
       " (0.8496204152299872, 0.0),\n",
       " (0.849539611248653, 0.0),\n",
       " (0.8492217060736251, 0.0),\n",
       " (0.8486031669496464, 0.0),\n",
       " (0.8482606246885649, 0.0),\n",
       " (0.8475738058616401, 0.0),\n",
       " (0.8466685395029928, 0.0),\n",
       " (0.846571474240088, 0.0),\n",
       " (0.8465352080567817, 0.0),\n",
       " (0.8464720010957282, 0.0),\n",
       " (0.8463658335747599, 0.0),\n",
       " (0.8462946258921412, 0.0),\n",
       " (0.8461905407979475, 0.0),\n",
       " (0.8461902172794543, 0.0),\n",
       " (0.8461372433722082, 0.0),\n",
       " (0.8459470333710919, 0.0),\n",
       " (0.8457346044141091, 0.0),\n",
       " (0.8455434365391877, 0.0),\n",
       " (0.8454571848565166, 0.0),\n",
       " (0.8454162665832253, 0.0),\n",
       " (0.8450298884025447, 0.0),\n",
       " (0.8450165497434956, 0.0),\n",
       " (0.8449667343035177, 0.0),\n",
       " (0.8448151704304451, 0.0),\n",
       " (0.8444161123553683, 0.0),\n",
       " (0.8439409197475142, 0.0),\n",
       " (0.8438738901935309, 0.0),\n",
       " (0.843708584961998, 0.0),\n",
       " (0.8436074714353373, 0.0),\n",
       " (0.8434885080305952, 0.0),\n",
       " (0.8432623843801378, 0.0),\n",
       " (0.8430796845107235, 0.0),\n",
       " (0.8430538341538864, 0.0),\n",
       " (0.8430286741629126, 0.0),\n",
       " (0.8425340081287082, 0.0),\n",
       " (0.8421317821712115, 0.0),\n",
       " (0.841966753882665, 0.0),\n",
       " (0.8418562460988765, 0.0),\n",
       " (0.8415528017768615, 0.0),\n",
       " (0.8415021431690236, 0.0),\n",
       " (0.8412817108996142, 0.0),\n",
       " (0.8410943450042401, 0.0),\n",
       " (0.8410872491315141, 0.0),\n",
       " (0.8409473509810168, 0.0),\n",
       " (0.8407979790614755, 0.0),\n",
       " (0.8405442969377283, 0.0),\n",
       " (0.8404611932216542, 0.0),\n",
       " (0.8399318082916939, 0.0),\n",
       " (0.8397175572494818, 0.0),\n",
       " (0.8394400614800775, 0.0),\n",
       " (0.839436299023942, 0.0),\n",
       " (0.8392734285328214, 0.0),\n",
       " (0.8392332137874013, 0.0),\n",
       " (0.8391145830157931, 0.0),\n",
       " (0.8388554982889246, 0.0),\n",
       " (0.8388420970618239, 0.0),\n",
       " (0.8386334807171112, 0.0),\n",
       " (0.8385635327351951, 0.0),\n",
       " (0.8378835467404635, 0.0),\n",
       " (0.8378403712301782, 0.0),\n",
       " (0.837811332587955, 0.0),\n",
       " (0.8378042438776613, 0.0),\n",
       " (0.8377857718975639, 0.0),\n",
       " (0.837478117559679, 0.0),\n",
       " (0.8374278119395726, 0.0),\n",
       " (0.8369287654161903, 0.0),\n",
       " (0.8364899061662217, 1.0),\n",
       " (0.8362645894227235, 0.0),\n",
       " (0.8361778508297547, 0.0),\n",
       " (0.8359435797580925, 0.0),\n",
       " (0.8357747882683958, 0.0),\n",
       " (0.8357542644193063, 0.0),\n",
       " (0.8355998679548429, 0.0),\n",
       " (0.8355721031942166, 1.0),\n",
       " (0.8352323260905836, 0.0),\n",
       " (0.8350024379302159, 0.0),\n",
       " (0.8349146677128657, 0.0),\n",
       " (0.8348733977891316, 0.0),\n",
       " (0.8344903370223088, 0.0),\n",
       " (0.8342075259436753, 0.0),\n",
       " (0.8340656787167657, 0.0),\n",
       " (0.8338849552221077, 0.0),\n",
       " (0.8338192652555662, 0.0),\n",
       " (0.8337942842698383, 0.0),\n",
       " (0.8337064149020974, 0.0),\n",
       " (0.8336266249421151, 0.0),\n",
       " (0.8335719420583335, 0.0),\n",
       " (0.833487397173509, 0.0),\n",
       " (0.8333273652408084, 1.0),\n",
       " (0.83319454712905, 0.0),\n",
       " (0.833081319451858, 0.0),\n",
       " (0.8330429303402455, 0.0),\n",
       " (0.832925550678116, 0.0),\n",
       " (0.8327550801217769, 0.0),\n",
       " (0.832380863308913, 1.0),\n",
       " (0.8322732475454394, 0.0),\n",
       " (0.8322327820320149, 0.0),\n",
       " (0.8320982450340666, 0.0),\n",
       " (0.8320211289344205, 0.0),\n",
       " (0.8317207529800217, 0.0),\n",
       " (0.8315286394901311, 0.0),\n",
       " (0.8312470408507945, 0.0),\n",
       " (0.8311685598181361, 0.0),\n",
       " (0.8310142758953201, 0.0),\n",
       " (0.8310097659489472, 0.0),\n",
       " (0.830831577281146, 0.0),\n",
       " (0.8306070575236364, 0.0),\n",
       " (0.8305437529131579, 0.0),\n",
       " (0.8301790961355647, 0.0),\n",
       " (0.8300137793665262, 0.0),\n",
       " (0.8298380242474709, 0.0),\n",
       " (0.8298056832159445, 0.0),\n",
       " (0.8295701281453828, 0.0),\n",
       " (0.8294835770208866, 0.0),\n",
       " (0.8294402860439284, 0.0),\n",
       " (0.8294221876078696, 0.0),\n",
       " (0.8291577212574731, 0.0),\n",
       " (0.82898025239722, 0.0),\n",
       " (0.8289725565910505, 0.0),\n",
       " (0.8289527028912571, 0.0),\n",
       " (0.8288586707903579, 0.0),\n",
       " (0.8285692208512654, 0.0),\n",
       " (0.8283355660251089, 0.0),\n",
       " (0.8281179491956663, 0.0),\n",
       " (0.8279216885227323, 0.0),\n",
       " (0.8276215836925179, 0.0),\n",
       " (0.8270757360787534, 0.0),\n",
       " (0.8266666889614144, 0.0),\n",
       " (0.8264228688534591, 0.0),\n",
       " (0.8258662682914606, 0.0),\n",
       " (0.8258459603514376, 0.0),\n",
       " (0.8258204882765852, 0.0),\n",
       " (0.825621772228422, 0.0),\n",
       " (0.8248986339817836, 0.0),\n",
       " (0.8242076802550403, 0.0),\n",
       " (0.8241712194429878, 0.0),\n",
       " (0.8237029364110237, 0.0),\n",
       " (0.8236405818802485, 0.0),\n",
       " (0.8235753161728707, 0.0),\n",
       " (0.8235158702077929, 0.0),\n",
       " (0.8233472232332922, 0.0),\n",
       " (0.8233346904714669, 0.0),\n",
       " (0.8227431970471595, 0.0),\n",
       " (0.8225754903898261, 1.0),\n",
       " (0.8223899793235103, 0.0),\n",
       " (0.8223433338634885, 0.0),\n",
       " (0.8222028266255375, 0.0),\n",
       " (0.8217400422043909, 0.0),\n",
       " (0.8213971928508088, 0.0),\n",
       " (0.8213341810727691, 1.0),\n",
       " (0.821329163099214, 0.0),\n",
       " (0.8210920039122558, 0.0),\n",
       " (0.8210609626327742, 0.0),\n",
       " (0.820856165856273, 0.0),\n",
       " (0.8204359039111196, 0.0),\n",
       " (0.8203798983005013, 0.0),\n",
       " (0.8201631779231069, 0.0),\n",
       " (0.8200481858902078, 0.0),\n",
       " (0.8198325571626519, 0.0),\n",
       " (0.8196502709973164, 0.0),\n",
       " (0.8194892729164086, 0.0),\n",
       " (0.8194240370284755, 1.0),\n",
       " (0.8193744455682693, 0.0),\n",
       " (0.8193430486216964, 0.0),\n",
       " (0.8191049697613395, 0.0),\n",
       " (0.8188986689608877, 1.0),\n",
       " (0.8188683147313975, 0.0),\n",
       " (0.8187934431665999, 0.0),\n",
       " (0.8187552096338581, 0.0),\n",
       " (0.8186104655800126, 0.0),\n",
       " (0.8184518618453787, 0.0),\n",
       " (0.8182809201563577, 0.0),\n",
       " (0.8182365526041152, 0.0),\n",
       " (0.8177048895005489, 0.0),\n",
       " (0.8175501557368056, 0.0),\n",
       " (0.8171341290211762, 0.0),\n",
       " (0.8170730913925526, 0.0),\n",
       " (0.8169336113187907, 0.0),\n",
       " (0.8167771872628473, 0.0),\n",
       " (0.8166205778704458, 0.0),\n",
       " (0.8164527078654207, 0.0),\n",
       " (0.8164139410015723, 0.0),\n",
       " (0.8160629443121616, 0.0),\n",
       " (0.8159800454462912, 0.0),\n",
       " (0.8159026185025892, 0.0),\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BAD</th>\n",
       "      <th>BADRATE</th>\n",
       "      <th>BAD_CNT</th>\n",
       "      <th>BAD_PCTG</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>GOOD_CNT</th>\n",
       "      <th>KS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>0.108</td>\n",
       "      <td>86</td>\n",
       "      <td>0.262</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>0.054</td>\n",
       "      <td>129</td>\n",
       "      <td>0.393</td>\n",
       "      <td>756</td>\n",
       "      <td>1469</td>\n",
       "      <td>0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>0.036</td>\n",
       "      <td>158</td>\n",
       "      <td>0.482</td>\n",
       "      <td>770</td>\n",
       "      <td>2239</td>\n",
       "      <td>0.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0.038</td>\n",
       "      <td>188</td>\n",
       "      <td>0.573</td>\n",
       "      <td>769</td>\n",
       "      <td>3008</td>\n",
       "      <td>0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0.028</td>\n",
       "      <td>210</td>\n",
       "      <td>0.640</td>\n",
       "      <td>777</td>\n",
       "      <td>3785</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>0.023</td>\n",
       "      <td>228</td>\n",
       "      <td>0.695</td>\n",
       "      <td>781</td>\n",
       "      <td>4566</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>0.023</td>\n",
       "      <td>246</td>\n",
       "      <td>0.750</td>\n",
       "      <td>781</td>\n",
       "      <td>5347</td>\n",
       "      <td>0.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>0.016</td>\n",
       "      <td>259</td>\n",
       "      <td>0.790</td>\n",
       "      <td>786</td>\n",
       "      <td>6133</td>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>0.020</td>\n",
       "      <td>275</td>\n",
       "      <td>0.838</td>\n",
       "      <td>783</td>\n",
       "      <td>6916</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>280</td>\n",
       "      <td>0.854</td>\n",
       "      <td>794</td>\n",
       "      <td>7710</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>0.009</td>\n",
       "      <td>287</td>\n",
       "      <td>0.875</td>\n",
       "      <td>792</td>\n",
       "      <td>8502</td>\n",
       "      <td>0.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003</td>\n",
       "      <td>289</td>\n",
       "      <td>0.881</td>\n",
       "      <td>797</td>\n",
       "      <td>9299</td>\n",
       "      <td>0.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0.009</td>\n",
       "      <td>296</td>\n",
       "      <td>0.902</td>\n",
       "      <td>792</td>\n",
       "      <td>10091</td>\n",
       "      <td>0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>0.008</td>\n",
       "      <td>302</td>\n",
       "      <td>0.921</td>\n",
       "      <td>793</td>\n",
       "      <td>10884</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11</td>\n",
       "      <td>0.014</td>\n",
       "      <td>313</td>\n",
       "      <td>0.954</td>\n",
       "      <td>788</td>\n",
       "      <td>11672</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>0.010</td>\n",
       "      <td>321</td>\n",
       "      <td>0.979</td>\n",
       "      <td>791</td>\n",
       "      <td>12463</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003</td>\n",
       "      <td>323</td>\n",
       "      <td>0.985</td>\n",
       "      <td>797</td>\n",
       "      <td>13260</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003</td>\n",
       "      <td>325</td>\n",
       "      <td>0.991</td>\n",
       "      <td>797</td>\n",
       "      <td>14057</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>326</td>\n",
       "      <td>0.994</td>\n",
       "      <td>798</td>\n",
       "      <td>14855</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>0.003</td>\n",
       "      <td>328</td>\n",
       "      <td>1.000</td>\n",
       "      <td>792</td>\n",
       "      <td>15647</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BAD  BADRATE  BAD_CNT  BAD_PCTG  GOOD  GOOD_CNT     KS\n",
       "0    86    0.108       86     0.262   713       713  0.217\n",
       "1    43    0.054      129     0.393   756      1469  0.299\n",
       "2    29    0.036      158     0.482   770      2239  0.339\n",
       "3    30    0.038      188     0.573   769      3008  0.381\n",
       "4    22    0.028      210     0.640   777      3785  0.398\n",
       "5    18    0.023      228     0.695   781      4566  0.403\n",
       "6    18    0.023      246     0.750   781      5347  0.408\n",
       "7    13    0.016      259     0.790   786      6133  0.398\n",
       "8    16    0.020      275     0.838   783      6916  0.396\n",
       "9     5    0.006      280     0.854   794      7710  0.361\n",
       "10    7    0.009      287     0.875   792      8502  0.332\n",
       "11    2    0.003      289     0.881   797      9299  0.287\n",
       "12    7    0.009      296     0.902   792     10091  0.258\n",
       "13    6    0.008      302     0.921   793     10884  0.225\n",
       "14   11    0.014      313     0.954   788     11672  0.208\n",
       "15    8    0.010      321     0.979   791     12463  0.182\n",
       "16    2    0.003      323     0.985   797     13260  0.137\n",
       "17    2    0.003      325     0.991   797     14057  0.092\n",
       "18    1    0.001      326     0.994   798     14855  0.045\n",
       "19    2    0.003      328     1.000   792     15647  0.000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#生成报告\n",
    "model = lr_model\n",
    "row_num, col_num = 0, 0\n",
    "bins = 20 #分20箱\n",
    "Y_predict = [s[1] for s in model.predict_proba(val_x)]\n",
    "Y = val_y\n",
    "nrows = Y.shape[0]\n",
    "lis = [(Y_predict[i], Y[i]) for i in range(nrows)]\n",
    "ks_lis = sorted(lis, key=lambda x: x[0], reverse=True)\n",
    "bin_num = int(nrows/bins+1)# 计算每组有多少条数据\n",
    "bad = sum([1 for (p, y) in ks_lis if y > 0.5]) # 计算逾期人数\n",
    "good = sum([1 for (p, y) in ks_lis if y <= 0.5])   # 计算好人的人数\n",
    "bad_cnt, good_cnt = 0, 0     # 累计坏人人数 ，累计好人的人数\n",
    "KS = []\n",
    "BAD = []\n",
    "GOOD = []\n",
    "BAD_CNT = []\n",
    "GOOD_CNT = []\n",
    "BAD_PCTG = []\n",
    "BADRATE = []\n",
    "dct_report = {}\n",
    "for j in range(bins):\n",
    "    ds = ks_lis[j*bin_num: min((j+1)*bin_num, nrows)]\n",
    "    bad1 = sum([1 for (p, y) in ds if y > 0.5])\n",
    "    good1 = sum([1 for (p, y) in ds if y <= 0.5])\n",
    "    bad_cnt += bad1\n",
    "    good_cnt += good1\n",
    "    bad_pctg = round(bad_cnt/sum(val_y),3)  # 一箱一箱累加 到这一箱一共有多少逾期 占所有逾期的比例\n",
    "    badrate = round(bad1/(bad1+good1),3)  # 一箱一箱累加 到这一箱一共有多少逾期占所有人的比例\n",
    "    ks = round(math.fabs((bad_cnt / bad) - (good_cnt / good)),3) # 计算KS值\n",
    "    KS.append(ks)\n",
    "    BAD.append(bad1)\n",
    "    GOOD.append(good1)\n",
    "    BAD_CNT.append(bad_cnt)\n",
    "    GOOD_CNT.append(good_cnt)\n",
    "    BAD_PCTG.append(bad_pctg)\n",
    "    BADRATE.append(badrate)\n",
    "    dct_report['KS'] = KS\n",
    "    dct_report['BAD'] = BAD\n",
    "    dct_report['GOOD'] = GOOD\n",
    "    dct_report['BAD_CNT'] = BAD_CNT\n",
    "    dct_report['GOOD_CNT'] = GOOD_CNT\n",
    "    dct_report['BAD_PCTG'] = BAD_PCTG\n",
    "    dct_report['BADRATE'] = BADRATE\n",
    "val_repot = pd.DataFrame(dct_report)\n",
    "val_repot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(val_repot.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "    require.config({\n",
       "        paths: {\n",
       "            'echarts':'https://assets.pyecharts.org/assets/echarts.min'\n",
       "        }\n",
       "    });\n",
       "</script>\n",
       "\n",
       "        <div id=\"196e0432649646c3992005a4f4d03807\" style=\"width:900px; height:500px;\"></div>\n",
       "\n",
       "<script>\n",
       "        require(['echarts'], function(echarts) {\n",
       "                var chart_196e0432649646c3992005a4f4d03807 = echarts.init(\n",
       "                    document.getElementById('196e0432649646c3992005a4f4d03807'), 'white', {renderer: 'canvas'});\n",
       "                var option_196e0432649646c3992005a4f4d03807 = {\n",
       "    \"animation\": true,\n",
       "    \"animationThreshold\": 2000,\n",
       "    \"animationDuration\": 1000,\n",
       "    \"animationEasing\": \"cubicOut\",\n",
       "    \"animationDelay\": 0,\n",
       "    \"animationDurationUpdate\": 300,\n",
       "    \"animationEasingUpdate\": \"cubicOut\",\n",
       "    \"animationDelayUpdate\": 0,\n",
       "    \"color\": [\n",
       "        \"blue\",\n",
       "        \"red\",\n",
       "        \"#c23531\",\n",
       "        \"#2f4554\",\n",
       "        \"#61a0a8\",\n",
       "        \"#d48265\",\n",
       "        \"#749f83\",\n",
       "        \"#ca8622\",\n",
       "        \"#bda29a\",\n",
       "        \"#6e7074\",\n",
       "        \"#546570\",\n",
       "        \"#c4ccd3\",\n",
       "        \"#f05b72\",\n",
       "        \"#ef5b9c\",\n",
       "        \"#f47920\",\n",
       "        \"#905a3d\",\n",
       "        \"#fab27b\",\n",
       "        \"#2a5caa\",\n",
       "        \"#444693\",\n",
       "        \"#726930\",\n",
       "        \"#b2d235\",\n",
       "        \"#6d8346\",\n",
       "        \"#ac6767\",\n",
       "        \"#1d953f\",\n",
       "        \"#6950a1\",\n",
       "        \"#918597\"\n",
       "    ],\n",
       "    \"series\": [\n",
       "        {\n",
       "            \"type\": \"line\",\n",
       "            \"name\": \"\\u5206\\u7ec4\\u574f\\u4eba\\u5360\\u6bd4\",\n",
       "            \"connectNulls\": false,\n",
       "            \"yAxisIndex\": 0,\n",
       "            \"symbolSize\": 4,\n",
       "            \"showSymbol\": true,\n",
       "            \"smooth\": false,\n",
       "            \"step\": false,\n",
       "            \"data\": [\n",
       "                [\n",
       "                    0,\n",
       "                    0.108\n",
       "                ],\n",
       "                [\n",
       "                    1,\n",
       "                    0.054\n",
       "                ],\n",
       "                [\n",
       "                    2,\n",
       "                    0.036\n",
       "                ],\n",
       "                [\n",
       "                    3,\n",
       "                    0.038\n",
       "                ],\n",
       "                [\n",
       "                    4,\n",
       "                    0.028\n",
       "                ],\n",
       "                [\n",
       "                    5,\n",
       "                    0.023\n",
       "                ],\n",
       "                [\n",
       "                    6,\n",
       "                    0.023\n",
       "                ],\n",
       "                [\n",
       "                    7,\n",
       "                    0.016\n",
       "                ],\n",
       "                [\n",
       "                    8,\n",
       "                    0.02\n",
       "                ],\n",
       "                [\n",
       "                    9,\n",
       "                    0.006\n",
       "                ],\n",
       "                [\n",
       "                    10,\n",
       "                    0.009\n",
       "                ],\n",
       "                [\n",
       "                    11,\n",
       "                    0.003\n",
       "                ],\n",
       "                [\n",
       "                    12,\n",
       "                    0.009\n",
       "                ],\n",
       "                [\n",
       "                    13,\n",
       "                    0.008\n",
       "                ],\n",
       "                [\n",
       "                    14,\n",
       "                    0.014\n",
       "                ],\n",
       "                [\n",
       "                    15,\n",
       "                    0.01\n",
       "                ],\n",
       "                [\n",
       "                    16,\n",
       "                    0.003\n",
       "                ],\n",
       "                [\n",
       "                    17,\n",
       "                    0.003\n",
       "                ],\n",
       "                [\n",
       "                    18,\n",
       "                    0.001\n",
       "                ],\n",
       "                [\n",
       "                    19,\n",
       "                    0.003\n",
       "                ]\n",
       "            ],\n",
       "            \"hoverAnimation\": true,\n",
       "            \"label\": {\n",
       "                \"show\": true,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8\n",
       "            },\n",
       "            \"lineStyle\": {\n",
       "                \"width\": 1,\n",
       "                \"opacity\": 1,\n",
       "                \"curveness\": 0,\n",
       "                \"type\": \"solid\"\n",
       "            },\n",
       "            \"areaStyle\": {\n",
       "                \"opacity\": 0\n",
       "            }\n",
       "        },\n",
       "        {\n",
       "            \"type\": \"line\",\n",
       "            \"name\": \"KS\",\n",
       "            \"connectNulls\": false,\n",
       "            \"yAxisIndex\": 1,\n",
       "            \"symbolSize\": 4,\n",
       "            \"showSymbol\": true,\n",
       "            \"smooth\": false,\n",
       "            \"step\": false,\n",
       "            \"data\": [\n",
       "                [\n",
       "                    0,\n",
       "                    0.217\n",
       "                ],\n",
       "                [\n",
       "                    1,\n",
       "                    0.299\n",
       "                ],\n",
       "                [\n",
       "                    2,\n",
       "                    0.339\n",
       "                ],\n",
       "                [\n",
       "                    3,\n",
       "                    0.381\n",
       "                ],\n",
       "                [\n",
       "                    4,\n",
       "                    0.398\n",
       "                ],\n",
       "                [\n",
       "                    5,\n",
       "                    0.403\n",
       "                ],\n",
       "                [\n",
       "                    6,\n",
       "                    0.408\n",
       "                ],\n",
       "                [\n",
       "                    7,\n",
       "                    0.398\n",
       "                ],\n",
       "                [\n",
       "                    8,\n",
       "                    0.396\n",
       "                ],\n",
       "                [\n",
       "                    9,\n",
       "                    0.361\n",
       "                ],\n",
       "                [\n",
       "                    10,\n",
       "                    0.332\n",
       "                ],\n",
       "                [\n",
       "                    11,\n",
       "                    0.287\n",
       "                ],\n",
       "                [\n",
       "                    12,\n",
       "                    0.258\n",
       "                ],\n",
       "                [\n",
       "                    13,\n",
       "                    0.225\n",
       "                ],\n",
       "                [\n",
       "                    14,\n",
       "                    0.208\n",
       "                ],\n",
       "                [\n",
       "                    15,\n",
       "                    0.182\n",
       "                ],\n",
       "                [\n",
       "                    16,\n",
       "                    0.137\n",
       "                ],\n",
       "                [\n",
       "                    17,\n",
       "                    0.092\n",
       "                ],\n",
       "                [\n",
       "                    18,\n",
       "                    0.045\n",
       "                ],\n",
       "                [\n",
       "                    19,\n",
       "                    0.0\n",
       "                ]\n",
       "            ],\n",
       "            \"hoverAnimation\": true,\n",
       "            \"label\": {\n",
       "                \"show\": false,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8\n",
       "            },\n",
       "            \"lineStyle\": {\n",
       "                \"width\": 1,\n",
       "                \"opacity\": 1,\n",
       "                \"curveness\": 0,\n",
       "                \"type\": \"solid\"\n",
       "            },\n",
       "            \"areaStyle\": {\n",
       "                \"opacity\": 0\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"legend\": [\n",
       "        {\n",
       "            \"data\": [\n",
       "                \"\\u5206\\u7ec4\\u574f\\u4eba\\u5360\\u6bd4\",\n",
       "                \"KS\"\n",
       "            ],\n",
       "            \"selected\": {\n",
       "                \"\\u5206\\u7ec4\\u574f\\u4eba\\u5360\\u6bd4\": true,\n",
       "                \"KS\": true\n",
       "            },\n",
       "            \"show\": true,\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10,\n",
       "            \"itemWidth\": 25,\n",
       "            \"itemHeight\": 14\n",
       "        }\n",
       "    ],\n",
       "    \"tooltip\": {\n",
       "        \"show\": true,\n",
       "        \"trigger\": \"item\",\n",
       "        \"triggerOn\": \"mousemove|click\",\n",
       "        \"axisPointer\": {\n",
       "            \"type\": \"line\"\n",
       "        },\n",
       "        \"textStyle\": {\n",
       "            \"fontSize\": 14\n",
       "        },\n",
       "        \"borderWidth\": 0\n",
       "    },\n",
       "    \"xAxis\": [\n",
       "        {\n",
       "            \"show\": true,\n",
       "            \"scale\": false,\n",
       "            \"nameLocation\": \"end\",\n",
       "            \"nameGap\": 15,\n",
       "            \"gridIndex\": 0,\n",
       "            \"inverse\": false,\n",
       "            \"offset\": 0,\n",
       "            \"splitNumber\": 5,\n",
       "            \"minInterval\": 0,\n",
       "            \"splitLine\": {\n",
       "                \"show\": false,\n",
       "                \"lineStyle\": {\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\"\n",
       "                }\n",
       "            },\n",
       "            \"data\": [\n",
       "                0,\n",
       "                1,\n",
       "                2,\n",
       "                3,\n",
       "                4,\n",
       "                5,\n",
       "                6,\n",
       "                7,\n",
       "                8,\n",
       "                9,\n",
       "                10,\n",
       "                11,\n",
       "                12,\n",
       "                13,\n",
       "                14,\n",
       "                15,\n",
       "                16,\n",
       "                17,\n",
       "                18,\n",
       "                19\n",
       "            ]\n",
       "        }\n",
       "    ],\n",
       "    \"yAxis\": [\n",
       "        {\n",
       "            \"show\": true,\n",
       "            \"scale\": false,\n",
       "            \"nameLocation\": \"end\",\n",
       "            \"nameGap\": 15,\n",
       "            \"gridIndex\": 0,\n",
       "            \"inverse\": false,\n",
       "            \"offset\": 0,\n",
       "            \"splitNumber\": 5,\n",
       "            \"minInterval\": 0,\n",
       "            \"splitLine\": {\n",
       "                \"show\": false,\n",
       "                \"lineStyle\": {\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\"\n",
       "                }\n",
       "            }\n",
       "        },\n",
       "        {\n",
       "            \"type\": \"value\",\n",
       "            \"name\": \"\\u7d2f\\u8ba1\\u574f\\u4eba\\u5360\\u6bd4\",\n",
       "            \"show\": true,\n",
       "            \"scale\": false,\n",
       "            \"nameLocation\": \"end\",\n",
       "            \"nameGap\": 15,\n",
       "            \"gridIndex\": 0,\n",
       "            \"axisLine\": {\n",
       "                \"show\": true,\n",
       "                \"onZero\": true,\n",
       "                \"onZeroAxisIndex\": 0,\n",
       "                \"lineStyle\": {\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\",\n",
       "                    \"color\": \"red\"\n",
       "                }\n",
       "            },\n",
       "            \"axisLabel\": {\n",
       "                \"show\": true,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8,\n",
       "                \"formatter\": \"{value}\"\n",
       "            },\n",
       "            \"inverse\": false,\n",
       "            \"position\": \"right\",\n",
       "            \"offset\": 0,\n",
       "            \"splitNumber\": 5,\n",
       "            \"min\": 0,\n",
       "            \"max\": 0.5,\n",
       "            \"minInterval\": 0,\n",
       "            \"splitLine\": {\n",
       "                \"show\": false,\n",
       "                \"lineStyle\": {\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\"\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"title\": [\n",
       "        {\n",
       "            \"text\": \"\\u884c\\u4e3a\\u8bc4\\u5206\\u5361\\u6a21\\u578b\\u8868\\u73b0\"\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "                chart_196e0432649646c3992005a4f4d03807.setOption(option_196e0432649646c3992005a4f4d03807);\n",
       "        });\n",
       "    </script>\n"
      ],
      "text/plain": [
       "<pyecharts.render.display.HTML at 0x1659bf02e80>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyecharts.charts import *\n",
    "from pyecharts import options as opts\n",
    "from pylab import *\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "line = (\n",
    "\n",
    "    Line()\n",
    "    .add_xaxis([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "    .add_yaxis(\n",
    "        \"分组坏人占比\",\n",
    "        list(val_repot.BADRATE),\n",
    "        yaxis_index=0,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"行为评分卡模型表现\"),\n",
    "    )\n",
    "    .extend_axis(\n",
    "        yaxis=opts.AxisOpts(\n",
    "            name=\"累计坏人占比\",\n",
    "            type_=\"value\",\n",
    "            min_=0,\n",
    "            max_=0.5,\n",
    "            position=\"right\",\n",
    "            axisline_opts=opts.AxisLineOpts(\n",
    "                linestyle_opts=opts.LineStyleOpts(color=\"red\")\n",
    "            ),\n",
    "            axislabel_opts=opts.LabelOpts(formatter=\"{value}\"),\n",
    "        )\n",
    "\n",
    "    )\n",
    "    .add_xaxis([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
    "    .add_yaxis(\n",
    "        \"KS\",\n",
    "        list(val_repot['KS']),\n",
    "        yaxis_index=1,\n",
    "        color=\"blue\",\n",
    "        label_opts=opts.LabelOpts(is_show=False),\n",
    "    )\n",
    ")\n",
    "line.render_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('pima-indians-diabetes.csv')\n",
    "train,test = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Dmatrix格式\n",
    "feature_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "target_column = 'Outcome'\n",
    "xgtrain = xgb.DMatrix(train[feature_columns].values,train[target_column].values)\n",
    "xgtest = xgb.DMatrix(test[feature_columns].values,test[target_column].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-error:0.3125\ttrain-error:0.25\n",
      "[1]\teval-error:0.244792\ttrain-error:0.180556\n",
      "[2]\teval-error:0.265625\ttrain-error:0.180556\n",
      "[3]\teval-error:0.229167\ttrain-error:0.149306\n",
      "[4]\teval-error:0.208333\ttrain-error:0.151042\n",
      "[5]\teval-error:0.229167\ttrain-error:0.157986\n",
      "[6]\teval-error:0.1875\ttrain-error:0.15625\n",
      "[7]\teval-error:0.1875\ttrain-error:0.151042\n",
      "[8]\teval-error:0.203125\ttrain-error:0.161458\n",
      "[9]\teval-error:0.203125\ttrain-error:0.154514\n"
     ]
    }
   ],
   "source": [
    "#参数设定\n",
    "param = {'max_depth':5, 'eta':0.1, 'silent':1, 'subsample':0.7, 'colsample_bytree':0.7, 'objective':'binary:logistic' }\n",
    "watchlist = [(xgtest,'eval'),(xgtrain,'train')]\n",
    "num_round = 10\n",
    "bst = xgb.train(param,xgtrain,num_round,watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = xgtest.get_label()\n",
    "preds = bst.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.203125"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for i in range(len(preds)) if int(preds[i]>0.5)!=labels[i])/float(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.save_model('1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误类为0.250000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2.model']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# 用pandas读入数据\n",
    "data = pd.read_csv('Pima-Indians-Diabetes.csv')\n",
    "\n",
    "# 做数据切分\n",
    "train, test = train_test_split(data)\n",
    "\n",
    "# 取出特征X和目标y的部分\n",
    "feature_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
    "target_column = 'Outcome'\n",
    "train_X = train[feature_columns].values\n",
    "train_y = train[target_column].values\n",
    "test_X = test[feature_columns].values\n",
    "test_y = test[target_column].values\n",
    "\n",
    "# 初始化模型\n",
    "xgb_classifier = xgb.XGBClassifier(n_estimators=20,\\\n",
    "                                   max_depth=4, \\\n",
    "                                   learning_rate=0.1, \\\n",
    "                                   subsample=0.7, \\\n",
    "                                   colsample_bytree=0.7)\n",
    "\n",
    "# 拟合模型\n",
    "xgb_classifier.fit(train_X, train_y)\n",
    "# 使用模型预测\n",
    "preds = xgb_classifier.predict(test_X)\n",
    "# 判断准确率\n",
    "print ('错误类为%f' %((preds!=test_y).sum()/float(test_y.shape[0])))\n",
    "# 模型存储\n",
    "joblib.dump(xgb_classifier, '2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数字0和1的二分类问题\n",
      "在2折数据上的交叉验证\n",
      "混淆矩阵:\n",
      "[[87  0]\n",
      " [ 1 92]]\n",
      "混淆矩阵:\n",
      "[[91  0]\n",
      " [ 3 86]]\n",
      "\n",
      "Iris: 多分类\n",
      "在2折数据上的交叉验证\n",
      "混淆矩阵:\n",
      "[[19  0  0]\n",
      " [ 0 31  3]\n",
      " [ 0  1 21]]\n",
      "混淆矩阵:\n",
      "[[31  0  0]\n",
      " [ 0 16  0]\n",
      " [ 0  3 25]]\n",
      "\n",
      "波士顿房价回归预测问题\n",
      "在2折数据上的交叉验证\n",
      "[12:12:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "MSE: 9.862814929045339\n",
      "[12:12:15] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "MSE: 15.989962572880902\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.datasets import load_iris, load_digits, load_boston\n",
    "\n",
    "rng = np.random.RandomState(31337)\n",
    "\n",
    "#二分类：混淆矩阵\n",
    "print(\"数字0和1的二分类问题\")\n",
    "digits = load_digits(2)\n",
    "y = digits['target']\n",
    "X = digits['data']\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=rng)\n",
    "print(\"在2折数据上的交叉验证\")\n",
    "for train_index, test_index in kf.split(X):\n",
    "    xgb_model = xgb.XGBClassifier().fit(X[train_index],y[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    print(\"混淆矩阵:\")\n",
    "    print(confusion_matrix(actuals, predictions))\n",
    "\n",
    "#多分类：混淆矩阵\n",
    "print(\"\\nIris: 多分类\")\n",
    "iris = load_iris()\n",
    "y = iris['target']\n",
    "X = iris['data']\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=rng)\n",
    "print(\"在2折数据上的交叉验证\")\n",
    "for train_index, test_index in kf.split(X):\n",
    "    xgb_model = xgb.XGBClassifier().fit(X[train_index],y[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    print(\"混淆矩阵:\")\n",
    "    print(confusion_matrix(actuals, predictions))\n",
    "\n",
    "#回归问题：MSE\n",
    "print(\"\\n波士顿房价回归预测问题\")\n",
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "X = boston['data']\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=rng)\n",
    "print(\"在2折数据上的交叉验证\")\n",
    "for train_index, test_index in kf.split(X):\n",
    "    xgb_model = xgb.XGBRegressor().fit(X[train_index],y[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    print(\"MSE:\",mean_squared_error(actuals, predictions))  # 均方误差  误差平方 再求平均\n",
    "\n",
    "MSE: 15.989962572880902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:45] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:46] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:47] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "0.5984879606490934\n",
      "{'max_depth': 4, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "y = boston['target']\n",
    "X = boston['data']\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "param_dict = {'max_depth': [2,4,6],\n",
    "              'n_estimators': [50,100,200]}\n",
    "\n",
    "clf = GridSearchCV(xgb_model, param_dict, verbose=1)\n",
    "clf.fit(X,y)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 早停 避免过拟合\n",
    "X = digits['data']\n",
    "y = digits['target']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.999497\n",
      "Will train until validation_0-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.999497\n",
      "[2]\tvalidation_0-auc:0.999497\n",
      "[3]\tvalidation_0-auc:0.999749\n",
      "[4]\tvalidation_0-auc:0.999749\n",
      "[5]\tvalidation_0-auc:0.999749\n",
      "[6]\tvalidation_0-auc:0.999749\n",
      "[7]\tvalidation_0-auc:0.999749\n",
      "[8]\tvalidation_0-auc:0.999749\n",
      "[9]\tvalidation_0-auc:0.999749\n",
      "[10]\tvalidation_0-auc:1\n",
      "[11]\tvalidation_0-auc:1\n",
      "[12]\tvalidation_0-auc:1\n",
      "[13]\tvalidation_0-auc:1\n",
      "[14]\tvalidation_0-auc:1\n",
      "[15]\tvalidation_0-auc:1\n",
      "[16]\tvalidation_0-auc:1\n",
      "[17]\tvalidation_0-auc:1\n",
      "[18]\tvalidation_0-auc:1\n",
      "[19]\tvalidation_0-auc:1\n",
      "[20]\tvalidation_0-auc:1\n",
      "Stopping. Best iteration:\n",
      "[10]\tvalidation_0-auc:1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建xgb分类器\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train,y_train,early_stopping_rounds = 10,eval_metric = 'auc',eval_set = [(X_test,y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "y = iris['target']\n",
    "X = iris['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier().fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = xgb_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征 petal_length 重要度为 0.599222\n",
      "特征 petal_width 重要度为 0.354334\n",
      "特征 sepal_width 重要度为 0.034046\n",
      "特征 sepal_length 重要度为 0.012397\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(feature_importances)[::-1]\n",
    "feature_names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "\n",
    "for index in indices:\n",
    "    print(\"特征 %s 重要度为 %f\" %(feature_names[index], feature_importances[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Bcard.txt')\n",
    "df_train = data[data.obs_mth != '2018-11-30'].reset_index().copy()\n",
    "val = data[data.obs_mth == '2018-11-30'].reset_index().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightGBM跨时间交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据时间对数据进行排序\n",
    "df_train = df_train.sort_values(by='obs_mth',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_list = []\n",
    "for i in range(1,len(df_train)+1):\n",
    "    rank_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把生成的序号 合并到数据中\n",
    "df_train['rank'] = rank_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rank'] = df_train['rank']/len(df_train) # 计算每一条数据 在时间这个维度上 在整个数据集的百分位的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据时间排序的rank值把所有的数据分成5箱\n",
    "pct_lst=[]\n",
    "for x in df_train['rank']:\n",
    "    if x <= 0.2:\n",
    "        x = 1\n",
    "    elif x <= 0.4:\n",
    "        x = 2\n",
    "    elif x <= 0.6:\n",
    "        x = 3\n",
    "    elif x <= 0.8:\n",
    "        x = 4\n",
    "    else:\n",
    "        x = 5\n",
    "    pct_lst.append(x)\n",
    "df_train['rank'] = pct_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>obs_mth</th>\n",
       "      <th>bad_ind</th>\n",
       "      <th>uid</th>\n",
       "      <th>td_score</th>\n",
       "      <th>jxl_score</th>\n",
       "      <th>mj_score</th>\n",
       "      <th>rh_score</th>\n",
       "      <th>zzc_score</th>\n",
       "      <th>zcx_score</th>\n",
       "      <th>person_info</th>\n",
       "      <th>finance_info</th>\n",
       "      <th>credit_info</th>\n",
       "      <th>act_info</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A10000005</td>\n",
       "      <td>0.675349</td>\n",
       "      <td>0.144072</td>\n",
       "      <td>0.186899</td>\n",
       "      <td>0.483640</td>\n",
       "      <td>0.928328</td>\n",
       "      <td>0.369644</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33407</th>\n",
       "      <td>33407</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2810176</td>\n",
       "      <td>0.146055</td>\n",
       "      <td>0.079922</td>\n",
       "      <td>0.250568</td>\n",
       "      <td>0.045240</td>\n",
       "      <td>0.766906</td>\n",
       "      <td>0.413713</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33383</th>\n",
       "      <td>33383</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2807687</td>\n",
       "      <td>0.551366</td>\n",
       "      <td>0.300781</td>\n",
       "      <td>0.225007</td>\n",
       "      <td>0.045447</td>\n",
       "      <td>0.735733</td>\n",
       "      <td>0.684182</td>\n",
       "      <td>-0.261014</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33379</th>\n",
       "      <td>33379</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2807232</td>\n",
       "      <td>0.708547</td>\n",
       "      <td>0.769513</td>\n",
       "      <td>0.928457</td>\n",
       "      <td>0.739716</td>\n",
       "      <td>0.947453</td>\n",
       "      <td>0.361551</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33376</th>\n",
       "      <td>33376</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2806932</td>\n",
       "      <td>0.482248</td>\n",
       "      <td>0.116658</td>\n",
       "      <td>0.286273</td>\n",
       "      <td>0.056618</td>\n",
       "      <td>0.047024</td>\n",
       "      <td>0.890433</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33374</th>\n",
       "      <td>33374</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2806817</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.533693</td>\n",
       "      <td>0.007876</td>\n",
       "      <td>0.547950</td>\n",
       "      <td>0.811325</td>\n",
       "      <td>0.277552</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33373</th>\n",
       "      <td>33373</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2806802</td>\n",
       "      <td>0.462954</td>\n",
       "      <td>0.420593</td>\n",
       "      <td>0.800949</td>\n",
       "      <td>0.212851</td>\n",
       "      <td>0.486658</td>\n",
       "      <td>0.138792</td>\n",
       "      <td>-0.053718</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33369</th>\n",
       "      <td>33369</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2806416</td>\n",
       "      <td>0.698203</td>\n",
       "      <td>0.164079</td>\n",
       "      <td>0.634027</td>\n",
       "      <td>0.013182</td>\n",
       "      <td>0.883847</td>\n",
       "      <td>0.174621</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33353</th>\n",
       "      <td>33353</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2804716</td>\n",
       "      <td>0.070496</td>\n",
       "      <td>0.822415</td>\n",
       "      <td>0.830328</td>\n",
       "      <td>0.520334</td>\n",
       "      <td>0.478299</td>\n",
       "      <td>0.835485</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33351</th>\n",
       "      <td>33351</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2804589</td>\n",
       "      <td>0.583609</td>\n",
       "      <td>0.233510</td>\n",
       "      <td>0.088810</td>\n",
       "      <td>0.698651</td>\n",
       "      <td>0.197491</td>\n",
       "      <td>0.411140</td>\n",
       "      <td>-0.053718</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33346</th>\n",
       "      <td>33346</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2804237</td>\n",
       "      <td>0.123935</td>\n",
       "      <td>0.094507</td>\n",
       "      <td>0.369492</td>\n",
       "      <td>0.235785</td>\n",
       "      <td>0.768280</td>\n",
       "      <td>0.608935</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33344</th>\n",
       "      <td>33344</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2803918</td>\n",
       "      <td>0.806005</td>\n",
       "      <td>0.116417</td>\n",
       "      <td>0.902288</td>\n",
       "      <td>0.891146</td>\n",
       "      <td>0.293035</td>\n",
       "      <td>0.355626</td>\n",
       "      <td>-0.261014</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33325</th>\n",
       "      <td>33325</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2802061</td>\n",
       "      <td>0.637281</td>\n",
       "      <td>0.398567</td>\n",
       "      <td>0.143135</td>\n",
       "      <td>0.597041</td>\n",
       "      <td>0.343201</td>\n",
       "      <td>0.500765</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33318</th>\n",
       "      <td>33318</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2801259</td>\n",
       "      <td>0.596511</td>\n",
       "      <td>0.883618</td>\n",
       "      <td>0.283320</td>\n",
       "      <td>0.732604</td>\n",
       "      <td>0.374978</td>\n",
       "      <td>0.500936</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33317</th>\n",
       "      <td>33317</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2801207</td>\n",
       "      <td>0.123823</td>\n",
       "      <td>0.945924</td>\n",
       "      <td>0.506181</td>\n",
       "      <td>0.590790</td>\n",
       "      <td>0.811825</td>\n",
       "      <td>0.224697</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33309</th>\n",
       "      <td>33309</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2800520</td>\n",
       "      <td>0.614830</td>\n",
       "      <td>0.877893</td>\n",
       "      <td>0.123203</td>\n",
       "      <td>0.916445</td>\n",
       "      <td>0.114235</td>\n",
       "      <td>0.743089</td>\n",
       "      <td>-0.053718</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33297</th>\n",
       "      <td>33297</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2799677</td>\n",
       "      <td>0.604717</td>\n",
       "      <td>0.374595</td>\n",
       "      <td>0.938408</td>\n",
       "      <td>0.586365</td>\n",
       "      <td>0.735909</td>\n",
       "      <td>0.740320</td>\n",
       "      <td>-0.261014</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33293</th>\n",
       "      <td>33293</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2799330</td>\n",
       "      <td>0.482733</td>\n",
       "      <td>0.928511</td>\n",
       "      <td>0.148658</td>\n",
       "      <td>0.640109</td>\n",
       "      <td>0.138359</td>\n",
       "      <td>0.033019</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33290</th>\n",
       "      <td>33290</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2799211</td>\n",
       "      <td>0.710292</td>\n",
       "      <td>0.130790</td>\n",
       "      <td>0.983253</td>\n",
       "      <td>0.082918</td>\n",
       "      <td>0.777281</td>\n",
       "      <td>0.623554</td>\n",
       "      <td>-0.053718</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33272</th>\n",
       "      <td>33272</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2798022</td>\n",
       "      <td>0.448084</td>\n",
       "      <td>0.748679</td>\n",
       "      <td>0.328625</td>\n",
       "      <td>0.132682</td>\n",
       "      <td>0.167770</td>\n",
       "      <td>0.727771</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33271</th>\n",
       "      <td>33271</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2797981</td>\n",
       "      <td>0.023756</td>\n",
       "      <td>0.670237</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>0.435098</td>\n",
       "      <td>0.713790</td>\n",
       "      <td>0.955407</td>\n",
       "      <td>-0.053718</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33269</th>\n",
       "      <td>33269</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A2797770</td>\n",
       "      <td>0.226554</td>\n",
       "      <td>0.680244</td>\n",
       "      <td>0.727622</td>\n",
       "      <td>0.254884</td>\n",
       "      <td>0.992944</td>\n",
       "      <td>0.876976</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33266</th>\n",
       "      <td>33266</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2797557</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>0.349348</td>\n",
       "      <td>0.092643</td>\n",
       "      <td>0.825133</td>\n",
       "      <td>0.950210</td>\n",
       "      <td>0.900024</td>\n",
       "      <td>-0.053718</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33389</th>\n",
       "      <td>33389</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2808538</td>\n",
       "      <td>0.384491</td>\n",
       "      <td>0.341654</td>\n",
       "      <td>0.032921</td>\n",
       "      <td>0.132932</td>\n",
       "      <td>0.876346</td>\n",
       "      <td>0.068431</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33408</th>\n",
       "      <td>33408</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2810400</td>\n",
       "      <td>0.990481</td>\n",
       "      <td>0.957257</td>\n",
       "      <td>0.178243</td>\n",
       "      <td>0.658462</td>\n",
       "      <td>0.474239</td>\n",
       "      <td>0.608943</td>\n",
       "      <td>-0.261014</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32843</th>\n",
       "      <td>32843</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2762336</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>0.530664</td>\n",
       "      <td>0.976051</td>\n",
       "      <td>0.032309</td>\n",
       "      <td>0.420492</td>\n",
       "      <td>0.154787</td>\n",
       "      <td>-0.053718</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33425</th>\n",
       "      <td>33425</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2811970</td>\n",
       "      <td>0.274318</td>\n",
       "      <td>0.645848</td>\n",
       "      <td>0.301810</td>\n",
       "      <td>0.473419</td>\n",
       "      <td>0.362711</td>\n",
       "      <td>0.197031</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33587</th>\n",
       "      <td>33587</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2825799</td>\n",
       "      <td>0.598443</td>\n",
       "      <td>0.240117</td>\n",
       "      <td>0.286880</td>\n",
       "      <td>0.268781</td>\n",
       "      <td>0.709853</td>\n",
       "      <td>0.695681</td>\n",
       "      <td>-0.261014</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33575</th>\n",
       "      <td>33575</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2824804</td>\n",
       "      <td>0.531891</td>\n",
       "      <td>0.789019</td>\n",
       "      <td>0.121659</td>\n",
       "      <td>0.681613</td>\n",
       "      <td>0.710183</td>\n",
       "      <td>0.402115</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33574</th>\n",
       "      <td>33574</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A2824741</td>\n",
       "      <td>0.658501</td>\n",
       "      <td>0.554823</td>\n",
       "      <td>0.936751</td>\n",
       "      <td>0.466318</td>\n",
       "      <td>0.349215</td>\n",
       "      <td>0.922726</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47097</th>\n",
       "      <td>47097</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4231626</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>0.749372</td>\n",
       "      <td>0.945397</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.446565</td>\n",
       "      <td>0.394080</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6680</th>\n",
       "      <td>6680</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A11427763</td>\n",
       "      <td>0.699621</td>\n",
       "      <td>0.338113</td>\n",
       "      <td>0.435493</td>\n",
       "      <td>0.405167</td>\n",
       "      <td>0.806553</td>\n",
       "      <td>0.463670</td>\n",
       "      <td>-0.261014</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47150</th>\n",
       "      <td>47150</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4237589</td>\n",
       "      <td>0.389172</td>\n",
       "      <td>0.947138</td>\n",
       "      <td>0.408213</td>\n",
       "      <td>0.810900</td>\n",
       "      <td>0.629026</td>\n",
       "      <td>0.054742</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47180</th>\n",
       "      <td>47180</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4241331</td>\n",
       "      <td>0.367323</td>\n",
       "      <td>0.829349</td>\n",
       "      <td>0.365953</td>\n",
       "      <td>0.676748</td>\n",
       "      <td>0.271886</td>\n",
       "      <td>0.821118</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47179</th>\n",
       "      <td>47179</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4241055</td>\n",
       "      <td>0.094088</td>\n",
       "      <td>0.292451</td>\n",
       "      <td>0.590439</td>\n",
       "      <td>0.441100</td>\n",
       "      <td>0.372515</td>\n",
       "      <td>0.666028</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47177</th>\n",
       "      <td>47177</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A424100</td>\n",
       "      <td>0.619198</td>\n",
       "      <td>0.063321</td>\n",
       "      <td>0.121981</td>\n",
       "      <td>0.102679</td>\n",
       "      <td>0.331851</td>\n",
       "      <td>0.960599</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47170</th>\n",
       "      <td>47170</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4240136</td>\n",
       "      <td>0.476540</td>\n",
       "      <td>0.272945</td>\n",
       "      <td>0.423133</td>\n",
       "      <td>0.015327</td>\n",
       "      <td>0.043314</td>\n",
       "      <td>0.608911</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47169</th>\n",
       "      <td>47169</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4240031</td>\n",
       "      <td>0.114890</td>\n",
       "      <td>0.180408</td>\n",
       "      <td>0.518461</td>\n",
       "      <td>0.950143</td>\n",
       "      <td>0.137414</td>\n",
       "      <td>0.714164</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47165</th>\n",
       "      <td>47165</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4239401</td>\n",
       "      <td>0.071612</td>\n",
       "      <td>0.280010</td>\n",
       "      <td>0.169715</td>\n",
       "      <td>0.984629</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.232999</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>6673</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A1142654</td>\n",
       "      <td>0.429817</td>\n",
       "      <td>0.468068</td>\n",
       "      <td>0.926577</td>\n",
       "      <td>0.993783</td>\n",
       "      <td>0.501110</td>\n",
       "      <td>0.921929</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47161</th>\n",
       "      <td>47161</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A423879</td>\n",
       "      <td>0.681097</td>\n",
       "      <td>0.035260</td>\n",
       "      <td>0.593894</td>\n",
       "      <td>0.189488</td>\n",
       "      <td>0.912019</td>\n",
       "      <td>0.671876</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47158</th>\n",
       "      <td>47158</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4238450</td>\n",
       "      <td>0.035759</td>\n",
       "      <td>0.350880</td>\n",
       "      <td>0.691053</td>\n",
       "      <td>0.787858</td>\n",
       "      <td>0.454150</td>\n",
       "      <td>0.786214</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47157</th>\n",
       "      <td>47157</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4238258</td>\n",
       "      <td>0.670054</td>\n",
       "      <td>0.200387</td>\n",
       "      <td>0.535783</td>\n",
       "      <td>0.031491</td>\n",
       "      <td>0.021225</td>\n",
       "      <td>0.772031</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47152</th>\n",
       "      <td>47152</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4237812</td>\n",
       "      <td>0.573472</td>\n",
       "      <td>0.644217</td>\n",
       "      <td>0.590915</td>\n",
       "      <td>0.194483</td>\n",
       "      <td>0.835350</td>\n",
       "      <td>0.477122</td>\n",
       "      <td>-0.261014</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47151</th>\n",
       "      <td>47151</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4237758</td>\n",
       "      <td>0.005613</td>\n",
       "      <td>0.399516</td>\n",
       "      <td>0.515077</td>\n",
       "      <td>0.274571</td>\n",
       "      <td>0.368966</td>\n",
       "      <td>0.716633</td>\n",
       "      <td>-0.053718</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47147</th>\n",
       "      <td>47147</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4237248</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.983200</td>\n",
       "      <td>0.015164</td>\n",
       "      <td>0.385588</td>\n",
       "      <td>0.282023</td>\n",
       "      <td>0.064995</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47103</th>\n",
       "      <td>47103</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4232560</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.601463</td>\n",
       "      <td>0.910951</td>\n",
       "      <td>0.536823</td>\n",
       "      <td>0.629676</td>\n",
       "      <td>0.034435</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47146</th>\n",
       "      <td>47146</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4237194</td>\n",
       "      <td>0.242057</td>\n",
       "      <td>0.488763</td>\n",
       "      <td>0.078373</td>\n",
       "      <td>0.592972</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47140</th>\n",
       "      <td>47140</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4236628</td>\n",
       "      <td>0.759067</td>\n",
       "      <td>0.943878</td>\n",
       "      <td>0.809749</td>\n",
       "      <td>0.909733</td>\n",
       "      <td>0.548097</td>\n",
       "      <td>0.797213</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47136</th>\n",
       "      <td>47136</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4236192</td>\n",
       "      <td>0.226262</td>\n",
       "      <td>0.318386</td>\n",
       "      <td>0.055679</td>\n",
       "      <td>0.494603</td>\n",
       "      <td>0.843739</td>\n",
       "      <td>0.666629</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47131</th>\n",
       "      <td>47131</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4235676</td>\n",
       "      <td>0.459989</td>\n",
       "      <td>0.671714</td>\n",
       "      <td>0.857372</td>\n",
       "      <td>0.052582</td>\n",
       "      <td>0.967063</td>\n",
       "      <td>0.834384</td>\n",
       "      <td>-0.261014</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47128</th>\n",
       "      <td>47128</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4235352</td>\n",
       "      <td>0.551001</td>\n",
       "      <td>0.816620</td>\n",
       "      <td>0.829444</td>\n",
       "      <td>0.230133</td>\n",
       "      <td>0.021902</td>\n",
       "      <td>0.118826</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47125</th>\n",
       "      <td>47125</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4234981</td>\n",
       "      <td>0.496588</td>\n",
       "      <td>0.221055</td>\n",
       "      <td>0.471806</td>\n",
       "      <td>0.172620</td>\n",
       "      <td>0.911311</td>\n",
       "      <td>0.207150</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47123</th>\n",
       "      <td>47123</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4234909</td>\n",
       "      <td>0.180478</td>\n",
       "      <td>0.837871</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.928461</td>\n",
       "      <td>0.006872</td>\n",
       "      <td>0.483376</td>\n",
       "      <td>-0.128677</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47122</th>\n",
       "      <td>47122</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4234704</td>\n",
       "      <td>0.013101</td>\n",
       "      <td>0.820456</td>\n",
       "      <td>0.094119</td>\n",
       "      <td>0.080380</td>\n",
       "      <td>0.672859</td>\n",
       "      <td>0.891824</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47112</th>\n",
       "      <td>47112</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4233575</td>\n",
       "      <td>0.723610</td>\n",
       "      <td>0.857182</td>\n",
       "      <td>0.117430</td>\n",
       "      <td>0.949779</td>\n",
       "      <td>0.280677</td>\n",
       "      <td>0.431667</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47109</th>\n",
       "      <td>47109</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4233356</td>\n",
       "      <td>0.636472</td>\n",
       "      <td>0.432827</td>\n",
       "      <td>0.423410</td>\n",
       "      <td>0.516783</td>\n",
       "      <td>0.678267</td>\n",
       "      <td>0.788935</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47106</th>\n",
       "      <td>47106</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4232739</td>\n",
       "      <td>0.911809</td>\n",
       "      <td>0.871835</td>\n",
       "      <td>0.073466</td>\n",
       "      <td>0.433998</td>\n",
       "      <td>0.747908</td>\n",
       "      <td>0.962329</td>\n",
       "      <td>0.078853</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47104</th>\n",
       "      <td>47104</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A4232571</td>\n",
       "      <td>0.333640</td>\n",
       "      <td>0.771295</td>\n",
       "      <td>0.678957</td>\n",
       "      <td>0.305642</td>\n",
       "      <td>0.231494</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39915</th>\n",
       "      <td>39915</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A345019</td>\n",
       "      <td>0.510283</td>\n",
       "      <td>0.545837</td>\n",
       "      <td>0.066670</td>\n",
       "      <td>0.257507</td>\n",
       "      <td>0.288563</td>\n",
       "      <td>0.628067</td>\n",
       "      <td>-0.322581</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79831 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     obs_mth  bad_ind        uid  td_score  jxl_score  mj_score  \\\n",
       "0          0  2018-10-31      0.0  A10000005  0.675349   0.144072  0.186899   \n",
       "33407  33407  2018-10-31      0.0   A2810176  0.146055   0.079922  0.250568   \n",
       "33383  33383  2018-10-31      0.0   A2807687  0.551366   0.300781  0.225007   \n",
       "33379  33379  2018-10-31      0.0   A2807232  0.708547   0.769513  0.928457   \n",
       "33376  33376  2018-10-31      0.0   A2806932  0.482248   0.116658  0.286273   \n",
       "33374  33374  2018-10-31      0.0   A2806817  0.003063   0.533693  0.007876   \n",
       "33373  33373  2018-10-31      0.0   A2806802  0.462954   0.420593  0.800949   \n",
       "33369  33369  2018-10-31      0.0   A2806416  0.698203   0.164079  0.634027   \n",
       "33353  33353  2018-10-31      0.0   A2804716  0.070496   0.822415  0.830328   \n",
       "33351  33351  2018-10-31      0.0   A2804589  0.583609   0.233510  0.088810   \n",
       "33346  33346  2018-10-31      0.0   A2804237  0.123935   0.094507  0.369492   \n",
       "33344  33344  2018-10-31      0.0   A2803918  0.806005   0.116417  0.902288   \n",
       "33325  33325  2018-10-31      0.0   A2802061  0.637281   0.398567  0.143135   \n",
       "33318  33318  2018-10-31      0.0   A2801259  0.596511   0.883618  0.283320   \n",
       "33317  33317  2018-10-31      0.0   A2801207  0.123823   0.945924  0.506181   \n",
       "33309  33309  2018-10-31      0.0   A2800520  0.614830   0.877893  0.123203   \n",
       "33297  33297  2018-10-31      0.0   A2799677  0.604717   0.374595  0.938408   \n",
       "33293  33293  2018-10-31      0.0   A2799330  0.482733   0.928511  0.148658   \n",
       "33290  33290  2018-10-31      0.0   A2799211  0.710292   0.130790  0.983253   \n",
       "33272  33272  2018-10-31      0.0   A2798022  0.448084   0.748679  0.328625   \n",
       "33271  33271  2018-10-31      0.0   A2797981  0.023756   0.670237  0.389094   \n",
       "33269  33269  2018-10-31      1.0   A2797770  0.226554   0.680244  0.727622   \n",
       "33266  33266  2018-10-31      0.0   A2797557  0.003059   0.349348  0.092643   \n",
       "33389  33389  2018-10-31      0.0   A2808538  0.384491   0.341654  0.032921   \n",
       "33408  33408  2018-10-31      0.0   A2810400  0.990481   0.957257  0.178243   \n",
       "32843  32843  2018-10-31      0.0   A2762336  0.009145   0.530664  0.976051   \n",
       "33425  33425  2018-10-31      0.0   A2811970  0.274318   0.645848  0.301810   \n",
       "33587  33587  2018-10-31      0.0   A2825799  0.598443   0.240117  0.286880   \n",
       "33575  33575  2018-10-31      0.0   A2824804  0.531891   0.789019  0.121659   \n",
       "33574  33574  2018-10-31      0.0   A2824741  0.658501   0.554823  0.936751   \n",
       "...      ...         ...      ...        ...       ...        ...       ...   \n",
       "47097  47097  2018-06-30      0.0   A4231626  0.348700   0.749372  0.945397   \n",
       "6680    6680  2018-06-30      0.0  A11427763  0.699621   0.338113  0.435493   \n",
       "47150  47150  2018-06-30      0.0   A4237589  0.389172   0.947138  0.408213   \n",
       "47180  47180  2018-06-30      0.0   A4241331  0.367323   0.829349  0.365953   \n",
       "47179  47179  2018-06-30      0.0   A4241055  0.094088   0.292451  0.590439   \n",
       "47177  47177  2018-06-30      0.0    A424100  0.619198   0.063321  0.121981   \n",
       "47170  47170  2018-06-30      0.0   A4240136  0.476540   0.272945  0.423133   \n",
       "47169  47169  2018-06-30      0.0   A4240031  0.114890   0.180408  0.518461   \n",
       "47165  47165  2018-06-30      0.0   A4239401  0.071612   0.280010  0.169715   \n",
       "6673    6673  2018-06-30      0.0   A1142654  0.429817   0.468068  0.926577   \n",
       "47161  47161  2018-06-30      0.0    A423879  0.681097   0.035260  0.593894   \n",
       "47158  47158  2018-06-30      0.0   A4238450  0.035759   0.350880  0.691053   \n",
       "47157  47157  2018-06-30      0.0   A4238258  0.670054   0.200387  0.535783   \n",
       "47152  47152  2018-06-30      0.0   A4237812  0.573472   0.644217  0.590915   \n",
       "47151  47151  2018-06-30      0.0   A4237758  0.005613   0.399516  0.515077   \n",
       "47147  47147  2018-06-30      0.0   A4237248  0.159877   0.983200  0.015164   \n",
       "47103  47103  2018-06-30      0.0   A4232560  0.513000   0.601463  0.910951   \n",
       "47146  47146  2018-06-30      0.0   A4237194  0.242057   0.488763  0.078373   \n",
       "47140  47140  2018-06-30      0.0   A4236628  0.759067   0.943878  0.809749   \n",
       "47136  47136  2018-06-30      0.0   A4236192  0.226262   0.318386  0.055679   \n",
       "47131  47131  2018-06-30      0.0   A4235676  0.459989   0.671714  0.857372   \n",
       "47128  47128  2018-06-30      0.0   A4235352  0.551001   0.816620  0.829444   \n",
       "47125  47125  2018-06-30      0.0   A4234981  0.496588   0.221055  0.471806   \n",
       "47123  47123  2018-06-30      0.0   A4234909  0.180478   0.837871  0.963415   \n",
       "47122  47122  2018-06-30      0.0   A4234704  0.013101   0.820456  0.094119   \n",
       "47112  47112  2018-06-30      0.0   A4233575  0.723610   0.857182  0.117430   \n",
       "47109  47109  2018-06-30      0.0   A4233356  0.636472   0.432827  0.423410   \n",
       "47106  47106  2018-06-30      0.0   A4232739  0.911809   0.871835  0.073466   \n",
       "47104  47104  2018-06-30      0.0   A4232571  0.333640   0.771295  0.678957   \n",
       "39915  39915  2018-06-30      0.0    A345019  0.510283   0.545837  0.066670   \n",
       "\n",
       "       rh_score  zzc_score  zcx_score  person_info  finance_info  credit_info  \\\n",
       "0      0.483640   0.928328   0.369644    -0.322581      0.023810         0.00   \n",
       "33407  0.045240   0.766906   0.413713     0.013863      0.023810         0.00   \n",
       "33383  0.045447   0.735733   0.684182    -0.261014      0.071429         0.03   \n",
       "33379  0.739716   0.947453   0.361551    -0.128677      0.047619         0.00   \n",
       "33376  0.056618   0.047024   0.890433     0.078853      0.047619         0.00   \n",
       "33374  0.547950   0.811325   0.277552    -0.128677      0.071429         0.02   \n",
       "33373  0.212851   0.486658   0.138792    -0.053718      0.023810         0.20   \n",
       "33369  0.013182   0.883847   0.174621    -0.322581      0.071429         0.06   \n",
       "33353  0.520334   0.478299   0.835485     0.078853      0.047619         0.00   \n",
       "33351  0.698651   0.197491   0.411140    -0.053718      0.023810         0.02   \n",
       "33346  0.235785   0.768280   0.608935    -0.322581      0.047619         0.00   \n",
       "33344  0.891146   0.293035   0.355626    -0.261014      0.023810         0.00   \n",
       "33325  0.597041   0.343201   0.500765     0.078853      0.023810         0.00   \n",
       "33318  0.732604   0.374978   0.500936    -0.322581      0.023810         0.00   \n",
       "33317  0.590790   0.811825   0.224697     0.013863      0.023810         0.08   \n",
       "33309  0.916445   0.114235   0.743089    -0.053718      0.023810         0.10   \n",
       "33297  0.586365   0.735909   0.740320    -0.261014      0.142857         0.09   \n",
       "33293  0.640109   0.138359   0.033019    -0.322581      0.047619         0.10   \n",
       "33290  0.082918   0.777281   0.623554    -0.053718      0.023810         0.00   \n",
       "33272  0.132682   0.167770   0.727771    -0.322581      0.023810         0.00   \n",
       "33271  0.435098   0.713790   0.955407    -0.053718      0.023810         0.00   \n",
       "33269  0.254884   0.992944   0.876976     0.013863      0.023810         0.19   \n",
       "33266  0.825133   0.950210   0.900024    -0.053718      0.119048         0.46   \n",
       "33389  0.132932   0.876346   0.068431     0.078853      0.047619         0.03   \n",
       "33408  0.658462   0.474239   0.608943    -0.261014      0.023810         0.00   \n",
       "32843  0.032309   0.420492   0.154787    -0.053718      0.023810         0.03   \n",
       "33425  0.473419   0.362711   0.197031     0.078853      0.023810         0.00   \n",
       "33587  0.268781   0.709853   0.695681    -0.261014      0.023810         0.00   \n",
       "33575  0.681613   0.710183   0.402115    -0.128677      0.023810         0.00   \n",
       "33574  0.466318   0.349215   0.922726    -0.128677      0.047619         0.00   \n",
       "...         ...        ...        ...          ...           ...          ...   \n",
       "47097  0.884615   0.446565   0.394080     0.062660      0.119048         0.13   \n",
       "6680   0.405167   0.806553   0.463670    -0.261014      0.023810         0.00   \n",
       "47150  0.810900   0.629026   0.054742     0.078853      0.023810         0.00   \n",
       "47180  0.676748   0.271886   0.821118     0.078853      0.023810         0.00   \n",
       "47179  0.441100   0.372515   0.666028    -0.322581      0.023810         0.00   \n",
       "47177  0.102679   0.331851   0.960599     0.062660      0.023810         0.00   \n",
       "47170  0.015327   0.043314   0.608911     0.062660      0.023810         0.00   \n",
       "47169  0.950143   0.137414   0.714164     0.062660      0.023810         0.02   \n",
       "47165  0.984629   0.002314   0.232999    -0.322581      0.023810         0.00   \n",
       "6673   0.993783   0.501110   0.921929    -0.322581      0.023810         0.00   \n",
       "47161  0.189488   0.912019   0.671876    -0.322581      0.047619         0.06   \n",
       "47158  0.787858   0.454150   0.786214    -0.322581      0.023810         0.00   \n",
       "47157  0.031491   0.021225   0.772031    -0.128677      0.023810         0.00   \n",
       "47152  0.194483   0.835350   0.477122    -0.261014      0.023810         0.00   \n",
       "47151  0.274571   0.368966   0.716633    -0.053718      0.023810         0.22   \n",
       "47147  0.385588   0.282023   0.064995     0.062660      0.023810         0.10   \n",
       "47103  0.536823   0.629676   0.034435     0.078853      0.023810         0.00   \n",
       "47146  0.592972   0.913333   0.024795    -0.128677      0.047619         0.00   \n",
       "47140  0.909733   0.548097   0.797213     0.062660      0.023810         0.19   \n",
       "47136  0.494603   0.843739   0.666629    -0.128677      0.023810         0.00   \n",
       "47131  0.052582   0.967063   0.834384    -0.261014      0.047619         0.04   \n",
       "47128  0.230133   0.021902   0.118826     0.078853      0.023810         0.00   \n",
       "47125  0.172620   0.911311   0.207150    -0.322581      0.023810         0.00   \n",
       "47123  0.928461   0.006872   0.483376    -0.128677      0.023810         0.00   \n",
       "47122  0.080380   0.672859   0.891824     0.078853      0.047619         0.02   \n",
       "47112  0.949779   0.280677   0.431667     0.078853      0.023810         0.00   \n",
       "47109  0.516783   0.678267   0.788935    -0.322581      0.023810         0.00   \n",
       "47106  0.433998   0.747908   0.962329     0.078853      0.023810         0.00   \n",
       "47104  0.305642   0.231494   0.020833     0.062660      0.047619         0.00   \n",
       "39915  0.257507   0.288563   0.628067    -0.322581      0.023810         0.00   \n",
       "\n",
       "       act_info  rank  \n",
       "0      0.217949     1  \n",
       "33407  0.269231     1  \n",
       "33383  0.269231     1  \n",
       "33379  0.269231     1  \n",
       "33376  0.269231     1  \n",
       "33374  0.269231     1  \n",
       "33373  0.269231     1  \n",
       "33369  0.269231     1  \n",
       "33353  0.269231     1  \n",
       "33351  0.269231     1  \n",
       "33346  0.269231     1  \n",
       "33344  0.269231     1  \n",
       "33325  0.269231     1  \n",
       "33318  0.269231     1  \n",
       "33317  0.269231     1  \n",
       "33309  0.269231     1  \n",
       "33297  0.269231     1  \n",
       "33293  0.269231     1  \n",
       "33290  0.269231     1  \n",
       "33272  0.269231     1  \n",
       "33271  0.269231     1  \n",
       "33269  0.269231     1  \n",
       "33266  0.269231     1  \n",
       "33389  0.269231     1  \n",
       "33408  0.269231     1  \n",
       "32843  0.487179     1  \n",
       "33425  0.282051     1  \n",
       "33587  0.269231     1  \n",
       "33575  0.269231     1  \n",
       "33574  0.269231     1  \n",
       "...         ...   ...  \n",
       "47097  0.166667     5  \n",
       "6680   0.076923     5  \n",
       "47150  0.166667     5  \n",
       "47180  0.166667     5  \n",
       "47179  0.166667     5  \n",
       "47177  0.512821     5  \n",
       "47170  0.166667     5  \n",
       "47169  0.166667     5  \n",
       "47165  0.166667     5  \n",
       "6673   0.371795     5  \n",
       "47161  0.512821     5  \n",
       "47158  0.166667     5  \n",
       "47157  0.166667     5  \n",
       "47152  0.166667     5  \n",
       "47151  0.166667     5  \n",
       "47147  0.166667     5  \n",
       "47103  0.166667     5  \n",
       "47146  0.166667     5  \n",
       "47140  0.166667     5  \n",
       "47136  0.166667     5  \n",
       "47131  0.166667     5  \n",
       "47128  0.166667     5  \n",
       "47125  0.166667     5  \n",
       "47123  0.166667     5  \n",
       "47122  0.166667     5  \n",
       "47112  0.166667     5  \n",
       "47109  0.166667     5  \n",
       "47106  0.166667     5  \n",
       "47104  0.166667     5  \n",
       "39915  0.538462     5  \n",
       "\n",
       "[79831 rows x 15 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用lgbm 进行跨时间的交叉验证\n",
    "def LGB_test(train_x,train_y,test_x,test_y):\n",
    "    from multiprocessing import cpu_count\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "        max_depth=2, n_estimators=800,max_features = 140, objective='binary',\n",
    "        subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "        learning_rate=0.05, min_child_weight=50,random_state=None,n_jobs=cpu_count()-1,\n",
    "        num_iterations = 800 #迭代次数\n",
    "    )\n",
    "    clf.fit(train_x,train_y,  #训练集的特征和目标 \n",
    "            eval_set=[(train_x,train_y),(test_x,test_y)],  #验证数据\n",
    "            eval_metric='auc',                             # 评估损失的指标 这里传入的是auc\n",
    "            early_stopping_rounds=100)                     # early_stopping 迭代次数 \n",
    "    print(clf.n_features_)\n",
    "    return clf,clf.best_score_['valid_1']['auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['person_info','finance_info','credit_info','act_info','td_score','jxl_score','mj_score','rh_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.737137\ttraining's binary_logloss: 0.0832707\tvalid_1's auc: 0.712178\tvalid_1's binary_logloss: 0.12168\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.779956\ttraining's binary_logloss: 0.0821329\tvalid_1's auc: 0.773038\tvalid_1's binary_logloss: 0.119538\n",
      "[3]\ttraining's auc: 0.787657\ttraining's binary_logloss: 0.0816239\tvalid_1's auc: 0.759829\tvalid_1's binary_logloss: 0.118773\n",
      "[4]\ttraining's auc: 0.787083\ttraining's binary_logloss: 0.0811169\tvalid_1's auc: 0.758327\tvalid_1's binary_logloss: 0.117919\n",
      "[5]\ttraining's auc: 0.791363\ttraining's binary_logloss: 0.0803378\tvalid_1's auc: 0.768679\tvalid_1's binary_logloss: 0.116488\n",
      "[6]\ttraining's auc: 0.797614\ttraining's binary_logloss: 0.0796057\tvalid_1's auc: 0.779753\tvalid_1's binary_logloss: 0.11516\n",
      "[7]\ttraining's auc: 0.796785\ttraining's binary_logloss: 0.0792409\tvalid_1's auc: 0.779428\tvalid_1's binary_logloss: 0.114638\n",
      "[8]\ttraining's auc: 0.799178\ttraining's binary_logloss: 0.0786552\tvalid_1's auc: 0.779952\tvalid_1's binary_logloss: 0.1136\n",
      "[9]\ttraining's auc: 0.800233\ttraining's binary_logloss: 0.078141\tvalid_1's auc: 0.780585\tvalid_1's binary_logloss: 0.112795\n",
      "[10]\ttraining's auc: 0.800095\ttraining's binary_logloss: 0.0778623\tvalid_1's auc: 0.779255\tvalid_1's binary_logloss: 0.11246\n",
      "[11]\ttraining's auc: 0.800564\ttraining's binary_logloss: 0.0773838\tvalid_1's auc: 0.780632\tvalid_1's binary_logloss: 0.11162\n",
      "[12]\ttraining's auc: 0.801518\ttraining's binary_logloss: 0.0769709\tvalid_1's auc: 0.782005\tvalid_1's binary_logloss: 0.110988\n",
      "[13]\ttraining's auc: 0.799616\ttraining's binary_logloss: 0.076757\tvalid_1's auc: 0.779543\tvalid_1's binary_logloss: 0.110771\n",
      "[14]\ttraining's auc: 0.799979\ttraining's binary_logloss: 0.0764021\tvalid_1's auc: 0.780339\tvalid_1's binary_logloss: 0.110206\n",
      "[15]\ttraining's auc: 0.803135\ttraining's binary_logloss: 0.0760872\tvalid_1's auc: 0.782372\tvalid_1's binary_logloss: 0.109794\n",
      "[16]\ttraining's auc: 0.803352\ttraining's binary_logloss: 0.0758013\tvalid_1's auc: 0.783064\tvalid_1's binary_logloss: 0.109309\n",
      "[17]\ttraining's auc: 0.804747\ttraining's binary_logloss: 0.0755999\tvalid_1's auc: 0.783873\tvalid_1's binary_logloss: 0.109072\n",
      "[18]\ttraining's auc: 0.804488\ttraining's binary_logloss: 0.0753487\tvalid_1's auc: 0.784544\tvalid_1's binary_logloss: 0.108687\n",
      "[19]\ttraining's auc: 0.805255\ttraining's binary_logloss: 0.0751014\tvalid_1's auc: 0.784966\tvalid_1's binary_logloss: 0.10833\n",
      "[20]\ttraining's auc: 0.805515\ttraining's binary_logloss: 0.0749265\tvalid_1's auc: 0.784932\tvalid_1's binary_logloss: 0.108144\n",
      "[21]\ttraining's auc: 0.805492\ttraining's binary_logloss: 0.074729\tvalid_1's auc: 0.785172\tvalid_1's binary_logloss: 0.107857\n",
      "[22]\ttraining's auc: 0.806313\ttraining's binary_logloss: 0.0745607\tvalid_1's auc: 0.785839\tvalid_1's binary_logloss: 0.107622\n",
      "[23]\ttraining's auc: 0.806817\ttraining's binary_logloss: 0.074424\tvalid_1's auc: 0.785816\tvalid_1's binary_logloss: 0.107488\n",
      "[24]\ttraining's auc: 0.807193\ttraining's binary_logloss: 0.0742699\tvalid_1's auc: 0.78552\tvalid_1's binary_logloss: 0.107392\n",
      "[25]\ttraining's auc: 0.807639\ttraining's binary_logloss: 0.0741103\tvalid_1's auc: 0.785228\tvalid_1's binary_logloss: 0.10721\n",
      "[26]\ttraining's auc: 0.808227\ttraining's binary_logloss: 0.0739871\tvalid_1's auc: 0.784998\tvalid_1's binary_logloss: 0.107082\n",
      "[27]\ttraining's auc: 0.809528\ttraining's binary_logloss: 0.0738892\tvalid_1's auc: 0.784879\tvalid_1's binary_logloss: 0.106981\n",
      "[28]\ttraining's auc: 0.811116\ttraining's binary_logloss: 0.0737893\tvalid_1's auc: 0.786362\tvalid_1's binary_logloss: 0.106936\n",
      "[29]\ttraining's auc: 0.810897\ttraining's binary_logloss: 0.073679\tvalid_1's auc: 0.786837\tvalid_1's binary_logloss: 0.106795\n",
      "[30]\ttraining's auc: 0.811648\ttraining's binary_logloss: 0.0735682\tvalid_1's auc: 0.786791\tvalid_1's binary_logloss: 0.106699\n",
      "[31]\ttraining's auc: 0.811873\ttraining's binary_logloss: 0.0734598\tvalid_1's auc: 0.786316\tvalid_1's binary_logloss: 0.106619\n",
      "[32]\ttraining's auc: 0.811835\ttraining's binary_logloss: 0.0733832\tvalid_1's auc: 0.786031\tvalid_1's binary_logloss: 0.106599\n",
      "[33]\ttraining's auc: 0.811977\ttraining's binary_logloss: 0.073282\tvalid_1's auc: 0.786137\tvalid_1's binary_logloss: 0.106495\n",
      "[34]\ttraining's auc: 0.812127\ttraining's binary_logloss: 0.0732173\tvalid_1's auc: 0.785708\tvalid_1's binary_logloss: 0.106511\n",
      "[35]\ttraining's auc: 0.812001\ttraining's binary_logloss: 0.0731508\tvalid_1's auc: 0.785861\tvalid_1's binary_logloss: 0.106454\n",
      "[36]\ttraining's auc: 0.812269\ttraining's binary_logloss: 0.0730878\tvalid_1's auc: 0.785533\tvalid_1's binary_logloss: 0.106435\n",
      "[37]\ttraining's auc: 0.81302\ttraining's binary_logloss: 0.0730101\tvalid_1's auc: 0.784796\tvalid_1's binary_logloss: 0.106412\n",
      "[38]\ttraining's auc: 0.813302\ttraining's binary_logloss: 0.0729402\tvalid_1's auc: 0.784632\tvalid_1's binary_logloss: 0.106409\n",
      "[39]\ttraining's auc: 0.813896\ttraining's binary_logloss: 0.0728764\tvalid_1's auc: 0.784974\tvalid_1's binary_logloss: 0.106342\n",
      "[40]\ttraining's auc: 0.814032\ttraining's binary_logloss: 0.072824\tvalid_1's auc: 0.785171\tvalid_1's binary_logloss: 0.106288\n",
      "[41]\ttraining's auc: 0.814233\ttraining's binary_logloss: 0.0727596\tvalid_1's auc: 0.785623\tvalid_1's binary_logloss: 0.106237\n",
      "[42]\ttraining's auc: 0.814391\ttraining's binary_logloss: 0.0727135\tvalid_1's auc: 0.785634\tvalid_1's binary_logloss: 0.106207\n",
      "[43]\ttraining's auc: 0.814671\ttraining's binary_logloss: 0.0726635\tvalid_1's auc: 0.785777\tvalid_1's binary_logloss: 0.106172\n",
      "[44]\ttraining's auc: 0.814689\ttraining's binary_logloss: 0.0726168\tvalid_1's auc: 0.785387\tvalid_1's binary_logloss: 0.106188\n",
      "[45]\ttraining's auc: 0.814518\ttraining's binary_logloss: 0.0725737\tvalid_1's auc: 0.78547\tvalid_1's binary_logloss: 0.10613\n",
      "[46]\ttraining's auc: 0.814832\ttraining's binary_logloss: 0.0725258\tvalid_1's auc: 0.785709\tvalid_1's binary_logloss: 0.106099\n",
      "[47]\ttraining's auc: 0.815099\ttraining's binary_logloss: 0.0724814\tvalid_1's auc: 0.785959\tvalid_1's binary_logloss: 0.106053\n",
      "[48]\ttraining's auc: 0.815353\ttraining's binary_logloss: 0.0724374\tvalid_1's auc: 0.785874\tvalid_1's binary_logloss: 0.106026\n",
      "[49]\ttraining's auc: 0.81525\ttraining's binary_logloss: 0.0723973\tvalid_1's auc: 0.78591\tvalid_1's binary_logloss: 0.106027\n",
      "[50]\ttraining's auc: 0.815296\ttraining's binary_logloss: 0.0723627\tvalid_1's auc: 0.78581\tvalid_1's binary_logloss: 0.106005\n",
      "[51]\ttraining's auc: 0.815512\ttraining's binary_logloss: 0.0723276\tvalid_1's auc: 0.785415\tvalid_1's binary_logloss: 0.10604\n",
      "[52]\ttraining's auc: 0.815828\ttraining's binary_logloss: 0.0723091\tvalid_1's auc: 0.785942\tvalid_1's binary_logloss: 0.106002\n",
      "[53]\ttraining's auc: 0.8156\ttraining's binary_logloss: 0.072295\tvalid_1's auc: 0.785885\tvalid_1's binary_logloss: 0.105995\n",
      "[54]\ttraining's auc: 0.815635\ttraining's binary_logloss: 0.0722595\tvalid_1's auc: 0.785942\tvalid_1's binary_logloss: 0.10599\n",
      "[55]\ttraining's auc: 0.815678\ttraining's binary_logloss: 0.0722314\tvalid_1's auc: 0.785967\tvalid_1's binary_logloss: 0.106\n",
      "[56]\ttraining's auc: 0.815706\ttraining's binary_logloss: 0.0721984\tvalid_1's auc: 0.785853\tvalid_1's binary_logloss: 0.105979\n",
      "[57]\ttraining's auc: 0.816073\ttraining's binary_logloss: 0.0721753\tvalid_1's auc: 0.786098\tvalid_1's binary_logloss: 0.105963\n",
      "[58]\ttraining's auc: 0.8161\ttraining's binary_logloss: 0.0721507\tvalid_1's auc: 0.785843\tvalid_1's binary_logloss: 0.10596\n",
      "[59]\ttraining's auc: 0.816179\ttraining's binary_logloss: 0.0721195\tvalid_1's auc: 0.78596\tvalid_1's binary_logloss: 0.105927\n",
      "[60]\ttraining's auc: 0.816269\ttraining's binary_logloss: 0.072096\tvalid_1's auc: 0.786205\tvalid_1's binary_logloss: 0.105923\n",
      "[61]\ttraining's auc: 0.816416\ttraining's binary_logloss: 0.0720742\tvalid_1's auc: 0.786516\tvalid_1's binary_logloss: 0.105911\n",
      "[62]\ttraining's auc: 0.816535\ttraining's binary_logloss: 0.072049\tvalid_1's auc: 0.786509\tvalid_1's binary_logloss: 0.10592\n",
      "[63]\ttraining's auc: 0.816589\ttraining's binary_logloss: 0.072023\tvalid_1's auc: 0.786443\tvalid_1's binary_logloss: 0.10595\n",
      "[64]\ttraining's auc: 0.816668\ttraining's binary_logloss: 0.072005\tvalid_1's auc: 0.786688\tvalid_1's binary_logloss: 0.105935\n",
      "[65]\ttraining's auc: 0.816827\ttraining's binary_logloss: 0.071983\tvalid_1's auc: 0.786675\tvalid_1's binary_logloss: 0.105958\n",
      "[66]\ttraining's auc: 0.816955\ttraining's binary_logloss: 0.0719667\tvalid_1's auc: 0.786444\tvalid_1's binary_logloss: 0.105989\n",
      "[67]\ttraining's auc: 0.817083\ttraining's binary_logloss: 0.0719441\tvalid_1's auc: 0.785922\tvalid_1's binary_logloss: 0.106031\n",
      "[68]\ttraining's auc: 0.817243\ttraining's binary_logloss: 0.0719268\tvalid_1's auc: 0.785906\tvalid_1's binary_logloss: 0.106044\n",
      "[69]\ttraining's auc: 0.817256\ttraining's binary_logloss: 0.0719066\tvalid_1's auc: 0.785847\tvalid_1's binary_logloss: 0.106065\n",
      "[70]\ttraining's auc: 0.817406\ttraining's binary_logloss: 0.071888\tvalid_1's auc: 0.785889\tvalid_1's binary_logloss: 0.106065\n",
      "[71]\ttraining's auc: 0.817542\ttraining's binary_logloss: 0.0718725\tvalid_1's auc: 0.785982\tvalid_1's binary_logloss: 0.106052\n",
      "[72]\ttraining's auc: 0.81753\ttraining's binary_logloss: 0.0718579\tvalid_1's auc: 0.785898\tvalid_1's binary_logloss: 0.10607\n",
      "[73]\ttraining's auc: 0.817572\ttraining's binary_logloss: 0.0718444\tvalid_1's auc: 0.785999\tvalid_1's binary_logloss: 0.106067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74]\ttraining's auc: 0.8177\ttraining's binary_logloss: 0.0718338\tvalid_1's auc: 0.786248\tvalid_1's binary_logloss: 0.106055\n",
      "[75]\ttraining's auc: 0.817776\ttraining's binary_logloss: 0.0718139\tvalid_1's auc: 0.786254\tvalid_1's binary_logloss: 0.10606\n",
      "[76]\ttraining's auc: 0.817746\ttraining's binary_logloss: 0.0717932\tvalid_1's auc: 0.786234\tvalid_1's binary_logloss: 0.106069\n",
      "[77]\ttraining's auc: 0.817805\ttraining's binary_logloss: 0.0717813\tvalid_1's auc: 0.786385\tvalid_1's binary_logloss: 0.106051\n",
      "[78]\ttraining's auc: 0.81785\ttraining's binary_logloss: 0.0717608\tvalid_1's auc: 0.786448\tvalid_1's binary_logloss: 0.106048\n",
      "[79]\ttraining's auc: 0.817856\ttraining's binary_logloss: 0.0717497\tvalid_1's auc: 0.786389\tvalid_1's binary_logloss: 0.106043\n",
      "[80]\ttraining's auc: 0.817805\ttraining's binary_logloss: 0.0717335\tvalid_1's auc: 0.78636\tvalid_1's binary_logloss: 0.106046\n",
      "[81]\ttraining's auc: 0.817929\ttraining's binary_logloss: 0.0717176\tvalid_1's auc: 0.786105\tvalid_1's binary_logloss: 0.106076\n",
      "[82]\ttraining's auc: 0.817987\ttraining's binary_logloss: 0.0717058\tvalid_1's auc: 0.786264\tvalid_1's binary_logloss: 0.106065\n",
      "[83]\ttraining's auc: 0.818062\ttraining's binary_logloss: 0.0716967\tvalid_1's auc: 0.786325\tvalid_1's binary_logloss: 0.106059\n",
      "[84]\ttraining's auc: 0.818091\ttraining's binary_logloss: 0.0716696\tvalid_1's auc: 0.786403\tvalid_1's binary_logloss: 0.106049\n",
      "[85]\ttraining's auc: 0.81818\ttraining's binary_logloss: 0.0716594\tvalid_1's auc: 0.786479\tvalid_1's binary_logloss: 0.106048\n",
      "[86]\ttraining's auc: 0.818214\ttraining's binary_logloss: 0.0716463\tvalid_1's auc: 0.786461\tvalid_1's binary_logloss: 0.10606\n",
      "[87]\ttraining's auc: 0.818102\ttraining's binary_logloss: 0.0716312\tvalid_1's auc: 0.786457\tvalid_1's binary_logloss: 0.106056\n",
      "[88]\ttraining's auc: 0.818067\ttraining's binary_logloss: 0.0716195\tvalid_1's auc: 0.786229\tvalid_1's binary_logloss: 0.106095\n",
      "[89]\ttraining's auc: 0.818104\ttraining's binary_logloss: 0.0716098\tvalid_1's auc: 0.786207\tvalid_1's binary_logloss: 0.106104\n",
      "[90]\ttraining's auc: 0.818199\ttraining's binary_logloss: 0.0716011\tvalid_1's auc: 0.786273\tvalid_1's binary_logloss: 0.106097\n",
      "[91]\ttraining's auc: 0.818391\ttraining's binary_logloss: 0.0715871\tvalid_1's auc: 0.7861\tvalid_1's binary_logloss: 0.106126\n",
      "[92]\ttraining's auc: 0.818523\ttraining's binary_logloss: 0.0715764\tvalid_1's auc: 0.786037\tvalid_1's binary_logloss: 0.106121\n",
      "[93]\ttraining's auc: 0.818597\ttraining's binary_logloss: 0.0715668\tvalid_1's auc: 0.786146\tvalid_1's binary_logloss: 0.106108\n",
      "[94]\ttraining's auc: 0.818624\ttraining's binary_logloss: 0.0715592\tvalid_1's auc: 0.786339\tvalid_1's binary_logloss: 0.106085\n",
      "[95]\ttraining's auc: 0.818724\ttraining's binary_logloss: 0.0715506\tvalid_1's auc: 0.786396\tvalid_1's binary_logloss: 0.106081\n",
      "[96]\ttraining's auc: 0.818797\ttraining's binary_logloss: 0.0715474\tvalid_1's auc: 0.786419\tvalid_1's binary_logloss: 0.106079\n",
      "[97]\ttraining's auc: 0.818848\ttraining's binary_logloss: 0.0715404\tvalid_1's auc: 0.786248\tvalid_1's binary_logloss: 0.106119\n",
      "[98]\ttraining's auc: 0.818902\ttraining's binary_logloss: 0.071534\tvalid_1's auc: 0.786302\tvalid_1's binary_logloss: 0.106112\n",
      "[99]\ttraining's auc: 0.818911\ttraining's binary_logloss: 0.071526\tvalid_1's auc: 0.786098\tvalid_1's binary_logloss: 0.106131\n",
      "[100]\ttraining's auc: 0.81893\ttraining's binary_logloss: 0.0715171\tvalid_1's auc: 0.786155\tvalid_1's binary_logloss: 0.10613\n",
      "[101]\ttraining's auc: 0.818953\ttraining's binary_logloss: 0.0715093\tvalid_1's auc: 0.786286\tvalid_1's binary_logloss: 0.10611\n",
      "[102]\ttraining's auc: 0.818995\ttraining's binary_logloss: 0.0715053\tvalid_1's auc: 0.786287\tvalid_1's binary_logloss: 0.106115\n",
      "[103]\ttraining's auc: 0.819091\ttraining's binary_logloss: 0.0714988\tvalid_1's auc: 0.78631\tvalid_1's binary_logloss: 0.106116\n",
      "[104]\ttraining's auc: 0.819228\ttraining's binary_logloss: 0.0714904\tvalid_1's auc: 0.786354\tvalid_1's binary_logloss: 0.106121\n",
      "[105]\ttraining's auc: 0.819244\ttraining's binary_logloss: 0.0714846\tvalid_1's auc: 0.786111\tvalid_1's binary_logloss: 0.106136\n",
      "[106]\ttraining's auc: 0.819265\ttraining's binary_logloss: 0.071478\tvalid_1's auc: 0.786237\tvalid_1's binary_logloss: 0.106122\n",
      "[107]\ttraining's auc: 0.819366\ttraining's binary_logloss: 0.0714687\tvalid_1's auc: 0.786319\tvalid_1's binary_logloss: 0.106117\n",
      "[108]\ttraining's auc: 0.819407\ttraining's binary_logloss: 0.0714625\tvalid_1's auc: 0.786366\tvalid_1's binary_logloss: 0.106104\n",
      "[109]\ttraining's auc: 0.819394\ttraining's binary_logloss: 0.0714565\tvalid_1's auc: 0.78624\tvalid_1's binary_logloss: 0.106119\n",
      "[110]\ttraining's auc: 0.819456\ttraining's binary_logloss: 0.0714378\tvalid_1's auc: 0.786298\tvalid_1's binary_logloss: 0.106121\n",
      "[111]\ttraining's auc: 0.819495\ttraining's binary_logloss: 0.0714317\tvalid_1's auc: 0.786337\tvalid_1's binary_logloss: 0.106128\n",
      "[112]\ttraining's auc: 0.819593\ttraining's binary_logloss: 0.0714241\tvalid_1's auc: 0.786212\tvalid_1's binary_logloss: 0.10614\n",
      "[113]\ttraining's auc: 0.819588\ttraining's binary_logloss: 0.0714217\tvalid_1's auc: 0.786266\tvalid_1's binary_logloss: 0.106136\n",
      "[114]\ttraining's auc: 0.819637\ttraining's binary_logloss: 0.0714143\tvalid_1's auc: 0.786454\tvalid_1's binary_logloss: 0.106111\n",
      "[115]\ttraining's auc: 0.819691\ttraining's binary_logloss: 0.0714069\tvalid_1's auc: 0.786437\tvalid_1's binary_logloss: 0.106119\n",
      "[116]\ttraining's auc: 0.819697\ttraining's binary_logloss: 0.0714035\tvalid_1's auc: 0.786476\tvalid_1's binary_logloss: 0.106111\n",
      "[117]\ttraining's auc: 0.81972\ttraining's binary_logloss: 0.0713982\tvalid_1's auc: 0.786557\tvalid_1's binary_logloss: 0.106108\n",
      "[118]\ttraining's auc: 0.819713\ttraining's binary_logloss: 0.0713928\tvalid_1's auc: 0.786523\tvalid_1's binary_logloss: 0.106116\n",
      "[119]\ttraining's auc: 0.819763\ttraining's binary_logloss: 0.0713878\tvalid_1's auc: 0.786595\tvalid_1's binary_logloss: 0.106118\n",
      "[120]\ttraining's auc: 0.819796\ttraining's binary_logloss: 0.0713836\tvalid_1's auc: 0.786625\tvalid_1's binary_logloss: 0.106106\n",
      "[121]\ttraining's auc: 0.819797\ttraining's binary_logloss: 0.0713798\tvalid_1's auc: 0.78641\tvalid_1's binary_logloss: 0.106126\n",
      "[122]\ttraining's auc: 0.81984\ttraining's binary_logloss: 0.0713757\tvalid_1's auc: 0.786368\tvalid_1's binary_logloss: 0.106127\n",
      "[123]\ttraining's auc: 0.819883\ttraining's binary_logloss: 0.0713706\tvalid_1's auc: 0.78633\tvalid_1's binary_logloss: 0.106133\n",
      "[124]\ttraining's auc: 0.819958\ttraining's binary_logloss: 0.0713496\tvalid_1's auc: 0.786431\tvalid_1's binary_logloss: 0.10612\n",
      "[125]\ttraining's auc: 0.820053\ttraining's binary_logloss: 0.0713432\tvalid_1's auc: 0.786387\tvalid_1's binary_logloss: 0.106119\n",
      "[126]\ttraining's auc: 0.820094\ttraining's binary_logloss: 0.0713362\tvalid_1's auc: 0.786264\tvalid_1's binary_logloss: 0.106145\n",
      "[127]\ttraining's auc: 0.820124\ttraining's binary_logloss: 0.0713233\tvalid_1's auc: 0.786321\tvalid_1's binary_logloss: 0.106139\n",
      "[128]\ttraining's auc: 0.82014\ttraining's binary_logloss: 0.0713187\tvalid_1's auc: 0.786278\tvalid_1's binary_logloss: 0.106147\n",
      "[129]\ttraining's auc: 0.820194\ttraining's binary_logloss: 0.0713123\tvalid_1's auc: 0.786063\tvalid_1's binary_logloss: 0.106171\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's auc: 0.810897\ttraining's binary_logloss: 0.073679\tvalid_1's auc: 0.786837\tvalid_1's binary_logloss: 0.106795\n",
      "8\n",
      "[1]\ttraining's auc: 0.741457\ttraining's binary_logloss: 0.0863868\tvalid_1's auc: 0.713623\tvalid_1's binary_logloss: 0.109309\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.78475\ttraining's binary_logloss: 0.0852072\tvalid_1's auc: 0.771443\tvalid_1's binary_logloss: 0.107672\n",
      "[3]\ttraining's auc: 0.789005\ttraining's binary_logloss: 0.0846673\tvalid_1's auc: 0.773894\tvalid_1's binary_logloss: 0.107001\n",
      "[4]\ttraining's auc: 0.785614\ttraining's binary_logloss: 0.0841296\tvalid_1's auc: 0.768015\tvalid_1's binary_logloss: 0.106362\n",
      "[5]\ttraining's auc: 0.79808\ttraining's binary_logloss: 0.0832829\tvalid_1's auc: 0.782823\tvalid_1's binary_logloss: 0.105157\n",
      "[6]\ttraining's auc: 0.798957\ttraining's binary_logloss: 0.0825228\tvalid_1's auc: 0.783147\tvalid_1's binary_logloss: 0.104134\n",
      "[7]\ttraining's auc: 0.799081\ttraining's binary_logloss: 0.0821122\tvalid_1's auc: 0.781683\tvalid_1's binary_logloss: 0.103707\n",
      "[8]\ttraining's auc: 0.799412\ttraining's binary_logloss: 0.0814982\tvalid_1's auc: 0.783838\tvalid_1's binary_logloss: 0.102936\n",
      "[9]\ttraining's auc: 0.801202\ttraining's binary_logloss: 0.0808916\tvalid_1's auc: 0.785921\tvalid_1's binary_logloss: 0.102128\n",
      "[10]\ttraining's auc: 0.801876\ttraining's binary_logloss: 0.0806186\tvalid_1's auc: 0.785232\tvalid_1's binary_logloss: 0.101833\n",
      "[11]\ttraining's auc: 0.802208\ttraining's binary_logloss: 0.0801273\tvalid_1's auc: 0.784914\tvalid_1's binary_logloss: 0.101233\n",
      "[12]\ttraining's auc: 0.802796\ttraining's binary_logloss: 0.0797167\tvalid_1's auc: 0.786252\tvalid_1's binary_logloss: 0.100718\n",
      "[13]\ttraining's auc: 0.802697\ttraining's binary_logloss: 0.0795035\tvalid_1's auc: 0.785844\tvalid_1's binary_logloss: 0.100485\n",
      "[14]\ttraining's auc: 0.80318\ttraining's binary_logloss: 0.0791192\tvalid_1's auc: 0.786648\tvalid_1's binary_logloss: 0.100034\n",
      "[15]\ttraining's auc: 0.803128\ttraining's binary_logloss: 0.0787713\tvalid_1's auc: 0.787153\tvalid_1's binary_logloss: 0.0996265\n",
      "[16]\ttraining's auc: 0.803674\ttraining's binary_logloss: 0.0784644\tvalid_1's auc: 0.787695\tvalid_1's binary_logloss: 0.09926\n",
      "[17]\ttraining's auc: 0.804562\ttraining's binary_logloss: 0.0782762\tvalid_1's auc: 0.787497\tvalid_1's binary_logloss: 0.0990753\n",
      "[18]\ttraining's auc: 0.804588\ttraining's binary_logloss: 0.0780198\tvalid_1's auc: 0.787855\tvalid_1's binary_logloss: 0.0987797\n",
      "[19]\ttraining's auc: 0.804856\ttraining's binary_logloss: 0.0777733\tvalid_1's auc: 0.788215\tvalid_1's binary_logloss: 0.0984624\n",
      "[20]\ttraining's auc: 0.805389\ttraining's binary_logloss: 0.0776052\tvalid_1's auc: 0.788883\tvalid_1's binary_logloss: 0.0982687\n",
      "[21]\ttraining's auc: 0.80535\ttraining's binary_logloss: 0.0774064\tvalid_1's auc: 0.789094\tvalid_1's binary_logloss: 0.0980445\n",
      "[22]\ttraining's auc: 0.805832\ttraining's binary_logloss: 0.0772279\tvalid_1's auc: 0.789989\tvalid_1's binary_logloss: 0.0978326\n",
      "[23]\ttraining's auc: 0.805626\ttraining's binary_logloss: 0.0770947\tvalid_1's auc: 0.789626\tvalid_1's binary_logloss: 0.0977211\n",
      "[24]\ttraining's auc: 0.805821\ttraining's binary_logloss: 0.0769216\tvalid_1's auc: 0.789687\tvalid_1's binary_logloss: 0.0975427\n",
      "[25]\ttraining's auc: 0.806713\ttraining's binary_logloss: 0.0767715\tvalid_1's auc: 0.790581\tvalid_1's binary_logloss: 0.0973363\n",
      "[26]\ttraining's auc: 0.806634\ttraining's binary_logloss: 0.0766375\tvalid_1's auc: 0.790566\tvalid_1's binary_logloss: 0.0972061\n",
      "[27]\ttraining's auc: 0.806535\ttraining's binary_logloss: 0.0765064\tvalid_1's auc: 0.79047\tvalid_1's binary_logloss: 0.0970804\n",
      "[28]\ttraining's auc: 0.807531\ttraining's binary_logloss: 0.0764124\tvalid_1's auc: 0.791324\tvalid_1's binary_logloss: 0.0969867\n",
      "[29]\ttraining's auc: 0.80751\ttraining's binary_logloss: 0.0763011\tvalid_1's auc: 0.79131\tvalid_1's binary_logloss: 0.0968865\n",
      "[30]\ttraining's auc: 0.807677\ttraining's binary_logloss: 0.0761941\tvalid_1's auc: 0.791657\tvalid_1's binary_logloss: 0.0967636\n",
      "[31]\ttraining's auc: 0.808178\ttraining's binary_logloss: 0.0760931\tvalid_1's auc: 0.792211\tvalid_1's binary_logloss: 0.0966492\n",
      "[32]\ttraining's auc: 0.808237\ttraining's binary_logloss: 0.0760263\tvalid_1's auc: 0.791882\tvalid_1's binary_logloss: 0.0966079\n",
      "[33]\ttraining's auc: 0.808377\ttraining's binary_logloss: 0.0759377\tvalid_1's auc: 0.792189\tvalid_1's binary_logloss: 0.0965059\n",
      "[34]\ttraining's auc: 0.808753\ttraining's binary_logloss: 0.0758853\tvalid_1's auc: 0.792333\tvalid_1's binary_logloss: 0.096474\n",
      "[35]\ttraining's auc: 0.808806\ttraining's binary_logloss: 0.0758101\tvalid_1's auc: 0.79303\tvalid_1's binary_logloss: 0.096386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36]\ttraining's auc: 0.808827\ttraining's binary_logloss: 0.0757494\tvalid_1's auc: 0.79308\tvalid_1's binary_logloss: 0.096316\n",
      "[37]\ttraining's auc: 0.809183\ttraining's binary_logloss: 0.0756719\tvalid_1's auc: 0.793709\tvalid_1's binary_logloss: 0.0962386\n",
      "[38]\ttraining's auc: 0.809257\ttraining's binary_logloss: 0.0756061\tvalid_1's auc: 0.794152\tvalid_1's binary_logloss: 0.0961597\n",
      "[39]\ttraining's auc: 0.809687\ttraining's binary_logloss: 0.0755395\tvalid_1's auc: 0.795144\tvalid_1's binary_logloss: 0.0960838\n",
      "[40]\ttraining's auc: 0.810185\ttraining's binary_logloss: 0.0754849\tvalid_1's auc: 0.795615\tvalid_1's binary_logloss: 0.0960232\n",
      "[41]\ttraining's auc: 0.810688\ttraining's binary_logloss: 0.0754276\tvalid_1's auc: 0.795945\tvalid_1's binary_logloss: 0.0959741\n",
      "[42]\ttraining's auc: 0.810748\ttraining's binary_logloss: 0.0753825\tvalid_1's auc: 0.795922\tvalid_1's binary_logloss: 0.0959403\n",
      "[43]\ttraining's auc: 0.811063\ttraining's binary_logloss: 0.0753409\tvalid_1's auc: 0.796153\tvalid_1's binary_logloss: 0.0959146\n",
      "[44]\ttraining's auc: 0.811224\ttraining's binary_logloss: 0.0752957\tvalid_1's auc: 0.796235\tvalid_1's binary_logloss: 0.0958662\n",
      "[45]\ttraining's auc: 0.811098\ttraining's binary_logloss: 0.0752433\tvalid_1's auc: 0.79586\tvalid_1's binary_logloss: 0.0958438\n",
      "[46]\ttraining's auc: 0.811677\ttraining's binary_logloss: 0.0751984\tvalid_1's auc: 0.796908\tvalid_1's binary_logloss: 0.095804\n",
      "[47]\ttraining's auc: 0.812068\ttraining's binary_logloss: 0.0751517\tvalid_1's auc: 0.797222\tvalid_1's binary_logloss: 0.0957643\n",
      "[48]\ttraining's auc: 0.812068\ttraining's binary_logloss: 0.0751066\tvalid_1's auc: 0.797407\tvalid_1's binary_logloss: 0.0957303\n",
      "[49]\ttraining's auc: 0.812315\ttraining's binary_logloss: 0.0750742\tvalid_1's auc: 0.797742\tvalid_1's binary_logloss: 0.0957043\n",
      "[50]\ttraining's auc: 0.812193\ttraining's binary_logloss: 0.075035\tvalid_1's auc: 0.797805\tvalid_1's binary_logloss: 0.0956603\n",
      "[51]\ttraining's auc: 0.812398\ttraining's binary_logloss: 0.0750107\tvalid_1's auc: 0.79826\tvalid_1's binary_logloss: 0.0956265\n",
      "[52]\ttraining's auc: 0.812448\ttraining's binary_logloss: 0.0749867\tvalid_1's auc: 0.7984\tvalid_1's binary_logloss: 0.0956\n",
      "[53]\ttraining's auc: 0.812505\ttraining's binary_logloss: 0.0749668\tvalid_1's auc: 0.798497\tvalid_1's binary_logloss: 0.0955708\n",
      "[54]\ttraining's auc: 0.812613\ttraining's binary_logloss: 0.0749391\tvalid_1's auc: 0.798727\tvalid_1's binary_logloss: 0.0955301\n",
      "[55]\ttraining's auc: 0.812745\ttraining's binary_logloss: 0.0749106\tvalid_1's auc: 0.798982\tvalid_1's binary_logloss: 0.0954986\n",
      "[56]\ttraining's auc: 0.813099\ttraining's binary_logloss: 0.0748768\tvalid_1's auc: 0.799148\tvalid_1's binary_logloss: 0.0954647\n",
      "[57]\ttraining's auc: 0.81328\ttraining's binary_logloss: 0.0748458\tvalid_1's auc: 0.799214\tvalid_1's binary_logloss: 0.0954446\n",
      "[58]\ttraining's auc: 0.813451\ttraining's binary_logloss: 0.074818\tvalid_1's auc: 0.799341\tvalid_1's binary_logloss: 0.0954327\n",
      "[59]\ttraining's auc: 0.813605\ttraining's binary_logloss: 0.0747929\tvalid_1's auc: 0.799612\tvalid_1's binary_logloss: 0.0954051\n",
      "[60]\ttraining's auc: 0.813714\ttraining's binary_logloss: 0.0747701\tvalid_1's auc: 0.799803\tvalid_1's binary_logloss: 0.0953861\n",
      "[61]\ttraining's auc: 0.813634\ttraining's binary_logloss: 0.0747407\tvalid_1's auc: 0.799942\tvalid_1's binary_logloss: 0.095374\n",
      "[62]\ttraining's auc: 0.813535\ttraining's binary_logloss: 0.074717\tvalid_1's auc: 0.800097\tvalid_1's binary_logloss: 0.0953561\n",
      "[63]\ttraining's auc: 0.813521\ttraining's binary_logloss: 0.0746957\tvalid_1's auc: 0.800189\tvalid_1's binary_logloss: 0.0953438\n",
      "[64]\ttraining's auc: 0.813528\ttraining's binary_logloss: 0.0746753\tvalid_1's auc: 0.800102\tvalid_1's binary_logloss: 0.0953255\n",
      "[65]\ttraining's auc: 0.81357\ttraining's binary_logloss: 0.0746536\tvalid_1's auc: 0.800311\tvalid_1's binary_logloss: 0.0953072\n",
      "[66]\ttraining's auc: 0.81374\ttraining's binary_logloss: 0.0746377\tvalid_1's auc: 0.800546\tvalid_1's binary_logloss: 0.0952973\n",
      "[67]\ttraining's auc: 0.813874\ttraining's binary_logloss: 0.0746233\tvalid_1's auc: 0.800887\tvalid_1's binary_logloss: 0.095278\n",
      "[68]\ttraining's auc: 0.814143\ttraining's binary_logloss: 0.0746075\tvalid_1's auc: 0.801114\tvalid_1's binary_logloss: 0.0952652\n",
      "[69]\ttraining's auc: 0.814221\ttraining's binary_logloss: 0.0745928\tvalid_1's auc: 0.801133\tvalid_1's binary_logloss: 0.0952573\n",
      "[70]\ttraining's auc: 0.814284\ttraining's binary_logloss: 0.0745781\tvalid_1's auc: 0.801393\tvalid_1's binary_logloss: 0.095239\n",
      "[71]\ttraining's auc: 0.814368\ttraining's binary_logloss: 0.0745616\tvalid_1's auc: 0.801597\tvalid_1's binary_logloss: 0.0952229\n",
      "[72]\ttraining's auc: 0.814504\ttraining's binary_logloss: 0.0745431\tvalid_1's auc: 0.802012\tvalid_1's binary_logloss: 0.0952005\n",
      "[73]\ttraining's auc: 0.814563\ttraining's binary_logloss: 0.0745305\tvalid_1's auc: 0.801893\tvalid_1's binary_logloss: 0.0952057\n",
      "[74]\ttraining's auc: 0.814562\ttraining's binary_logloss: 0.074523\tvalid_1's auc: 0.802004\tvalid_1's binary_logloss: 0.0952063\n",
      "[75]\ttraining's auc: 0.814597\ttraining's binary_logloss: 0.074509\tvalid_1's auc: 0.80196\tvalid_1's binary_logloss: 0.0951936\n",
      "[76]\ttraining's auc: 0.814794\ttraining's binary_logloss: 0.0744949\tvalid_1's auc: 0.802097\tvalid_1's binary_logloss: 0.0951746\n",
      "[77]\ttraining's auc: 0.814982\ttraining's binary_logloss: 0.0744796\tvalid_1's auc: 0.802227\tvalid_1's binary_logloss: 0.0951714\n",
      "[78]\ttraining's auc: 0.815019\ttraining's binary_logloss: 0.0744618\tvalid_1's auc: 0.802245\tvalid_1's binary_logloss: 0.0951604\n",
      "[79]\ttraining's auc: 0.815101\ttraining's binary_logloss: 0.0744485\tvalid_1's auc: 0.802421\tvalid_1's binary_logloss: 0.0951487\n",
      "[80]\ttraining's auc: 0.815151\ttraining's binary_logloss: 0.0744375\tvalid_1's auc: 0.802459\tvalid_1's binary_logloss: 0.0951442\n",
      "[81]\ttraining's auc: 0.815267\ttraining's binary_logloss: 0.0744249\tvalid_1's auc: 0.802373\tvalid_1's binary_logloss: 0.0951374\n",
      "[82]\ttraining's auc: 0.815474\ttraining's binary_logloss: 0.0744142\tvalid_1's auc: 0.802474\tvalid_1's binary_logloss: 0.0951315\n",
      "[83]\ttraining's auc: 0.81549\ttraining's binary_logloss: 0.0744026\tvalid_1's auc: 0.802452\tvalid_1's binary_logloss: 0.0951299\n",
      "[84]\ttraining's auc: 0.815595\ttraining's binary_logloss: 0.0743925\tvalid_1's auc: 0.802392\tvalid_1's binary_logloss: 0.0951259\n",
      "[85]\ttraining's auc: 0.815746\ttraining's binary_logloss: 0.0743791\tvalid_1's auc: 0.802338\tvalid_1's binary_logloss: 0.0951217\n",
      "[86]\ttraining's auc: 0.815849\ttraining's binary_logloss: 0.0743631\tvalid_1's auc: 0.802344\tvalid_1's binary_logloss: 0.095118\n",
      "[87]\ttraining's auc: 0.815906\ttraining's binary_logloss: 0.0743547\tvalid_1's auc: 0.802452\tvalid_1's binary_logloss: 0.0951125\n",
      "[88]\ttraining's auc: 0.815987\ttraining's binary_logloss: 0.0743414\tvalid_1's auc: 0.80263\tvalid_1's binary_logloss: 0.0950959\n",
      "[89]\ttraining's auc: 0.816043\ttraining's binary_logloss: 0.0743305\tvalid_1's auc: 0.802659\tvalid_1's binary_logloss: 0.0950899\n",
      "[90]\ttraining's auc: 0.816042\ttraining's binary_logloss: 0.0743172\tvalid_1's auc: 0.802765\tvalid_1's binary_logloss: 0.0950777\n",
      "[91]\ttraining's auc: 0.816235\ttraining's binary_logloss: 0.0743045\tvalid_1's auc: 0.802469\tvalid_1's binary_logloss: 0.0950805\n",
      "[92]\ttraining's auc: 0.816398\ttraining's binary_logloss: 0.0742931\tvalid_1's auc: 0.802498\tvalid_1's binary_logloss: 0.0950739\n",
      "[93]\ttraining's auc: 0.816512\ttraining's binary_logloss: 0.0742855\tvalid_1's auc: 0.802584\tvalid_1's binary_logloss: 0.0950732\n",
      "[94]\ttraining's auc: 0.816609\ttraining's binary_logloss: 0.0742719\tvalid_1's auc: 0.802594\tvalid_1's binary_logloss: 0.0950556\n",
      "[95]\ttraining's auc: 0.816697\ttraining's binary_logloss: 0.0742655\tvalid_1's auc: 0.802682\tvalid_1's binary_logloss: 0.0950482\n",
      "[96]\ttraining's auc: 0.816718\ttraining's binary_logloss: 0.0742601\tvalid_1's auc: 0.802768\tvalid_1's binary_logloss: 0.0950436\n",
      "[97]\ttraining's auc: 0.816783\ttraining's binary_logloss: 0.0742516\tvalid_1's auc: 0.80278\tvalid_1's binary_logloss: 0.0950438\n",
      "[98]\ttraining's auc: 0.816798\ttraining's binary_logloss: 0.0742465\tvalid_1's auc: 0.802738\tvalid_1's binary_logloss: 0.0950419\n",
      "[99]\ttraining's auc: 0.816856\ttraining's binary_logloss: 0.0742133\tvalid_1's auc: 0.802645\tvalid_1's binary_logloss: 0.0950279\n",
      "[100]\ttraining's auc: 0.816887\ttraining's binary_logloss: 0.0742047\tvalid_1's auc: 0.802575\tvalid_1's binary_logloss: 0.0950374\n",
      "[101]\ttraining's auc: 0.816917\ttraining's binary_logloss: 0.0742003\tvalid_1's auc: 0.802561\tvalid_1's binary_logloss: 0.0950398\n",
      "[102]\ttraining's auc: 0.816939\ttraining's binary_logloss: 0.0741954\tvalid_1's auc: 0.802565\tvalid_1's binary_logloss: 0.0950353\n",
      "[103]\ttraining's auc: 0.816968\ttraining's binary_logloss: 0.074186\tvalid_1's auc: 0.802548\tvalid_1's binary_logloss: 0.0950288\n",
      "[104]\ttraining's auc: 0.816986\ttraining's binary_logloss: 0.0741787\tvalid_1's auc: 0.802492\tvalid_1's binary_logloss: 0.0950306\n",
      "[105]\ttraining's auc: 0.817076\ttraining's binary_logloss: 0.0741712\tvalid_1's auc: 0.802443\tvalid_1's binary_logloss: 0.0950379\n",
      "[106]\ttraining's auc: 0.8174\ttraining's binary_logloss: 0.0741545\tvalid_1's auc: 0.802431\tvalid_1's binary_logloss: 0.0950465\n",
      "[107]\ttraining's auc: 0.817488\ttraining's binary_logloss: 0.074146\tvalid_1's auc: 0.802481\tvalid_1's binary_logloss: 0.0950438\n",
      "[108]\ttraining's auc: 0.8176\ttraining's binary_logloss: 0.0741379\tvalid_1's auc: 0.802441\tvalid_1's binary_logloss: 0.0950526\n",
      "[109]\ttraining's auc: 0.817602\ttraining's binary_logloss: 0.0741324\tvalid_1's auc: 0.802397\tvalid_1's binary_logloss: 0.0950563\n",
      "[110]\ttraining's auc: 0.817592\ttraining's binary_logloss: 0.0741088\tvalid_1's auc: 0.802309\tvalid_1's binary_logloss: 0.0950496\n",
      "[111]\ttraining's auc: 0.817624\ttraining's binary_logloss: 0.0741037\tvalid_1's auc: 0.802315\tvalid_1's binary_logloss: 0.0950413\n",
      "[112]\ttraining's auc: 0.817633\ttraining's binary_logloss: 0.0740973\tvalid_1's auc: 0.802264\tvalid_1's binary_logloss: 0.0950462\n",
      "[113]\ttraining's auc: 0.817686\ttraining's binary_logloss: 0.0740862\tvalid_1's auc: 0.802315\tvalid_1's binary_logloss: 0.0950487\n",
      "[114]\ttraining's auc: 0.817811\ttraining's binary_logloss: 0.0740763\tvalid_1's auc: 0.802212\tvalid_1's binary_logloss: 0.0950592\n",
      "[115]\ttraining's auc: 0.817815\ttraining's binary_logloss: 0.0740722\tvalid_1's auc: 0.802149\tvalid_1's binary_logloss: 0.0950681\n",
      "[116]\ttraining's auc: 0.817916\ttraining's binary_logloss: 0.0740635\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.095063\n",
      "[117]\ttraining's auc: 0.817986\ttraining's binary_logloss: 0.0740543\tvalid_1's auc: 0.802053\tvalid_1's binary_logloss: 0.0950708\n",
      "[118]\ttraining's auc: 0.818105\ttraining's binary_logloss: 0.0740477\tvalid_1's auc: 0.80198\tvalid_1's binary_logloss: 0.0950694\n",
      "[119]\ttraining's auc: 0.81822\ttraining's binary_logloss: 0.0740386\tvalid_1's auc: 0.801948\tvalid_1's binary_logloss: 0.0950725\n",
      "[120]\ttraining's auc: 0.818257\ttraining's binary_logloss: 0.0740326\tvalid_1's auc: 0.801958\tvalid_1's binary_logloss: 0.0950768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121]\ttraining's auc: 0.818331\ttraining's binary_logloss: 0.0740275\tvalid_1's auc: 0.801952\tvalid_1's binary_logloss: 0.0950769\n",
      "[122]\ttraining's auc: 0.818439\ttraining's binary_logloss: 0.0740214\tvalid_1's auc: 0.801875\tvalid_1's binary_logloss: 0.0950907\n",
      "[123]\ttraining's auc: 0.818463\ttraining's binary_logloss: 0.0740155\tvalid_1's auc: 0.80186\tvalid_1's binary_logloss: 0.0950991\n",
      "[124]\ttraining's auc: 0.818456\ttraining's binary_logloss: 0.0739921\tvalid_1's auc: 0.801753\tvalid_1's binary_logloss: 0.095094\n",
      "[125]\ttraining's auc: 0.818562\ttraining's binary_logloss: 0.0739821\tvalid_1's auc: 0.801819\tvalid_1's binary_logloss: 0.0950942\n",
      "[126]\ttraining's auc: 0.818554\ttraining's binary_logloss: 0.0739783\tvalid_1's auc: 0.801738\tvalid_1's binary_logloss: 0.0951069\n",
      "[127]\ttraining's auc: 0.81862\ttraining's binary_logloss: 0.0739709\tvalid_1's auc: 0.801746\tvalid_1's binary_logloss: 0.0951167\n",
      "[128]\ttraining's auc: 0.818659\ttraining's binary_logloss: 0.0739662\tvalid_1's auc: 0.801785\tvalid_1's binary_logloss: 0.0951113\n",
      "[129]\ttraining's auc: 0.818665\ttraining's binary_logloss: 0.0739622\tvalid_1's auc: 0.801756\tvalid_1's binary_logloss: 0.095114\n",
      "[130]\ttraining's auc: 0.818764\ttraining's binary_logloss: 0.0739552\tvalid_1's auc: 0.801818\tvalid_1's binary_logloss: 0.0951088\n",
      "[131]\ttraining's auc: 0.818858\ttraining's binary_logloss: 0.0739478\tvalid_1's auc: 0.801971\tvalid_1's binary_logloss: 0.095105\n",
      "[132]\ttraining's auc: 0.818933\ttraining's binary_logloss: 0.0739425\tvalid_1's auc: 0.801928\tvalid_1's binary_logloss: 0.0951129\n",
      "[133]\ttraining's auc: 0.819071\ttraining's binary_logloss: 0.0739346\tvalid_1's auc: 0.801949\tvalid_1's binary_logloss: 0.0951196\n",
      "[134]\ttraining's auc: 0.819143\ttraining's binary_logloss: 0.0739299\tvalid_1's auc: 0.801949\tvalid_1's binary_logloss: 0.0951235\n",
      "[135]\ttraining's auc: 0.819234\ttraining's binary_logloss: 0.0739223\tvalid_1's auc: 0.801948\tvalid_1's binary_logloss: 0.0951184\n",
      "[136]\ttraining's auc: 0.819415\ttraining's binary_logloss: 0.0739095\tvalid_1's auc: 0.801855\tvalid_1's binary_logloss: 0.09513\n",
      "[137]\ttraining's auc: 0.819446\ttraining's binary_logloss: 0.0739031\tvalid_1's auc: 0.801825\tvalid_1's binary_logloss: 0.0951303\n",
      "[138]\ttraining's auc: 0.819461\ttraining's binary_logloss: 0.0738988\tvalid_1's auc: 0.801859\tvalid_1's binary_logloss: 0.0951259\n",
      "[139]\ttraining's auc: 0.819546\ttraining's binary_logloss: 0.0738929\tvalid_1's auc: 0.801914\tvalid_1's binary_logloss: 0.0951219\n",
      "[140]\ttraining's auc: 0.819603\ttraining's binary_logloss: 0.0738854\tvalid_1's auc: 0.801728\tvalid_1's binary_logloss: 0.0951282\n",
      "[141]\ttraining's auc: 0.81963\ttraining's binary_logloss: 0.0738669\tvalid_1's auc: 0.801777\tvalid_1's binary_logloss: 0.095107\n",
      "[142]\ttraining's auc: 0.819694\ttraining's binary_logloss: 0.0738615\tvalid_1's auc: 0.801859\tvalid_1's binary_logloss: 0.0951036\n",
      "[143]\ttraining's auc: 0.819721\ttraining's binary_logloss: 0.0738539\tvalid_1's auc: 0.801846\tvalid_1's binary_logloss: 0.0951049\n",
      "[144]\ttraining's auc: 0.81965\ttraining's binary_logloss: 0.0738476\tvalid_1's auc: 0.801824\tvalid_1's binary_logloss: 0.0951036\n",
      "[145]\ttraining's auc: 0.819702\ttraining's binary_logloss: 0.0738367\tvalid_1's auc: 0.802133\tvalid_1's binary_logloss: 0.0950777\n",
      "[146]\ttraining's auc: 0.819798\ttraining's binary_logloss: 0.0738278\tvalid_1's auc: 0.802184\tvalid_1's binary_logloss: 0.0950806\n",
      "[147]\ttraining's auc: 0.819812\ttraining's binary_logloss: 0.0738235\tvalid_1's auc: 0.802117\tvalid_1's binary_logloss: 0.0950776\n",
      "[148]\ttraining's auc: 0.819831\ttraining's binary_logloss: 0.0738202\tvalid_1's auc: 0.802007\tvalid_1's binary_logloss: 0.0950854\n",
      "[149]\ttraining's auc: 0.819869\ttraining's binary_logloss: 0.0738173\tvalid_1's auc: 0.802015\tvalid_1's binary_logloss: 0.0950882\n",
      "[150]\ttraining's auc: 0.819959\ttraining's binary_logloss: 0.0738134\tvalid_1's auc: 0.801975\tvalid_1's binary_logloss: 0.0950914\n",
      "[151]\ttraining's auc: 0.819973\ttraining's binary_logloss: 0.0737944\tvalid_1's auc: 0.801927\tvalid_1's binary_logloss: 0.0950848\n",
      "[152]\ttraining's auc: 0.819996\ttraining's binary_logloss: 0.0737901\tvalid_1's auc: 0.802021\tvalid_1's binary_logloss: 0.0950817\n",
      "[153]\ttraining's auc: 0.820003\ttraining's binary_logloss: 0.073786\tvalid_1's auc: 0.801963\tvalid_1's binary_logloss: 0.0950871\n",
      "[154]\ttraining's auc: 0.820087\ttraining's binary_logloss: 0.0737786\tvalid_1's auc: 0.801939\tvalid_1's binary_logloss: 0.0950857\n",
      "[155]\ttraining's auc: 0.820148\ttraining's binary_logloss: 0.0737745\tvalid_1's auc: 0.8019\tvalid_1's binary_logloss: 0.0950877\n",
      "[156]\ttraining's auc: 0.820152\ttraining's binary_logloss: 0.0737723\tvalid_1's auc: 0.801933\tvalid_1's binary_logloss: 0.0950913\n",
      "[157]\ttraining's auc: 0.820185\ttraining's binary_logloss: 0.0737671\tvalid_1's auc: 0.802059\tvalid_1's binary_logloss: 0.0950855\n",
      "[158]\ttraining's auc: 0.820196\ttraining's binary_logloss: 0.0737641\tvalid_1's auc: 0.802073\tvalid_1's binary_logloss: 0.0950863\n",
      "[159]\ttraining's auc: 0.820228\ttraining's binary_logloss: 0.0737492\tvalid_1's auc: 0.802143\tvalid_1's binary_logloss: 0.0950674\n",
      "[160]\ttraining's auc: 0.820263\ttraining's binary_logloss: 0.0737427\tvalid_1's auc: 0.802189\tvalid_1's binary_logloss: 0.0950583\n",
      "[161]\ttraining's auc: 0.820275\ttraining's binary_logloss: 0.0737374\tvalid_1's auc: 0.802206\tvalid_1's binary_logloss: 0.0950577\n",
      "[162]\ttraining's auc: 0.820287\ttraining's binary_logloss: 0.0737342\tvalid_1's auc: 0.802236\tvalid_1's binary_logloss: 0.0950503\n",
      "[163]\ttraining's auc: 0.820297\ttraining's binary_logloss: 0.0737319\tvalid_1's auc: 0.802259\tvalid_1's binary_logloss: 0.0950501\n",
      "[164]\ttraining's auc: 0.820325\ttraining's binary_logloss: 0.0737185\tvalid_1's auc: 0.802264\tvalid_1's binary_logloss: 0.0950552\n",
      "[165]\ttraining's auc: 0.820341\ttraining's binary_logloss: 0.0737166\tvalid_1's auc: 0.802289\tvalid_1's binary_logloss: 0.0950501\n",
      "[166]\ttraining's auc: 0.820339\ttraining's binary_logloss: 0.073715\tvalid_1's auc: 0.80236\tvalid_1's binary_logloss: 0.0950499\n",
      "[167]\ttraining's auc: 0.820397\ttraining's binary_logloss: 0.0737079\tvalid_1's auc: 0.802275\tvalid_1's binary_logloss: 0.0950522\n",
      "[168]\ttraining's auc: 0.820458\ttraining's binary_logloss: 0.0737033\tvalid_1's auc: 0.802365\tvalid_1's binary_logloss: 0.0950485\n",
      "[169]\ttraining's auc: 0.820497\ttraining's binary_logloss: 0.0736885\tvalid_1's auc: 0.802386\tvalid_1's binary_logloss: 0.0950428\n",
      "[170]\ttraining's auc: 0.820583\ttraining's binary_logloss: 0.0736822\tvalid_1's auc: 0.802275\tvalid_1's binary_logloss: 0.0950511\n",
      "[171]\ttraining's auc: 0.820591\ttraining's binary_logloss: 0.0736788\tvalid_1's auc: 0.802257\tvalid_1's binary_logloss: 0.0950523\n",
      "[172]\ttraining's auc: 0.82066\ttraining's binary_logloss: 0.0736723\tvalid_1's auc: 0.802133\tvalid_1's binary_logloss: 0.0950562\n",
      "[173]\ttraining's auc: 0.820724\ttraining's binary_logloss: 0.0736681\tvalid_1's auc: 0.802077\tvalid_1's binary_logloss: 0.0950592\n",
      "[174]\ttraining's auc: 0.820824\ttraining's binary_logloss: 0.07366\tvalid_1's auc: 0.802019\tvalid_1's binary_logloss: 0.0950626\n",
      "[175]\ttraining's auc: 0.82091\ttraining's binary_logloss: 0.0736522\tvalid_1's auc: 0.802096\tvalid_1's binary_logloss: 0.0950604\n",
      "[176]\ttraining's auc: 0.820943\ttraining's binary_logloss: 0.073649\tvalid_1's auc: 0.8022\tvalid_1's binary_logloss: 0.0950437\n",
      "[177]\ttraining's auc: 0.820964\ttraining's binary_logloss: 0.0736455\tvalid_1's auc: 0.802107\tvalid_1's binary_logloss: 0.0950517\n",
      "[178]\ttraining's auc: 0.82104\ttraining's binary_logloss: 0.0736381\tvalid_1's auc: 0.802185\tvalid_1's binary_logloss: 0.0950498\n",
      "[179]\ttraining's auc: 0.821046\ttraining's binary_logloss: 0.0736369\tvalid_1's auc: 0.802196\tvalid_1's binary_logloss: 0.095051\n",
      "[180]\ttraining's auc: 0.821092\ttraining's binary_logloss: 0.0736316\tvalid_1's auc: 0.802213\tvalid_1's binary_logloss: 0.0950498\n",
      "[181]\ttraining's auc: 0.821091\ttraining's binary_logloss: 0.0736285\tvalid_1's auc: 0.802195\tvalid_1's binary_logloss: 0.0950463\n",
      "[182]\ttraining's auc: 0.821173\ttraining's binary_logloss: 0.073623\tvalid_1's auc: 0.802054\tvalid_1's binary_logloss: 0.0950586\n",
      "[183]\ttraining's auc: 0.821276\ttraining's binary_logloss: 0.0736181\tvalid_1's auc: 0.802058\tvalid_1's binary_logloss: 0.0950551\n",
      "[184]\ttraining's auc: 0.821302\ttraining's binary_logloss: 0.0736146\tvalid_1's auc: 0.80196\tvalid_1's binary_logloss: 0.0950624\n",
      "[185]\ttraining's auc: 0.821323\ttraining's binary_logloss: 0.0736109\tvalid_1's auc: 0.802067\tvalid_1's binary_logloss: 0.0950555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[186]\ttraining's auc: 0.82134\ttraining's binary_logloss: 0.0736078\tvalid_1's auc: 0.802099\tvalid_1's binary_logloss: 0.0950544\n",
      "[187]\ttraining's auc: 0.821335\ttraining's binary_logloss: 0.0736012\tvalid_1's auc: 0.802016\tvalid_1's binary_logloss: 0.0950511\n",
      "[188]\ttraining's auc: 0.821401\ttraining's binary_logloss: 0.0735963\tvalid_1's auc: 0.801984\tvalid_1's binary_logloss: 0.0950564\n",
      "[189]\ttraining's auc: 0.821433\ttraining's binary_logloss: 0.073592\tvalid_1's auc: 0.801796\tvalid_1's binary_logloss: 0.0950681\n",
      "[190]\ttraining's auc: 0.821438\ttraining's binary_logloss: 0.0735892\tvalid_1's auc: 0.801722\tvalid_1's binary_logloss: 0.0950749\n",
      "[191]\ttraining's auc: 0.821501\ttraining's binary_logloss: 0.0735838\tvalid_1's auc: 0.801653\tvalid_1's binary_logloss: 0.0950755\n",
      "[192]\ttraining's auc: 0.821515\ttraining's binary_logloss: 0.0735815\tvalid_1's auc: 0.80165\tvalid_1's binary_logloss: 0.0950761\n",
      "[193]\ttraining's auc: 0.82166\ttraining's binary_logloss: 0.0735721\tvalid_1's auc: 0.801594\tvalid_1's binary_logloss: 0.0950799\n",
      "[194]\ttraining's auc: 0.821713\ttraining's binary_logloss: 0.0735686\tvalid_1's auc: 0.801585\tvalid_1's binary_logloss: 0.0950764\n",
      "[195]\ttraining's auc: 0.821698\ttraining's binary_logloss: 0.0735666\tvalid_1's auc: 0.801527\tvalid_1's binary_logloss: 0.0950831\n",
      "[196]\ttraining's auc: 0.821752\ttraining's binary_logloss: 0.0735631\tvalid_1's auc: 0.801404\tvalid_1's binary_logloss: 0.0950923\n",
      "[197]\ttraining's auc: 0.821803\ttraining's binary_logloss: 0.0735478\tvalid_1's auc: 0.80142\tvalid_1's binary_logloss: 0.0950945\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's auc: 0.816783\ttraining's binary_logloss: 0.0742516\tvalid_1's auc: 0.80278\tvalid_1's binary_logloss: 0.0950438\n",
      "8\n",
      "[1]\ttraining's auc: 0.730347\ttraining's binary_logloss: 0.0973531\tvalid_1's auc: 0.746153\tvalid_1's binary_logloss: 0.0662543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.784643\ttraining's binary_logloss: 0.0959369\tvalid_1's auc: 0.790691\tvalid_1's binary_logloss: 0.0654012\n",
      "[3]\ttraining's auc: 0.789082\ttraining's binary_logloss: 0.0953758\tvalid_1's auc: 0.802344\tvalid_1's binary_logloss: 0.0649805\n",
      "[4]\ttraining's auc: 0.786326\ttraining's binary_logloss: 0.0948066\tvalid_1's auc: 0.799455\tvalid_1's binary_logloss: 0.0645839\n",
      "[5]\ttraining's auc: 0.791919\ttraining's binary_logloss: 0.0938076\tvalid_1's auc: 0.805947\tvalid_1's binary_logloss: 0.0638862\n",
      "[6]\ttraining's auc: 0.791494\ttraining's binary_logloss: 0.0930058\tvalid_1's auc: 0.804091\tvalid_1's binary_logloss: 0.0633804\n",
      "[7]\ttraining's auc: 0.792345\ttraining's binary_logloss: 0.0926092\tvalid_1's auc: 0.804251\tvalid_1's binary_logloss: 0.0630972\n",
      "[8]\ttraining's auc: 0.793064\ttraining's binary_logloss: 0.0919349\tvalid_1's auc: 0.80601\tvalid_1's binary_logloss: 0.0625998\n",
      "[9]\ttraining's auc: 0.794182\ttraining's binary_logloss: 0.0913051\tvalid_1's auc: 0.808126\tvalid_1's binary_logloss: 0.0621007\n",
      "[10]\ttraining's auc: 0.794928\ttraining's binary_logloss: 0.0910205\tvalid_1's auc: 0.80572\tvalid_1's binary_logloss: 0.0618922\n",
      "[11]\ttraining's auc: 0.79524\ttraining's binary_logloss: 0.090501\tvalid_1's auc: 0.80703\tvalid_1's binary_logloss: 0.0614723\n",
      "[12]\ttraining's auc: 0.79574\ttraining's binary_logloss: 0.0900586\tvalid_1's auc: 0.808318\tvalid_1's binary_logloss: 0.0611114\n",
      "[13]\ttraining's auc: 0.79546\ttraining's binary_logloss: 0.0898371\tvalid_1's auc: 0.806084\tvalid_1's binary_logloss: 0.0609427\n",
      "[14]\ttraining's auc: 0.795859\ttraining's binary_logloss: 0.0894495\tvalid_1's auc: 0.807249\tvalid_1's binary_logloss: 0.060596\n",
      "[15]\ttraining's auc: 0.796052\ttraining's binary_logloss: 0.0890783\tvalid_1's auc: 0.808929\tvalid_1's binary_logloss: 0.0602894\n",
      "[16]\ttraining's auc: 0.796931\ttraining's binary_logloss: 0.0887567\tvalid_1's auc: 0.809481\tvalid_1's binary_logloss: 0.0600169\n",
      "[17]\ttraining's auc: 0.797487\ttraining's binary_logloss: 0.0885409\tvalid_1's auc: 0.810306\tvalid_1's binary_logloss: 0.0598276\n",
      "[18]\ttraining's auc: 0.797386\ttraining's binary_logloss: 0.088272\tvalid_1's auc: 0.810957\tvalid_1's binary_logloss: 0.0595831\n",
      "[19]\ttraining's auc: 0.797783\ttraining's binary_logloss: 0.0880119\tvalid_1's auc: 0.811418\tvalid_1's binary_logloss: 0.0593429\n",
      "[20]\ttraining's auc: 0.799486\ttraining's binary_logloss: 0.0878218\tvalid_1's auc: 0.810457\tvalid_1's binary_logloss: 0.0591831\n",
      "[21]\ttraining's auc: 0.799557\ttraining's binary_logloss: 0.0876093\tvalid_1's auc: 0.810367\tvalid_1's binary_logloss: 0.0589851\n",
      "[22]\ttraining's auc: 0.800037\ttraining's binary_logloss: 0.0874158\tvalid_1's auc: 0.811402\tvalid_1's binary_logloss: 0.0587923\n",
      "[23]\ttraining's auc: 0.800854\ttraining's binary_logloss: 0.087263\tvalid_1's auc: 0.811054\tvalid_1's binary_logloss: 0.0586657\n",
      "[24]\ttraining's auc: 0.800888\ttraining's binary_logloss: 0.0870833\tvalid_1's auc: 0.811045\tvalid_1's binary_logloss: 0.0584966\n",
      "[25]\ttraining's auc: 0.801352\ttraining's binary_logloss: 0.0868993\tvalid_1's auc: 0.811509\tvalid_1's binary_logloss: 0.0583259\n",
      "[26]\ttraining's auc: 0.801304\ttraining's binary_logloss: 0.0867486\tvalid_1's auc: 0.811852\tvalid_1's binary_logloss: 0.0581731\n",
      "[27]\ttraining's auc: 0.801356\ttraining's binary_logloss: 0.0866195\tvalid_1's auc: 0.811964\tvalid_1's binary_logloss: 0.058046\n",
      "[28]\ttraining's auc: 0.802675\ttraining's binary_logloss: 0.0865259\tvalid_1's auc: 0.812162\tvalid_1's binary_logloss: 0.0579675\n",
      "[29]\ttraining's auc: 0.802572\ttraining's binary_logloss: 0.0864057\tvalid_1's auc: 0.812596\tvalid_1's binary_logloss: 0.0578267\n",
      "[30]\ttraining's auc: 0.802746\ttraining's binary_logloss: 0.0862843\tvalid_1's auc: 0.813263\tvalid_1's binary_logloss: 0.0576991\n",
      "[31]\ttraining's auc: 0.803172\ttraining's binary_logloss: 0.0861779\tvalid_1's auc: 0.813785\tvalid_1's binary_logloss: 0.0575856\n",
      "[32]\ttraining's auc: 0.80326\ttraining's binary_logloss: 0.0861033\tvalid_1's auc: 0.813827\tvalid_1's binary_logloss: 0.057515\n",
      "[33]\ttraining's auc: 0.803658\ttraining's binary_logloss: 0.0860037\tvalid_1's auc: 0.813718\tvalid_1's binary_logloss: 0.0574186\n",
      "[34]\ttraining's auc: 0.804209\ttraining's binary_logloss: 0.0859439\tvalid_1's auc: 0.813551\tvalid_1's binary_logloss: 0.0573574\n",
      "[35]\ttraining's auc: 0.804444\ttraining's binary_logloss: 0.0858615\tvalid_1's auc: 0.813784\tvalid_1's binary_logloss: 0.0572712\n",
      "[36]\ttraining's auc: 0.804486\ttraining's binary_logloss: 0.0857884\tvalid_1's auc: 0.813859\tvalid_1's binary_logloss: 0.0572145\n",
      "[37]\ttraining's auc: 0.804945\ttraining's binary_logloss: 0.0857096\tvalid_1's auc: 0.81533\tvalid_1's binary_logloss: 0.0571436\n",
      "[38]\ttraining's auc: 0.80507\ttraining's binary_logloss: 0.0856327\tvalid_1's auc: 0.814838\tvalid_1's binary_logloss: 0.0570514\n",
      "[39]\ttraining's auc: 0.805467\ttraining's binary_logloss: 0.0855602\tvalid_1's auc: 0.815411\tvalid_1's binary_logloss: 0.0569847\n",
      "[40]\ttraining's auc: 0.805484\ttraining's binary_logloss: 0.0855052\tvalid_1's auc: 0.814968\tvalid_1's binary_logloss: 0.0569331\n",
      "[41]\ttraining's auc: 0.805575\ttraining's binary_logloss: 0.085437\tvalid_1's auc: 0.814742\tvalid_1's binary_logloss: 0.0568484\n",
      "[42]\ttraining's auc: 0.805705\ttraining's binary_logloss: 0.0853839\tvalid_1's auc: 0.814734\tvalid_1's binary_logloss: 0.0567924\n",
      "[43]\ttraining's auc: 0.805655\ttraining's binary_logloss: 0.0853263\tvalid_1's auc: 0.814792\tvalid_1's binary_logloss: 0.0567316\n",
      "[44]\ttraining's auc: 0.805827\ttraining's binary_logloss: 0.0852791\tvalid_1's auc: 0.814882\tvalid_1's binary_logloss: 0.0566794\n",
      "[45]\ttraining's auc: 0.806062\ttraining's binary_logloss: 0.0852219\tvalid_1's auc: 0.815107\tvalid_1's binary_logloss: 0.0566252\n",
      "[46]\ttraining's auc: 0.805973\ttraining's binary_logloss: 0.0851788\tvalid_1's auc: 0.814832\tvalid_1's binary_logloss: 0.05658\n",
      "[47]\ttraining's auc: 0.8062\ttraining's binary_logloss: 0.0851374\tvalid_1's auc: 0.814829\tvalid_1's binary_logloss: 0.0565284\n",
      "[48]\ttraining's auc: 0.806433\ttraining's binary_logloss: 0.0850893\tvalid_1's auc: 0.81472\tvalid_1's binary_logloss: 0.0564771\n",
      "[49]\ttraining's auc: 0.806647\ttraining's binary_logloss: 0.0850431\tvalid_1's auc: 0.81491\tvalid_1's binary_logloss: 0.0564311\n",
      "[50]\ttraining's auc: 0.806568\ttraining's binary_logloss: 0.0850022\tvalid_1's auc: 0.814637\tvalid_1's binary_logloss: 0.0563811\n",
      "[51]\ttraining's auc: 0.806722\ttraining's binary_logloss: 0.084969\tvalid_1's auc: 0.814831\tvalid_1's binary_logloss: 0.0563503\n",
      "[52]\ttraining's auc: 0.806686\ttraining's binary_logloss: 0.0849264\tvalid_1's auc: 0.815347\tvalid_1's binary_logloss: 0.0563003\n",
      "[53]\ttraining's auc: 0.806864\ttraining's binary_logloss: 0.0849003\tvalid_1's auc: 0.815294\tvalid_1's binary_logloss: 0.0562744\n",
      "[54]\ttraining's auc: 0.807012\ttraining's binary_logloss: 0.0848644\tvalid_1's auc: 0.815161\tvalid_1's binary_logloss: 0.0562394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55]\ttraining's auc: 0.807071\ttraining's binary_logloss: 0.0848348\tvalid_1's auc: 0.815044\tvalid_1's binary_logloss: 0.0562107\n",
      "[56]\ttraining's auc: 0.807192\ttraining's binary_logloss: 0.0848079\tvalid_1's auc: 0.815161\tvalid_1's binary_logloss: 0.0561835\n",
      "[57]\ttraining's auc: 0.807266\ttraining's binary_logloss: 0.0847812\tvalid_1's auc: 0.815412\tvalid_1's binary_logloss: 0.0561607\n",
      "[58]\ttraining's auc: 0.807522\ttraining's binary_logloss: 0.0847539\tvalid_1's auc: 0.815017\tvalid_1's binary_logloss: 0.0561352\n",
      "[59]\ttraining's auc: 0.807756\ttraining's binary_logloss: 0.0847271\tvalid_1's auc: 0.815526\tvalid_1's binary_logloss: 0.0561127\n",
      "[60]\ttraining's auc: 0.807906\ttraining's binary_logloss: 0.0847052\tvalid_1's auc: 0.815651\tvalid_1's binary_logloss: 0.0560871\n",
      "[61]\ttraining's auc: 0.807908\ttraining's binary_logloss: 0.0846771\tvalid_1's auc: 0.81586\tvalid_1's binary_logloss: 0.0560598\n",
      "[62]\ttraining's auc: 0.807825\ttraining's binary_logloss: 0.0846535\tvalid_1's auc: 0.815716\tvalid_1's binary_logloss: 0.0560395\n",
      "[63]\ttraining's auc: 0.807979\ttraining's binary_logloss: 0.0846277\tvalid_1's auc: 0.815459\tvalid_1's binary_logloss: 0.0560157\n",
      "[64]\ttraining's auc: 0.808122\ttraining's binary_logloss: 0.084603\tvalid_1's auc: 0.815693\tvalid_1's binary_logloss: 0.0559968\n",
      "[65]\ttraining's auc: 0.808225\ttraining's binary_logloss: 0.084582\tvalid_1's auc: 0.815806\tvalid_1's binary_logloss: 0.0559781\n",
      "[66]\ttraining's auc: 0.80833\ttraining's binary_logloss: 0.0845667\tvalid_1's auc: 0.815883\tvalid_1's binary_logloss: 0.0559607\n",
      "[67]\ttraining's auc: 0.808585\ttraining's binary_logloss: 0.0845463\tvalid_1's auc: 0.815894\tvalid_1's binary_logloss: 0.0559384\n",
      "[68]\ttraining's auc: 0.808854\ttraining's binary_logloss: 0.0845274\tvalid_1's auc: 0.815614\tvalid_1's binary_logloss: 0.0559353\n",
      "[69]\ttraining's auc: 0.808877\ttraining's binary_logloss: 0.0845188\tvalid_1's auc: 0.815212\tvalid_1's binary_logloss: 0.0559384\n",
      "[70]\ttraining's auc: 0.808971\ttraining's binary_logloss: 0.0845027\tvalid_1's auc: 0.815137\tvalid_1's binary_logloss: 0.0559341\n",
      "[71]\ttraining's auc: 0.809045\ttraining's binary_logloss: 0.0844853\tvalid_1's auc: 0.815219\tvalid_1's binary_logloss: 0.055911\n",
      "[72]\ttraining's auc: 0.809042\ttraining's binary_logloss: 0.0844673\tvalid_1's auc: 0.815066\tvalid_1's binary_logloss: 0.0558948\n",
      "[73]\ttraining's auc: 0.809116\ttraining's binary_logloss: 0.0844553\tvalid_1's auc: 0.815337\tvalid_1's binary_logloss: 0.0558831\n",
      "[74]\ttraining's auc: 0.809289\ttraining's binary_logloss: 0.0844443\tvalid_1's auc: 0.815503\tvalid_1's binary_logloss: 0.0558681\n",
      "[75]\ttraining's auc: 0.809309\ttraining's binary_logloss: 0.0844295\tvalid_1's auc: 0.81553\tvalid_1's binary_logloss: 0.0558534\n",
      "[76]\ttraining's auc: 0.809421\ttraining's binary_logloss: 0.0844129\tvalid_1's auc: 0.815692\tvalid_1's binary_logloss: 0.0558498\n",
      "[77]\ttraining's auc: 0.809427\ttraining's binary_logloss: 0.0843957\tvalid_1's auc: 0.81563\tvalid_1's binary_logloss: 0.0558328\n",
      "[78]\ttraining's auc: 0.809453\ttraining's binary_logloss: 0.0843765\tvalid_1's auc: 0.815666\tvalid_1's binary_logloss: 0.0558153\n",
      "[79]\ttraining's auc: 0.809528\ttraining's binary_logloss: 0.0843643\tvalid_1's auc: 0.815543\tvalid_1's binary_logloss: 0.0558216\n",
      "[80]\ttraining's auc: 0.809577\ttraining's binary_logloss: 0.0843499\tvalid_1's auc: 0.81583\tvalid_1's binary_logloss: 0.0557993\n",
      "[81]\ttraining's auc: 0.809609\ttraining's binary_logloss: 0.0843394\tvalid_1's auc: 0.815952\tvalid_1's binary_logloss: 0.0557891\n",
      "[82]\ttraining's auc: 0.809766\ttraining's binary_logloss: 0.0843312\tvalid_1's auc: 0.815966\tvalid_1's binary_logloss: 0.0557922\n",
      "[83]\ttraining's auc: 0.809899\ttraining's binary_logloss: 0.0843101\tvalid_1's auc: 0.816123\tvalid_1's binary_logloss: 0.0557687\n",
      "[84]\ttraining's auc: 0.809947\ttraining's binary_logloss: 0.0843024\tvalid_1's auc: 0.816103\tvalid_1's binary_logloss: 0.0557681\n",
      "[85]\ttraining's auc: 0.810048\ttraining's binary_logloss: 0.0842881\tvalid_1's auc: 0.816454\tvalid_1's binary_logloss: 0.0557638\n",
      "[86]\ttraining's auc: 0.810162\ttraining's binary_logloss: 0.0842728\tvalid_1's auc: 0.816742\tvalid_1's binary_logloss: 0.0557547\n",
      "[87]\ttraining's auc: 0.810217\ttraining's binary_logloss: 0.0842661\tvalid_1's auc: 0.816622\tvalid_1's binary_logloss: 0.0557495\n",
      "[88]\ttraining's auc: 0.81029\ttraining's binary_logloss: 0.0842544\tvalid_1's auc: 0.816682\tvalid_1's binary_logloss: 0.0557426\n",
      "[89]\ttraining's auc: 0.810337\ttraining's binary_logloss: 0.0842415\tvalid_1's auc: 0.816768\tvalid_1's binary_logloss: 0.0557346\n",
      "[90]\ttraining's auc: 0.810397\ttraining's binary_logloss: 0.0842351\tvalid_1's auc: 0.816723\tvalid_1's binary_logloss: 0.0557292\n",
      "[91]\ttraining's auc: 0.810544\ttraining's binary_logloss: 0.0842254\tvalid_1's auc: 0.816725\tvalid_1's binary_logloss: 0.0557352\n",
      "[92]\ttraining's auc: 0.810626\ttraining's binary_logloss: 0.0842153\tvalid_1's auc: 0.816878\tvalid_1's binary_logloss: 0.0557199\n",
      "[93]\ttraining's auc: 0.810682\ttraining's binary_logloss: 0.084208\tvalid_1's auc: 0.817028\tvalid_1's binary_logloss: 0.0557043\n",
      "[94]\ttraining's auc: 0.810723\ttraining's binary_logloss: 0.0841944\tvalid_1's auc: 0.817029\tvalid_1's binary_logloss: 0.0557083\n",
      "[95]\ttraining's auc: 0.810891\ttraining's binary_logloss: 0.0841806\tvalid_1's auc: 0.816979\tvalid_1's binary_logloss: 0.0556996\n",
      "[96]\ttraining's auc: 0.810885\ttraining's binary_logloss: 0.0841726\tvalid_1's auc: 0.816964\tvalid_1's binary_logloss: 0.0556878\n",
      "[97]\ttraining's auc: 0.810904\ttraining's binary_logloss: 0.084164\tvalid_1's auc: 0.816987\tvalid_1's binary_logloss: 0.0556789\n",
      "[98]\ttraining's auc: 0.810969\ttraining's binary_logloss: 0.0841569\tvalid_1's auc: 0.816706\tvalid_1's binary_logloss: 0.0556799\n",
      "[99]\ttraining's auc: 0.811\ttraining's binary_logloss: 0.0841486\tvalid_1's auc: 0.816578\tvalid_1's binary_logloss: 0.0556796\n",
      "[100]\ttraining's auc: 0.811023\ttraining's binary_logloss: 0.0841396\tvalid_1's auc: 0.816573\tvalid_1's binary_logloss: 0.0556673\n",
      "[101]\ttraining's auc: 0.811082\ttraining's binary_logloss: 0.0841317\tvalid_1's auc: 0.816623\tvalid_1's binary_logloss: 0.0556678\n",
      "[102]\ttraining's auc: 0.811115\ttraining's binary_logloss: 0.0841233\tvalid_1's auc: 0.816463\tvalid_1's binary_logloss: 0.0556686\n",
      "[103]\ttraining's auc: 0.811129\ttraining's binary_logloss: 0.0841152\tvalid_1's auc: 0.816507\tvalid_1's binary_logloss: 0.0556573\n",
      "[104]\ttraining's auc: 0.811194\ttraining's binary_logloss: 0.0841038\tvalid_1's auc: 0.81628\tvalid_1's binary_logloss: 0.0556554\n",
      "[105]\ttraining's auc: 0.811221\ttraining's binary_logloss: 0.084099\tvalid_1's auc: 0.81619\tvalid_1's binary_logloss: 0.0556605\n",
      "[106]\ttraining's auc: 0.81131\ttraining's binary_logloss: 0.0840896\tvalid_1's auc: 0.816408\tvalid_1's binary_logloss: 0.055658\n",
      "[107]\ttraining's auc: 0.811319\ttraining's binary_logloss: 0.0840826\tvalid_1's auc: 0.816327\tvalid_1's binary_logloss: 0.0556523\n",
      "[108]\ttraining's auc: 0.811399\ttraining's binary_logloss: 0.084074\tvalid_1's auc: 0.816593\tvalid_1's binary_logloss: 0.0556376\n",
      "[109]\ttraining's auc: 0.811488\ttraining's binary_logloss: 0.0840642\tvalid_1's auc: 0.816672\tvalid_1's binary_logloss: 0.0556311\n",
      "[110]\ttraining's auc: 0.811508\ttraining's binary_logloss: 0.084041\tvalid_1's auc: 0.816725\tvalid_1's binary_logloss: 0.055597\n",
      "[111]\ttraining's auc: 0.811534\ttraining's binary_logloss: 0.0840348\tvalid_1's auc: 0.81679\tvalid_1's binary_logloss: 0.05559\n",
      "[112]\ttraining's auc: 0.811644\ttraining's binary_logloss: 0.0840235\tvalid_1's auc: 0.816695\tvalid_1's binary_logloss: 0.0555803\n",
      "[113]\ttraining's auc: 0.811697\ttraining's binary_logloss: 0.0840188\tvalid_1's auc: 0.816542\tvalid_1's binary_logloss: 0.0555778\n",
      "[114]\ttraining's auc: 0.811812\ttraining's binary_logloss: 0.0840102\tvalid_1's auc: 0.816632\tvalid_1's binary_logloss: 0.055572\n",
      "[115]\ttraining's auc: 0.811866\ttraining's binary_logloss: 0.0839881\tvalid_1's auc: 0.816756\tvalid_1's binary_logloss: 0.055542\n",
      "[116]\ttraining's auc: 0.811941\ttraining's binary_logloss: 0.083982\tvalid_1's auc: 0.816655\tvalid_1's binary_logloss: 0.0555348\n",
      "[117]\ttraining's auc: 0.811962\ttraining's binary_logloss: 0.0839769\tvalid_1's auc: 0.816731\tvalid_1's binary_logloss: 0.0555246\n",
      "[118]\ttraining's auc: 0.812033\ttraining's binary_logloss: 0.0839671\tvalid_1's auc: 0.816513\tvalid_1's binary_logloss: 0.055535\n",
      "[119]\ttraining's auc: 0.812134\ttraining's binary_logloss: 0.083958\tvalid_1's auc: 0.816675\tvalid_1's binary_logloss: 0.0555292\n",
      "[120]\ttraining's auc: 0.812188\ttraining's binary_logloss: 0.0839506\tvalid_1's auc: 0.816855\tvalid_1's binary_logloss: 0.0555269\n",
      "[121]\ttraining's auc: 0.812211\ttraining's binary_logloss: 0.0839447\tvalid_1's auc: 0.816766\tvalid_1's binary_logloss: 0.0555208\n",
      "[122]\ttraining's auc: 0.812209\ttraining's binary_logloss: 0.0839376\tvalid_1's auc: 0.816905\tvalid_1's binary_logloss: 0.0555092\n",
      "[123]\ttraining's auc: 0.812227\ttraining's binary_logloss: 0.083932\tvalid_1's auc: 0.816791\tvalid_1's binary_logloss: 0.0555082\n",
      "[124]\ttraining's auc: 0.812235\ttraining's binary_logloss: 0.0839212\tvalid_1's auc: 0.816807\tvalid_1's binary_logloss: 0.0554858\n",
      "[125]\ttraining's auc: 0.812324\ttraining's binary_logloss: 0.0839061\tvalid_1's auc: 0.816606\tvalid_1's binary_logloss: 0.0554898\n",
      "[126]\ttraining's auc: 0.812445\ttraining's binary_logloss: 0.0838952\tvalid_1's auc: 0.816601\tvalid_1's binary_logloss: 0.0554877\n",
      "[127]\ttraining's auc: 0.812448\ttraining's binary_logloss: 0.0838909\tvalid_1's auc: 0.816622\tvalid_1's binary_logloss: 0.0554798\n",
      "[128]\ttraining's auc: 0.812476\ttraining's binary_logloss: 0.0838855\tvalid_1's auc: 0.816441\tvalid_1's binary_logloss: 0.0554872\n",
      "[129]\ttraining's auc: 0.812541\ttraining's binary_logloss: 0.0838795\tvalid_1's auc: 0.816417\tvalid_1's binary_logloss: 0.0554909\n",
      "[130]\ttraining's auc: 0.812635\ttraining's binary_logloss: 0.0838719\tvalid_1's auc: 0.81634\tvalid_1's binary_logloss: 0.0554934\n",
      "[131]\ttraining's auc: 0.812699\ttraining's binary_logloss: 0.0838656\tvalid_1's auc: 0.816408\tvalid_1's binary_logloss: 0.055488\n",
      "[132]\ttraining's auc: 0.81284\ttraining's binary_logloss: 0.0838555\tvalid_1's auc: 0.816359\tvalid_1's binary_logloss: 0.0554943\n",
      "[133]\ttraining's auc: 0.812861\ttraining's binary_logloss: 0.0838504\tvalid_1's auc: 0.816246\tvalid_1's binary_logloss: 0.0554984\n",
      "[134]\ttraining's auc: 0.812865\ttraining's binary_logloss: 0.0838465\tvalid_1's auc: 0.816282\tvalid_1's binary_logloss: 0.0554834\n",
      "[135]\ttraining's auc: 0.812863\ttraining's binary_logloss: 0.0838421\tvalid_1's auc: 0.816134\tvalid_1's binary_logloss: 0.0554914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[136]\ttraining's auc: 0.812889\ttraining's binary_logloss: 0.0838366\tvalid_1's auc: 0.816153\tvalid_1's binary_logloss: 0.0554912\n",
      "[137]\ttraining's auc: 0.812918\ttraining's binary_logloss: 0.0838319\tvalid_1's auc: 0.816121\tvalid_1's binary_logloss: 0.0554858\n",
      "[138]\ttraining's auc: 0.813006\ttraining's binary_logloss: 0.0838246\tvalid_1's auc: 0.815959\tvalid_1's binary_logloss: 0.0554931\n",
      "[139]\ttraining's auc: 0.813071\ttraining's binary_logloss: 0.0838158\tvalid_1's auc: 0.815998\tvalid_1's binary_logloss: 0.0554945\n",
      "[140]\ttraining's auc: 0.813133\ttraining's binary_logloss: 0.0838078\tvalid_1's auc: 0.815881\tvalid_1's binary_logloss: 0.0554977\n",
      "[141]\ttraining's auc: 0.813199\ttraining's binary_logloss: 0.083801\tvalid_1's auc: 0.815823\tvalid_1's binary_logloss: 0.0555011\n",
      "[142]\ttraining's auc: 0.813305\ttraining's binary_logloss: 0.0837922\tvalid_1's auc: 0.815685\tvalid_1's binary_logloss: 0.055499\n",
      "[143]\ttraining's auc: 0.813375\ttraining's binary_logloss: 0.0837872\tvalid_1's auc: 0.815654\tvalid_1's binary_logloss: 0.0555044\n",
      "[144]\ttraining's auc: 0.813392\ttraining's binary_logloss: 0.0837827\tvalid_1's auc: 0.815709\tvalid_1's binary_logloss: 0.0554975\n",
      "[145]\ttraining's auc: 0.813393\ttraining's binary_logloss: 0.083773\tvalid_1's auc: 0.815679\tvalid_1's binary_logloss: 0.0554819\n",
      "[146]\ttraining's auc: 0.813453\ttraining's binary_logloss: 0.0837654\tvalid_1's auc: 0.815367\tvalid_1's binary_logloss: 0.0554899\n",
      "[147]\ttraining's auc: 0.813504\ttraining's binary_logloss: 0.0837601\tvalid_1's auc: 0.815288\tvalid_1's binary_logloss: 0.0554886\n",
      "[148]\ttraining's auc: 0.813553\ttraining's binary_logloss: 0.083753\tvalid_1's auc: 0.815414\tvalid_1's binary_logloss: 0.0554872\n",
      "[149]\ttraining's auc: 0.813599\ttraining's binary_logloss: 0.0837481\tvalid_1's auc: 0.815351\tvalid_1's binary_logloss: 0.0554927\n",
      "[150]\ttraining's auc: 0.813616\ttraining's binary_logloss: 0.0837454\tvalid_1's auc: 0.815323\tvalid_1's binary_logloss: 0.0554984\n",
      "[151]\ttraining's auc: 0.813628\ttraining's binary_logloss: 0.0837397\tvalid_1's auc: 0.815408\tvalid_1's binary_logloss: 0.0554824\n",
      "[152]\ttraining's auc: 0.813704\ttraining's binary_logloss: 0.0837332\tvalid_1's auc: 0.815281\tvalid_1's binary_logloss: 0.0554865\n",
      "[153]\ttraining's auc: 0.813714\ttraining's binary_logloss: 0.0837292\tvalid_1's auc: 0.815339\tvalid_1's binary_logloss: 0.0554811\n",
      "[154]\ttraining's auc: 0.813726\ttraining's binary_logloss: 0.0837261\tvalid_1's auc: 0.81528\tvalid_1's binary_logloss: 0.0554864\n",
      "[155]\ttraining's auc: 0.813776\ttraining's binary_logloss: 0.0837209\tvalid_1's auc: 0.815182\tvalid_1's binary_logloss: 0.0554883\n",
      "[156]\ttraining's auc: 0.81378\ttraining's binary_logloss: 0.0837193\tvalid_1's auc: 0.815228\tvalid_1's binary_logloss: 0.0554887\n",
      "[157]\ttraining's auc: 0.81383\ttraining's binary_logloss: 0.0837121\tvalid_1's auc: 0.81528\tvalid_1's binary_logloss: 0.0554903\n",
      "[158]\ttraining's auc: 0.813835\ttraining's binary_logloss: 0.0837096\tvalid_1's auc: 0.815256\tvalid_1's binary_logloss: 0.0554954\n",
      "[159]\ttraining's auc: 0.813875\ttraining's binary_logloss: 0.0836899\tvalid_1's auc: 0.815323\tvalid_1's binary_logloss: 0.0554826\n",
      "[160]\ttraining's auc: 0.81393\ttraining's binary_logloss: 0.0836853\tvalid_1's auc: 0.815383\tvalid_1's binary_logloss: 0.0554774\n",
      "[161]\ttraining's auc: 0.813957\ttraining's binary_logloss: 0.0836789\tvalid_1's auc: 0.815375\tvalid_1's binary_logloss: 0.0554705\n",
      "[162]\ttraining's auc: 0.813994\ttraining's binary_logloss: 0.083666\tvalid_1's auc: 0.815531\tvalid_1's binary_logloss: 0.0554527\n",
      "[163]\ttraining's auc: 0.814058\ttraining's binary_logloss: 0.0836602\tvalid_1's auc: 0.815676\tvalid_1's binary_logloss: 0.0554442\n",
      "[164]\ttraining's auc: 0.814085\ttraining's binary_logloss: 0.0836569\tvalid_1's auc: 0.815799\tvalid_1's binary_logloss: 0.0554305\n",
      "[165]\ttraining's auc: 0.814116\ttraining's binary_logloss: 0.083654\tvalid_1's auc: 0.815778\tvalid_1's binary_logloss: 0.0554323\n",
      "[166]\ttraining's auc: 0.814124\ttraining's binary_logloss: 0.083651\tvalid_1's auc: 0.815747\tvalid_1's binary_logloss: 0.0554311\n",
      "[167]\ttraining's auc: 0.814138\ttraining's binary_logloss: 0.0836481\tvalid_1's auc: 0.815762\tvalid_1's binary_logloss: 0.0554241\n",
      "[168]\ttraining's auc: 0.814148\ttraining's binary_logloss: 0.0836438\tvalid_1's auc: 0.815754\tvalid_1's binary_logloss: 0.0554241\n",
      "[169]\ttraining's auc: 0.814178\ttraining's binary_logloss: 0.0836298\tvalid_1's auc: 0.815786\tvalid_1's binary_logloss: 0.0554117\n",
      "[170]\ttraining's auc: 0.814206\ttraining's binary_logloss: 0.0836258\tvalid_1's auc: 0.815884\tvalid_1's binary_logloss: 0.0554081\n",
      "[171]\ttraining's auc: 0.814216\ttraining's binary_logloss: 0.0836227\tvalid_1's auc: 0.815941\tvalid_1's binary_logloss: 0.055397\n",
      "[172]\ttraining's auc: 0.814237\ttraining's binary_logloss: 0.0836109\tvalid_1's auc: 0.815898\tvalid_1's binary_logloss: 0.0553878\n",
      "[173]\ttraining's auc: 0.814302\ttraining's binary_logloss: 0.0836048\tvalid_1's auc: 0.815716\tvalid_1's binary_logloss: 0.0554021\n",
      "[174]\ttraining's auc: 0.814368\ttraining's binary_logloss: 0.0835975\tvalid_1's auc: 0.815631\tvalid_1's binary_logloss: 0.0554097\n",
      "[175]\ttraining's auc: 0.814403\ttraining's binary_logloss: 0.083593\tvalid_1's auc: 0.815677\tvalid_1's binary_logloss: 0.05541\n",
      "[176]\ttraining's auc: 0.814425\ttraining's binary_logloss: 0.083589\tvalid_1's auc: 0.815744\tvalid_1's binary_logloss: 0.055407\n",
      "[177]\ttraining's auc: 0.814426\ttraining's binary_logloss: 0.0835857\tvalid_1's auc: 0.81576\tvalid_1's binary_logloss: 0.0554079\n",
      "[178]\ttraining's auc: 0.814497\ttraining's binary_logloss: 0.0835804\tvalid_1's auc: 0.815944\tvalid_1's binary_logloss: 0.0554055\n",
      "[179]\ttraining's auc: 0.814534\ttraining's binary_logloss: 0.0835758\tvalid_1's auc: 0.815994\tvalid_1's binary_logloss: 0.0554021\n",
      "[180]\ttraining's auc: 0.814579\ttraining's binary_logloss: 0.0835695\tvalid_1's auc: 0.816067\tvalid_1's binary_logloss: 0.0554038\n",
      "[181]\ttraining's auc: 0.81461\ttraining's binary_logloss: 0.0835651\tvalid_1's auc: 0.816039\tvalid_1's binary_logloss: 0.0554052\n",
      "[182]\ttraining's auc: 0.814604\ttraining's binary_logloss: 0.0835579\tvalid_1's auc: 0.815678\tvalid_1's binary_logloss: 0.0554098\n",
      "[183]\ttraining's auc: 0.814646\ttraining's binary_logloss: 0.0835537\tvalid_1's auc: 0.815526\tvalid_1's binary_logloss: 0.0554199\n",
      "[184]\ttraining's auc: 0.814668\ttraining's binary_logloss: 0.0835495\tvalid_1's auc: 0.815537\tvalid_1's binary_logloss: 0.0554238\n",
      "[185]\ttraining's auc: 0.814693\ttraining's binary_logloss: 0.0835455\tvalid_1's auc: 0.815463\tvalid_1's binary_logloss: 0.0554272\n",
      "[186]\ttraining's auc: 0.814727\ttraining's binary_logloss: 0.083542\tvalid_1's auc: 0.815518\tvalid_1's binary_logloss: 0.0554214\n",
      "[187]\ttraining's auc: 0.814759\ttraining's binary_logloss: 0.0835357\tvalid_1's auc: 0.815634\tvalid_1's binary_logloss: 0.0554154\n",
      "[188]\ttraining's auc: 0.814815\ttraining's binary_logloss: 0.0835318\tvalid_1's auc: 0.815721\tvalid_1's binary_logloss: 0.0554208\n",
      "[189]\ttraining's auc: 0.81481\ttraining's binary_logloss: 0.0835295\tvalid_1's auc: 0.815711\tvalid_1's binary_logloss: 0.055416\n",
      "[190]\ttraining's auc: 0.81487\ttraining's binary_logloss: 0.0835239\tvalid_1's auc: 0.815835\tvalid_1's binary_logloss: 0.0554041\n",
      "[191]\ttraining's auc: 0.814906\ttraining's binary_logloss: 0.0835216\tvalid_1's auc: 0.815789\tvalid_1's binary_logloss: 0.0554069\n",
      "[192]\ttraining's auc: 0.814962\ttraining's binary_logloss: 0.083518\tvalid_1's auc: 0.815633\tvalid_1's binary_logloss: 0.055411\n",
      "[193]\ttraining's auc: 0.81498\ttraining's binary_logloss: 0.0835152\tvalid_1's auc: 0.815639\tvalid_1's binary_logloss: 0.0554061\n",
      "[194]\ttraining's auc: 0.814999\ttraining's binary_logloss: 0.083511\tvalid_1's auc: 0.815608\tvalid_1's binary_logloss: 0.0554075\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's auc: 0.810723\ttraining's binary_logloss: 0.0841944\tvalid_1's auc: 0.817029\tvalid_1's binary_logloss: 0.0557083\n",
      "8\n",
      "[1]\ttraining's auc: 0.730749\ttraining's binary_logloss: 0.0961633\tvalid_1's auc: 0.742913\tvalid_1's binary_logloss: 0.0709548\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.784028\ttraining's binary_logloss: 0.0947491\tvalid_1's auc: 0.797433\tvalid_1's binary_logloss: 0.0699955\n",
      "[3]\ttraining's auc: 0.788859\ttraining's binary_logloss: 0.0942243\tvalid_1's auc: 0.804463\tvalid_1's binary_logloss: 0.0695991\n",
      "[4]\ttraining's auc: 0.788094\ttraining's binary_logloss: 0.0936544\tvalid_1's auc: 0.800355\tvalid_1's binary_logloss: 0.069149\n",
      "[5]\ttraining's auc: 0.793122\ttraining's binary_logloss: 0.0926345\tvalid_1's auc: 0.803236\tvalid_1's binary_logloss: 0.068461\n",
      "[6]\ttraining's auc: 0.794215\ttraining's binary_logloss: 0.0917177\tvalid_1's auc: 0.80357\tvalid_1's binary_logloss: 0.0678381\n",
      "[7]\ttraining's auc: 0.794273\ttraining's binary_logloss: 0.0913001\tvalid_1's auc: 0.802532\tvalid_1's binary_logloss: 0.0674945\n",
      "[8]\ttraining's auc: 0.794774\ttraining's binary_logloss: 0.0906156\tvalid_1's auc: 0.802836\tvalid_1's binary_logloss: 0.0670167\n",
      "[9]\ttraining's auc: 0.795662\ttraining's binary_logloss: 0.0899819\tvalid_1's auc: 0.803685\tvalid_1's binary_logloss: 0.0665586\n",
      "[10]\ttraining's auc: 0.796146\ttraining's binary_logloss: 0.0897168\tvalid_1's auc: 0.805366\tvalid_1's binary_logloss: 0.0663114\n",
      "[11]\ttraining's auc: 0.796625\ttraining's binary_logloss: 0.0892145\tvalid_1's auc: 0.807456\tvalid_1's binary_logloss: 0.0659167\n",
      "[12]\ttraining's auc: 0.79694\ttraining's binary_logloss: 0.0887677\tvalid_1's auc: 0.809563\tvalid_1's binary_logloss: 0.0655383\n",
      "[13]\ttraining's auc: 0.796783\ttraining's binary_logloss: 0.0885507\tvalid_1's auc: 0.809199\tvalid_1's binary_logloss: 0.0653411\n",
      "[14]\ttraining's auc: 0.796407\ttraining's binary_logloss: 0.0881473\tvalid_1's auc: 0.808661\tvalid_1's binary_logloss: 0.0650116\n",
      "[15]\ttraining's auc: 0.797193\ttraining's binary_logloss: 0.0877834\tvalid_1's auc: 0.80988\tvalid_1's binary_logloss: 0.0647292\n",
      "[16]\ttraining's auc: 0.79679\ttraining's binary_logloss: 0.0874629\tvalid_1's auc: 0.809688\tvalid_1's binary_logloss: 0.0644529\n",
      "[17]\ttraining's auc: 0.798097\ttraining's binary_logloss: 0.0872538\tvalid_1's auc: 0.810618\tvalid_1's binary_logloss: 0.0642563\n",
      "[18]\ttraining's auc: 0.798006\ttraining's binary_logloss: 0.0869944\tvalid_1's auc: 0.810322\tvalid_1's binary_logloss: 0.0640333\n",
      "[19]\ttraining's auc: 0.799009\ttraining's binary_logloss: 0.0867339\tvalid_1's auc: 0.812054\tvalid_1's binary_logloss: 0.0637932\n",
      "[20]\ttraining's auc: 0.799827\ttraining's binary_logloss: 0.0865587\tvalid_1's auc: 0.813022\tvalid_1's binary_logloss: 0.063626\n",
      "[21]\ttraining's auc: 0.799805\ttraining's binary_logloss: 0.086356\tvalid_1's auc: 0.813127\tvalid_1's binary_logloss: 0.0634464\n",
      "[22]\ttraining's auc: 0.800228\ttraining's binary_logloss: 0.0861655\tvalid_1's auc: 0.813698\tvalid_1's binary_logloss: 0.0632564\n",
      "[23]\ttraining's auc: 0.800426\ttraining's binary_logloss: 0.0860253\tvalid_1's auc: 0.81439\tvalid_1's binary_logloss: 0.0631232\n",
      "[24]\ttraining's auc: 0.800352\ttraining's binary_logloss: 0.0858502\tvalid_1's auc: 0.814154\tvalid_1's binary_logloss: 0.0629754\n",
      "[25]\ttraining's auc: 0.800805\ttraining's binary_logloss: 0.0856703\tvalid_1's auc: 0.81578\tvalid_1's binary_logloss: 0.0628145\n",
      "[26]\ttraining's auc: 0.800391\ttraining's binary_logloss: 0.0855272\tvalid_1's auc: 0.814905\tvalid_1's binary_logloss: 0.0626772\n",
      "[27]\ttraining's auc: 0.800352\ttraining's binary_logloss: 0.0854034\tvalid_1's auc: 0.814819\tvalid_1's binary_logloss: 0.0625652\n",
      "[28]\ttraining's auc: 0.801818\ttraining's binary_logloss: 0.0853141\tvalid_1's auc: 0.815369\tvalid_1's binary_logloss: 0.0624889\n",
      "[29]\ttraining's auc: 0.801923\ttraining's binary_logloss: 0.0851895\tvalid_1's auc: 0.816079\tvalid_1's binary_logloss: 0.0623599\n",
      "[30]\ttraining's auc: 0.802866\ttraining's binary_logloss: 0.0850684\tvalid_1's auc: 0.818307\tvalid_1's binary_logloss: 0.0622376\n",
      "[31]\ttraining's auc: 0.80303\ttraining's binary_logloss: 0.0849616\tvalid_1's auc: 0.817998\tvalid_1's binary_logloss: 0.0621342\n",
      "[32]\ttraining's auc: 0.8032\ttraining's binary_logloss: 0.0848904\tvalid_1's auc: 0.818715\tvalid_1's binary_logloss: 0.062045\n",
      "[33]\ttraining's auc: 0.803554\ttraining's binary_logloss: 0.084791\tvalid_1's auc: 0.818353\tvalid_1's binary_logloss: 0.0619613\n",
      "[34]\ttraining's auc: 0.803704\ttraining's binary_logloss: 0.0847369\tvalid_1's auc: 0.818047\tvalid_1's binary_logloss: 0.06189\n",
      "[35]\ttraining's auc: 0.804011\ttraining's binary_logloss: 0.0846602\tvalid_1's auc: 0.81893\tvalid_1's binary_logloss: 0.061801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36]\ttraining's auc: 0.80415\ttraining's binary_logloss: 0.084594\tvalid_1's auc: 0.819485\tvalid_1's binary_logloss: 0.0617198\n",
      "[37]\ttraining's auc: 0.804479\ttraining's binary_logloss: 0.0845205\tvalid_1's auc: 0.819578\tvalid_1's binary_logloss: 0.0616303\n",
      "[38]\ttraining's auc: 0.804591\ttraining's binary_logloss: 0.0844439\tvalid_1's auc: 0.819611\tvalid_1's binary_logloss: 0.061551\n",
      "[39]\ttraining's auc: 0.804917\ttraining's binary_logloss: 0.0843732\tvalid_1's auc: 0.81937\tvalid_1's binary_logloss: 0.0614767\n",
      "[40]\ttraining's auc: 0.805168\ttraining's binary_logloss: 0.084307\tvalid_1's auc: 0.81904\tvalid_1's binary_logloss: 0.0614045\n",
      "[41]\ttraining's auc: 0.805101\ttraining's binary_logloss: 0.0842394\tvalid_1's auc: 0.819597\tvalid_1's binary_logloss: 0.0613289\n",
      "[42]\ttraining's auc: 0.805366\ttraining's binary_logloss: 0.0841893\tvalid_1's auc: 0.819161\tvalid_1's binary_logloss: 0.0612731\n",
      "[43]\ttraining's auc: 0.805585\ttraining's binary_logloss: 0.0841439\tvalid_1's auc: 0.819247\tvalid_1's binary_logloss: 0.0612279\n",
      "[44]\ttraining's auc: 0.805655\ttraining's binary_logloss: 0.0841003\tvalid_1's auc: 0.81963\tvalid_1's binary_logloss: 0.0611558\n",
      "[45]\ttraining's auc: 0.805859\ttraining's binary_logloss: 0.0840439\tvalid_1's auc: 0.819395\tvalid_1's binary_logloss: 0.0611003\n",
      "[46]\ttraining's auc: 0.806262\ttraining's binary_logloss: 0.0839955\tvalid_1's auc: 0.820188\tvalid_1's binary_logloss: 0.0610605\n",
      "[47]\ttraining's auc: 0.806468\ttraining's binary_logloss: 0.0839516\tvalid_1's auc: 0.82017\tvalid_1's binary_logloss: 0.061004\n",
      "[48]\ttraining's auc: 0.8067\ttraining's binary_logloss: 0.0839061\tvalid_1's auc: 0.820392\tvalid_1's binary_logloss: 0.0609647\n",
      "[49]\ttraining's auc: 0.806929\ttraining's binary_logloss: 0.0838587\tvalid_1's auc: 0.820826\tvalid_1's binary_logloss: 0.0609038\n",
      "[50]\ttraining's auc: 0.807089\ttraining's binary_logloss: 0.0838216\tvalid_1's auc: 0.820821\tvalid_1's binary_logloss: 0.0608608\n",
      "[51]\ttraining's auc: 0.807181\ttraining's binary_logloss: 0.0837891\tvalid_1's auc: 0.821273\tvalid_1's binary_logloss: 0.0608166\n",
      "[52]\ttraining's auc: 0.807257\ttraining's binary_logloss: 0.0837462\tvalid_1's auc: 0.821287\tvalid_1's binary_logloss: 0.0607748\n",
      "[53]\ttraining's auc: 0.807363\ttraining's binary_logloss: 0.0837182\tvalid_1's auc: 0.821665\tvalid_1's binary_logloss: 0.0607496\n",
      "[54]\ttraining's auc: 0.80749\ttraining's binary_logloss: 0.0836762\tvalid_1's auc: 0.821429\tvalid_1's binary_logloss: 0.060718\n",
      "[55]\ttraining's auc: 0.807735\ttraining's binary_logloss: 0.0836466\tvalid_1's auc: 0.821384\tvalid_1's binary_logloss: 0.0606832\n",
      "[56]\ttraining's auc: 0.807724\ttraining's binary_logloss: 0.0836164\tvalid_1's auc: 0.820822\tvalid_1's binary_logloss: 0.0606668\n",
      "[57]\ttraining's auc: 0.807636\ttraining's binary_logloss: 0.0835872\tvalid_1's auc: 0.820919\tvalid_1's binary_logloss: 0.0606504\n",
      "[58]\ttraining's auc: 0.80759\ttraining's binary_logloss: 0.08356\tvalid_1's auc: 0.821101\tvalid_1's binary_logloss: 0.0606177\n",
      "[59]\ttraining's auc: 0.80776\ttraining's binary_logloss: 0.0835347\tvalid_1's auc: 0.821095\tvalid_1's binary_logloss: 0.0606016\n",
      "[60]\ttraining's auc: 0.807931\ttraining's binary_logloss: 0.0835121\tvalid_1's auc: 0.821164\tvalid_1's binary_logloss: 0.0605791\n",
      "[61]\ttraining's auc: 0.808173\ttraining's binary_logloss: 0.0834877\tvalid_1's auc: 0.821144\tvalid_1's binary_logloss: 0.0605648\n",
      "[62]\ttraining's auc: 0.808135\ttraining's binary_logloss: 0.0834663\tvalid_1's auc: 0.82103\tvalid_1's binary_logloss: 0.0605446\n",
      "[63]\ttraining's auc: 0.808258\ttraining's binary_logloss: 0.0834457\tvalid_1's auc: 0.820971\tvalid_1's binary_logloss: 0.0605161\n",
      "[64]\ttraining's auc: 0.808281\ttraining's binary_logloss: 0.0834215\tvalid_1's auc: 0.820993\tvalid_1's binary_logloss: 0.0604997\n",
      "[65]\ttraining's auc: 0.808472\ttraining's binary_logloss: 0.0833987\tvalid_1's auc: 0.821043\tvalid_1's binary_logloss: 0.0604765\n",
      "[66]\ttraining's auc: 0.808539\ttraining's binary_logloss: 0.0833827\tvalid_1's auc: 0.82095\tvalid_1's binary_logloss: 0.0604534\n",
      "[67]\ttraining's auc: 0.80868\ttraining's binary_logloss: 0.083365\tvalid_1's auc: 0.820823\tvalid_1's binary_logloss: 0.0604365\n",
      "[68]\ttraining's auc: 0.808902\ttraining's binary_logloss: 0.0833306\tvalid_1's auc: 0.821164\tvalid_1's binary_logloss: 0.0604114\n",
      "[69]\ttraining's auc: 0.808963\ttraining's binary_logloss: 0.0833054\tvalid_1's auc: 0.821152\tvalid_1's binary_logloss: 0.0603806\n",
      "[70]\ttraining's auc: 0.809065\ttraining's binary_logloss: 0.0832896\tvalid_1's auc: 0.820988\tvalid_1's binary_logloss: 0.0603731\n",
      "[71]\ttraining's auc: 0.809131\ttraining's binary_logloss: 0.0832733\tvalid_1's auc: 0.820796\tvalid_1's binary_logloss: 0.060353\n",
      "[72]\ttraining's auc: 0.809242\ttraining's binary_logloss: 0.0832494\tvalid_1's auc: 0.821042\tvalid_1's binary_logloss: 0.0603353\n",
      "[73]\ttraining's auc: 0.809251\ttraining's binary_logloss: 0.0832331\tvalid_1's auc: 0.820673\tvalid_1's binary_logloss: 0.0603286\n",
      "[74]\ttraining's auc: 0.809299\ttraining's binary_logloss: 0.083222\tvalid_1's auc: 0.820532\tvalid_1's binary_logloss: 0.0603274\n",
      "[75]\ttraining's auc: 0.809464\ttraining's binary_logloss: 0.0832105\tvalid_1's auc: 0.820394\tvalid_1's binary_logloss: 0.0603293\n",
      "[76]\ttraining's auc: 0.809585\ttraining's binary_logloss: 0.0831955\tvalid_1's auc: 0.820388\tvalid_1's binary_logloss: 0.0603156\n",
      "[77]\ttraining's auc: 0.809747\ttraining's binary_logloss: 0.0831809\tvalid_1's auc: 0.820271\tvalid_1's binary_logloss: 0.0603137\n",
      "[78]\ttraining's auc: 0.809796\ttraining's binary_logloss: 0.0831612\tvalid_1's auc: 0.820245\tvalid_1's binary_logloss: 0.0602973\n",
      "[79]\ttraining's auc: 0.809824\ttraining's binary_logloss: 0.0831457\tvalid_1's auc: 0.820242\tvalid_1's binary_logloss: 0.0602737\n",
      "[80]\ttraining's auc: 0.809846\ttraining's binary_logloss: 0.0831342\tvalid_1's auc: 0.820216\tvalid_1's binary_logloss: 0.0602666\n",
      "[81]\ttraining's auc: 0.809914\ttraining's binary_logloss: 0.0831249\tvalid_1's auc: 0.820202\tvalid_1's binary_logloss: 0.0602674\n",
      "[82]\ttraining's auc: 0.810072\ttraining's binary_logloss: 0.0831136\tvalid_1's auc: 0.820429\tvalid_1's binary_logloss: 0.0602719\n",
      "[83]\ttraining's auc: 0.810203\ttraining's binary_logloss: 0.0830954\tvalid_1's auc: 0.820795\tvalid_1's binary_logloss: 0.0602409\n",
      "[84]\ttraining's auc: 0.810357\ttraining's binary_logloss: 0.0830836\tvalid_1's auc: 0.820813\tvalid_1's binary_logloss: 0.060238\n",
      "[85]\ttraining's auc: 0.810445\ttraining's binary_logloss: 0.0830713\tvalid_1's auc: 0.820432\tvalid_1's binary_logloss: 0.0602427\n",
      "[86]\ttraining's auc: 0.810666\ttraining's binary_logloss: 0.0830504\tvalid_1's auc: 0.820626\tvalid_1's binary_logloss: 0.0602363\n",
      "[87]\ttraining's auc: 0.810741\ttraining's binary_logloss: 0.0830327\tvalid_1's auc: 0.820713\tvalid_1's binary_logloss: 0.0602196\n",
      "[88]\ttraining's auc: 0.810789\ttraining's binary_logloss: 0.0830221\tvalid_1's auc: 0.820649\tvalid_1's binary_logloss: 0.0602134\n",
      "[89]\ttraining's auc: 0.810902\ttraining's binary_logloss: 0.0830092\tvalid_1's auc: 0.820928\tvalid_1's binary_logloss: 0.0602072\n",
      "[90]\ttraining's auc: 0.811032\ttraining's binary_logloss: 0.082995\tvalid_1's auc: 0.820882\tvalid_1's binary_logloss: 0.0601896\n",
      "[91]\ttraining's auc: 0.811066\ttraining's binary_logloss: 0.0829881\tvalid_1's auc: 0.820881\tvalid_1's binary_logloss: 0.0601859\n",
      "[92]\ttraining's auc: 0.811259\ttraining's binary_logloss: 0.0829758\tvalid_1's auc: 0.820903\tvalid_1's binary_logloss: 0.060185\n",
      "[93]\ttraining's auc: 0.811381\ttraining's binary_logloss: 0.0829651\tvalid_1's auc: 0.821054\tvalid_1's binary_logloss: 0.0601818\n",
      "[94]\ttraining's auc: 0.811463\ttraining's binary_logloss: 0.0829539\tvalid_1's auc: 0.821084\tvalid_1's binary_logloss: 0.0601786\n",
      "[95]\ttraining's auc: 0.811544\ttraining's binary_logloss: 0.0829391\tvalid_1's auc: 0.821226\tvalid_1's binary_logloss: 0.0601635\n",
      "[96]\ttraining's auc: 0.811549\ttraining's binary_logloss: 0.0829323\tvalid_1's auc: 0.821141\tvalid_1's binary_logloss: 0.0601641\n",
      "[97]\ttraining's auc: 0.811578\ttraining's binary_logloss: 0.0829267\tvalid_1's auc: 0.821183\tvalid_1's binary_logloss: 0.0601605\n",
      "[98]\ttraining's auc: 0.811656\ttraining's binary_logloss: 0.0829193\tvalid_1's auc: 0.821278\tvalid_1's binary_logloss: 0.060157\n",
      "[99]\ttraining's auc: 0.811626\ttraining's binary_logloss: 0.0829081\tvalid_1's auc: 0.821307\tvalid_1's binary_logloss: 0.0601464\n",
      "[100]\ttraining's auc: 0.811672\ttraining's binary_logloss: 0.0828978\tvalid_1's auc: 0.821349\tvalid_1's binary_logloss: 0.0601376\n",
      "[101]\ttraining's auc: 0.811739\ttraining's binary_logloss: 0.0828873\tvalid_1's auc: 0.821272\tvalid_1's binary_logloss: 0.0601442\n",
      "[102]\ttraining's auc: 0.811776\ttraining's binary_logloss: 0.0828784\tvalid_1's auc: 0.821243\tvalid_1's binary_logloss: 0.0601307\n",
      "[103]\ttraining's auc: 0.811866\ttraining's binary_logloss: 0.0828724\tvalid_1's auc: 0.821194\tvalid_1's binary_logloss: 0.0601363\n",
      "[104]\ttraining's auc: 0.811853\ttraining's binary_logloss: 0.0828615\tvalid_1's auc: 0.821196\tvalid_1's binary_logloss: 0.0601267\n",
      "[105]\ttraining's auc: 0.811929\ttraining's binary_logloss: 0.0828553\tvalid_1's auc: 0.821368\tvalid_1's binary_logloss: 0.0601072\n",
      "[106]\ttraining's auc: 0.812023\ttraining's binary_logloss: 0.0828443\tvalid_1's auc: 0.821415\tvalid_1's binary_logloss: 0.0601093\n",
      "[107]\ttraining's auc: 0.812052\ttraining's binary_logloss: 0.0828383\tvalid_1's auc: 0.821405\tvalid_1's binary_logloss: 0.0601062\n",
      "[108]\ttraining's auc: 0.812191\ttraining's binary_logloss: 0.0828266\tvalid_1's auc: 0.821293\tvalid_1's binary_logloss: 0.0601056\n",
      "[109]\ttraining's auc: 0.812247\ttraining's binary_logloss: 0.0828197\tvalid_1's auc: 0.821175\tvalid_1's binary_logloss: 0.0601072\n",
      "[110]\ttraining's auc: 0.8123\ttraining's binary_logloss: 0.0828126\tvalid_1's auc: 0.82121\tvalid_1's binary_logloss: 0.0601011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111]\ttraining's auc: 0.812325\ttraining's binary_logloss: 0.0828061\tvalid_1's auc: 0.821159\tvalid_1's binary_logloss: 0.0600955\n",
      "[112]\ttraining's auc: 0.812362\ttraining's binary_logloss: 0.082795\tvalid_1's auc: 0.821345\tvalid_1's binary_logloss: 0.0600771\n",
      "[113]\ttraining's auc: 0.812404\ttraining's binary_logloss: 0.0827782\tvalid_1's auc: 0.821364\tvalid_1's binary_logloss: 0.0600613\n",
      "[114]\ttraining's auc: 0.812475\ttraining's binary_logloss: 0.0827683\tvalid_1's auc: 0.82134\tvalid_1's binary_logloss: 0.0600647\n",
      "[115]\ttraining's auc: 0.812525\ttraining's binary_logloss: 0.0827628\tvalid_1's auc: 0.821321\tvalid_1's binary_logloss: 0.060064\n",
      "[116]\ttraining's auc: 0.812595\ttraining's binary_logloss: 0.0827561\tvalid_1's auc: 0.821365\tvalid_1's binary_logloss: 0.0600534\n",
      "[117]\ttraining's auc: 0.812622\ttraining's binary_logloss: 0.0827515\tvalid_1's auc: 0.821384\tvalid_1's binary_logloss: 0.0600524\n",
      "[118]\ttraining's auc: 0.812656\ttraining's binary_logloss: 0.0827469\tvalid_1's auc: 0.821383\tvalid_1's binary_logloss: 0.0600542\n",
      "[119]\ttraining's auc: 0.812781\ttraining's binary_logloss: 0.0827366\tvalid_1's auc: 0.821528\tvalid_1's binary_logloss: 0.0600541\n",
      "[120]\ttraining's auc: 0.812874\ttraining's binary_logloss: 0.0827277\tvalid_1's auc: 0.821715\tvalid_1's binary_logloss: 0.0600413\n",
      "[121]\ttraining's auc: 0.812917\ttraining's binary_logloss: 0.0827186\tvalid_1's auc: 0.821565\tvalid_1's binary_logloss: 0.0600364\n",
      "[122]\ttraining's auc: 0.813006\ttraining's binary_logloss: 0.08271\tvalid_1's auc: 0.821589\tvalid_1's binary_logloss: 0.0600399\n",
      "[123]\ttraining's auc: 0.813021\ttraining's binary_logloss: 0.0827034\tvalid_1's auc: 0.821694\tvalid_1's binary_logloss: 0.0600359\n",
      "[124]\ttraining's auc: 0.813044\ttraining's binary_logloss: 0.0826933\tvalid_1's auc: 0.821681\tvalid_1's binary_logloss: 0.0600237\n",
      "[125]\ttraining's auc: 0.813119\ttraining's binary_logloss: 0.082688\tvalid_1's auc: 0.821795\tvalid_1's binary_logloss: 0.0600174\n",
      "[126]\ttraining's auc: 0.813216\ttraining's binary_logloss: 0.0826821\tvalid_1's auc: 0.821783\tvalid_1's binary_logloss: 0.0600013\n",
      "[127]\ttraining's auc: 0.813249\ttraining's binary_logloss: 0.0826778\tvalid_1's auc: 0.821767\tvalid_1's binary_logloss: 0.0600024\n",
      "[128]\ttraining's auc: 0.813268\ttraining's binary_logloss: 0.082668\tvalid_1's auc: 0.821632\tvalid_1's binary_logloss: 0.0600261\n",
      "[129]\ttraining's auc: 0.813323\ttraining's binary_logloss: 0.0826608\tvalid_1's auc: 0.821584\tvalid_1's binary_logloss: 0.0600235\n",
      "[130]\ttraining's auc: 0.813384\ttraining's binary_logloss: 0.0826554\tvalid_1's auc: 0.821659\tvalid_1's binary_logloss: 0.0600134\n",
      "[131]\ttraining's auc: 0.8135\ttraining's binary_logloss: 0.0826488\tvalid_1's auc: 0.821627\tvalid_1's binary_logloss: 0.0600142\n",
      "[132]\ttraining's auc: 0.813568\ttraining's binary_logloss: 0.0826436\tvalid_1's auc: 0.821635\tvalid_1's binary_logloss: 0.0600165\n",
      "[133]\ttraining's auc: 0.81359\ttraining's binary_logloss: 0.0826381\tvalid_1's auc: 0.821556\tvalid_1's binary_logloss: 0.060016\n",
      "[134]\ttraining's auc: 0.813677\ttraining's binary_logloss: 0.0826315\tvalid_1's auc: 0.821542\tvalid_1's binary_logloss: 0.0600176\n",
      "[135]\ttraining's auc: 0.813703\ttraining's binary_logloss: 0.0826274\tvalid_1's auc: 0.821401\tvalid_1's binary_logloss: 0.060018\n",
      "[136]\ttraining's auc: 0.813712\ttraining's binary_logloss: 0.0826241\tvalid_1's auc: 0.821315\tvalid_1's binary_logloss: 0.0600189\n",
      "[137]\ttraining's auc: 0.813741\ttraining's binary_logloss: 0.0826197\tvalid_1's auc: 0.821362\tvalid_1's binary_logloss: 0.0600188\n",
      "[138]\ttraining's auc: 0.81375\ttraining's binary_logloss: 0.0826153\tvalid_1's auc: 0.821385\tvalid_1's binary_logloss: 0.0600158\n",
      "[139]\ttraining's auc: 0.813797\ttraining's binary_logloss: 0.08261\tvalid_1's auc: 0.821375\tvalid_1's binary_logloss: 0.0600182\n",
      "[140]\ttraining's auc: 0.813874\ttraining's binary_logloss: 0.0826028\tvalid_1's auc: 0.821267\tvalid_1's binary_logloss: 0.0600265\n",
      "[141]\ttraining's auc: 0.813955\ttraining's binary_logloss: 0.0825958\tvalid_1's auc: 0.821178\tvalid_1's binary_logloss: 0.0600343\n",
      "[142]\ttraining's auc: 0.813982\ttraining's binary_logloss: 0.0825833\tvalid_1's auc: 0.821238\tvalid_1's binary_logloss: 0.0600276\n",
      "[143]\ttraining's auc: 0.814039\ttraining's binary_logloss: 0.0825807\tvalid_1's auc: 0.82131\tvalid_1's binary_logloss: 0.0600209\n",
      "[144]\ttraining's auc: 0.814088\ttraining's binary_logloss: 0.0825761\tvalid_1's auc: 0.821281\tvalid_1's binary_logloss: 0.0600217\n",
      "[145]\ttraining's auc: 0.814122\ttraining's binary_logloss: 0.0825661\tvalid_1's auc: 0.821387\tvalid_1's binary_logloss: 0.0600102\n",
      "[146]\ttraining's auc: 0.81409\ttraining's binary_logloss: 0.082561\tvalid_1's auc: 0.821264\tvalid_1's binary_logloss: 0.0600136\n",
      "[147]\ttraining's auc: 0.814117\ttraining's binary_logloss: 0.0825569\tvalid_1's auc: 0.82129\tvalid_1's binary_logloss: 0.0600151\n",
      "[148]\ttraining's auc: 0.814148\ttraining's binary_logloss: 0.0825527\tvalid_1's auc: 0.821262\tvalid_1's binary_logloss: 0.0600157\n",
      "[149]\ttraining's auc: 0.81417\ttraining's binary_logloss: 0.0825475\tvalid_1's auc: 0.821183\tvalid_1's binary_logloss: 0.0600157\n",
      "[150]\ttraining's auc: 0.814211\ttraining's binary_logloss: 0.0825441\tvalid_1's auc: 0.821185\tvalid_1's binary_logloss: 0.0600186\n",
      "[151]\ttraining's auc: 0.814252\ttraining's binary_logloss: 0.0825278\tvalid_1's auc: 0.821409\tvalid_1's binary_logloss: 0.0599965\n",
      "[152]\ttraining's auc: 0.814293\ttraining's binary_logloss: 0.0825228\tvalid_1's auc: 0.821292\tvalid_1's binary_logloss: 0.0599981\n",
      "[153]\ttraining's auc: 0.814297\ttraining's binary_logloss: 0.0825193\tvalid_1's auc: 0.821381\tvalid_1's binary_logloss: 0.0599917\n",
      "[154]\ttraining's auc: 0.814325\ttraining's binary_logloss: 0.0825136\tvalid_1's auc: 0.821493\tvalid_1's binary_logloss: 0.0599887\n",
      "[155]\ttraining's auc: 0.81438\ttraining's binary_logloss: 0.0825076\tvalid_1's auc: 0.82136\tvalid_1's binary_logloss: 0.0599906\n",
      "[156]\ttraining's auc: 0.81443\ttraining's binary_logloss: 0.0825036\tvalid_1's auc: 0.821325\tvalid_1's binary_logloss: 0.0599898\n",
      "[157]\ttraining's auc: 0.814514\ttraining's binary_logloss: 0.0824935\tvalid_1's auc: 0.821218\tvalid_1's binary_logloss: 0.0599927\n",
      "[158]\ttraining's auc: 0.814527\ttraining's binary_logloss: 0.0824906\tvalid_1's auc: 0.82108\tvalid_1's binary_logloss: 0.0600016\n",
      "[159]\ttraining's auc: 0.81457\ttraining's binary_logloss: 0.0824697\tvalid_1's auc: 0.82096\tvalid_1's binary_logloss: 0.0600046\n",
      "[160]\ttraining's auc: 0.814641\ttraining's binary_logloss: 0.0824625\tvalid_1's auc: 0.820928\tvalid_1's binary_logloss: 0.0600086\n",
      "[161]\ttraining's auc: 0.814685\ttraining's binary_logloss: 0.0824566\tvalid_1's auc: 0.821109\tvalid_1's binary_logloss: 0.0599903\n",
      "[162]\ttraining's auc: 0.814727\ttraining's binary_logloss: 0.0824545\tvalid_1's auc: 0.8212\tvalid_1's binary_logloss: 0.0599849\n",
      "[163]\ttraining's auc: 0.814776\ttraining's binary_logloss: 0.0824503\tvalid_1's auc: 0.821302\tvalid_1's binary_logloss: 0.0599763\n",
      "[164]\ttraining's auc: 0.814829\ttraining's binary_logloss: 0.0824443\tvalid_1's auc: 0.820976\tvalid_1's binary_logloss: 0.0599816\n",
      "[165]\ttraining's auc: 0.8149\ttraining's binary_logloss: 0.0824396\tvalid_1's auc: 0.820881\tvalid_1's binary_logloss: 0.0599805\n",
      "[166]\ttraining's auc: 0.814997\ttraining's binary_logloss: 0.0824266\tvalid_1's auc: 0.820852\tvalid_1's binary_logloss: 0.0599968\n",
      "[167]\ttraining's auc: 0.815014\ttraining's binary_logloss: 0.0824233\tvalid_1's auc: 0.820927\tvalid_1's binary_logloss: 0.0599868\n",
      "[168]\ttraining's auc: 0.815013\ttraining's binary_logloss: 0.0824207\tvalid_1's auc: 0.8208\tvalid_1's binary_logloss: 0.0599936\n",
      "[169]\ttraining's auc: 0.81509\ttraining's binary_logloss: 0.0824145\tvalid_1's auc: 0.820815\tvalid_1's binary_logloss: 0.0599954\n",
      "[170]\ttraining's auc: 0.815097\ttraining's binary_logloss: 0.0824122\tvalid_1's auc: 0.820917\tvalid_1's binary_logloss: 0.0599933\n",
      "[171]\ttraining's auc: 0.815103\ttraining's binary_logloss: 0.082409\tvalid_1's auc: 0.820822\tvalid_1's binary_logloss: 0.0599925\n",
      "[172]\ttraining's auc: 0.815198\ttraining's binary_logloss: 0.0823915\tvalid_1's auc: 0.820884\tvalid_1's binary_logloss: 0.0600012\n",
      "[173]\ttraining's auc: 0.815222\ttraining's binary_logloss: 0.0823894\tvalid_1's auc: 0.821\tvalid_1's binary_logloss: 0.0600029\n",
      "[174]\ttraining's auc: 0.815255\ttraining's binary_logloss: 0.082384\tvalid_1's auc: 0.82078\tvalid_1's binary_logloss: 0.0600164\n",
      "[175]\ttraining's auc: 0.815369\ttraining's binary_logloss: 0.0823761\tvalid_1's auc: 0.820559\tvalid_1's binary_logloss: 0.0600307\n",
      "[176]\ttraining's auc: 0.815466\ttraining's binary_logloss: 0.0823674\tvalid_1's auc: 0.820595\tvalid_1's binary_logloss: 0.0600342\n",
      "[177]\ttraining's auc: 0.815487\ttraining's binary_logloss: 0.0823635\tvalid_1's auc: 0.820692\tvalid_1's binary_logloss: 0.0600314\n",
      "[178]\ttraining's auc: 0.815583\ttraining's binary_logloss: 0.0823559\tvalid_1's auc: 0.820668\tvalid_1's binary_logloss: 0.0600398\n",
      "[179]\ttraining's auc: 0.815687\ttraining's binary_logloss: 0.0823484\tvalid_1's auc: 0.820566\tvalid_1's binary_logloss: 0.060047\n",
      "[180]\ttraining's auc: 0.815706\ttraining's binary_logloss: 0.0823448\tvalid_1's auc: 0.820561\tvalid_1's binary_logloss: 0.060051\n",
      "[181]\ttraining's auc: 0.815737\ttraining's binary_logloss: 0.0823392\tvalid_1's auc: 0.820477\tvalid_1's binary_logloss: 0.06005\n",
      "[182]\ttraining's auc: 0.815722\ttraining's binary_logloss: 0.0823335\tvalid_1's auc: 0.820675\tvalid_1's binary_logloss: 0.06003\n",
      "[183]\ttraining's auc: 0.815745\ttraining's binary_logloss: 0.0823273\tvalid_1's auc: 0.820777\tvalid_1's binary_logloss: 0.0600256\n",
      "[184]\ttraining's auc: 0.815755\ttraining's binary_logloss: 0.0823253\tvalid_1's auc: 0.820866\tvalid_1's binary_logloss: 0.0600241\n",
      "[185]\ttraining's auc: 0.815829\ttraining's binary_logloss: 0.0823227\tvalid_1's auc: 0.820888\tvalid_1's binary_logloss: 0.0600228\n",
      "[186]\ttraining's auc: 0.815887\ttraining's binary_logloss: 0.0823157\tvalid_1's auc: 0.82077\tvalid_1's binary_logloss: 0.0600275\n",
      "[187]\ttraining's auc: 0.815929\ttraining's binary_logloss: 0.0823053\tvalid_1's auc: 0.82075\tvalid_1's binary_logloss: 0.0600366\n",
      "[188]\ttraining's auc: 0.815992\ttraining's binary_logloss: 0.0823002\tvalid_1's auc: 0.820815\tvalid_1's binary_logloss: 0.0600324\n",
      "[189]\ttraining's auc: 0.81606\ttraining's binary_logloss: 0.0822913\tvalid_1's auc: 0.820713\tvalid_1's binary_logloss: 0.0600395\n",
      "[190]\ttraining's auc: 0.816139\ttraining's binary_logloss: 0.0822851\tvalid_1's auc: 0.82074\tvalid_1's binary_logloss: 0.0600402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[191]\ttraining's auc: 0.816213\ttraining's binary_logloss: 0.0822793\tvalid_1's auc: 0.820821\tvalid_1's binary_logloss: 0.0600409\n",
      "[192]\ttraining's auc: 0.816249\ttraining's binary_logloss: 0.0822733\tvalid_1's auc: 0.820999\tvalid_1's binary_logloss: 0.0600369\n",
      "[193]\ttraining's auc: 0.816205\ttraining's binary_logloss: 0.0822664\tvalid_1's auc: 0.821091\tvalid_1's binary_logloss: 0.0600323\n",
      "[194]\ttraining's auc: 0.816235\ttraining's binary_logloss: 0.0822621\tvalid_1's auc: 0.820952\tvalid_1's binary_logloss: 0.0600387\n",
      "[195]\ttraining's auc: 0.816252\ttraining's binary_logloss: 0.0822505\tvalid_1's auc: 0.820979\tvalid_1's binary_logloss: 0.0600292\n",
      "[196]\ttraining's auc: 0.816315\ttraining's binary_logloss: 0.0822465\tvalid_1's auc: 0.821024\tvalid_1's binary_logloss: 0.0600296\n",
      "[197]\ttraining's auc: 0.816356\ttraining's binary_logloss: 0.0822341\tvalid_1's auc: 0.821042\tvalid_1's binary_logloss: 0.0600237\n",
      "[198]\ttraining's auc: 0.816366\ttraining's binary_logloss: 0.0822317\tvalid_1's auc: 0.820935\tvalid_1's binary_logloss: 0.0600264\n",
      "[199]\ttraining's auc: 0.816393\ttraining's binary_logloss: 0.082226\tvalid_1's auc: 0.821061\tvalid_1's binary_logloss: 0.0600098\n",
      "[200]\ttraining's auc: 0.816488\ttraining's binary_logloss: 0.0822196\tvalid_1's auc: 0.821045\tvalid_1's binary_logloss: 0.0600129\n",
      "[201]\ttraining's auc: 0.816518\ttraining's binary_logloss: 0.0822179\tvalid_1's auc: 0.821047\tvalid_1's binary_logloss: 0.0600112\n",
      "[202]\ttraining's auc: 0.816547\ttraining's binary_logloss: 0.0822135\tvalid_1's auc: 0.820971\tvalid_1's binary_logloss: 0.0600017\n",
      "[203]\ttraining's auc: 0.816584\ttraining's binary_logloss: 0.0822088\tvalid_1's auc: 0.820758\tvalid_1's binary_logloss: 0.0600126\n",
      "[204]\ttraining's auc: 0.816601\ttraining's binary_logloss: 0.0821987\tvalid_1's auc: 0.820789\tvalid_1's binary_logloss: 0.0600005\n",
      "[205]\ttraining's auc: 0.816627\ttraining's binary_logloss: 0.0821949\tvalid_1's auc: 0.820564\tvalid_1's binary_logloss: 0.0600141\n",
      "[206]\ttraining's auc: 0.816667\ttraining's binary_logloss: 0.0821892\tvalid_1's auc: 0.820599\tvalid_1's binary_logloss: 0.0600205\n",
      "[207]\ttraining's auc: 0.816684\ttraining's binary_logloss: 0.0821831\tvalid_1's auc: 0.820521\tvalid_1's binary_logloss: 0.0600273\n",
      "[208]\ttraining's auc: 0.816712\ttraining's binary_logloss: 0.0821732\tvalid_1's auc: 0.820456\tvalid_1's binary_logloss: 0.060027\n",
      "[209]\ttraining's auc: 0.816755\ttraining's binary_logloss: 0.0821695\tvalid_1's auc: 0.820614\tvalid_1's binary_logloss: 0.0600191\n",
      "[210]\ttraining's auc: 0.816784\ttraining's binary_logloss: 0.0821682\tvalid_1's auc: 0.82067\tvalid_1's binary_logloss: 0.0600131\n",
      "[211]\ttraining's auc: 0.816821\ttraining's binary_logloss: 0.082164\tvalid_1's auc: 0.820598\tvalid_1's binary_logloss: 0.0600109\n",
      "[212]\ttraining's auc: 0.816849\ttraining's binary_logloss: 0.0821616\tvalid_1's auc: 0.820533\tvalid_1's binary_logloss: 0.0600131\n",
      "[213]\ttraining's auc: 0.816839\ttraining's binary_logloss: 0.0821587\tvalid_1's auc: 0.820506\tvalid_1's binary_logloss: 0.0600095\n",
      "[214]\ttraining's auc: 0.816874\ttraining's binary_logloss: 0.0821531\tvalid_1's auc: 0.820567\tvalid_1's binary_logloss: 0.0600023\n",
      "[215]\ttraining's auc: 0.816867\ttraining's binary_logloss: 0.0821499\tvalid_1's auc: 0.820573\tvalid_1's binary_logloss: 0.0600039\n",
      "[216]\ttraining's auc: 0.816881\ttraining's binary_logloss: 0.0821431\tvalid_1's auc: 0.82061\tvalid_1's binary_logloss: 0.06\n",
      "[217]\ttraining's auc: 0.816894\ttraining's binary_logloss: 0.0821404\tvalid_1's auc: 0.820641\tvalid_1's binary_logloss: 0.0600019\n",
      "[218]\ttraining's auc: 0.816938\ttraining's binary_logloss: 0.0821355\tvalid_1's auc: 0.820575\tvalid_1's binary_logloss: 0.0599994\n",
      "[219]\ttraining's auc: 0.817\ttraining's binary_logloss: 0.0821307\tvalid_1's auc: 0.820626\tvalid_1's binary_logloss: 0.0599999\n",
      "[220]\ttraining's auc: 0.816996\ttraining's binary_logloss: 0.0821268\tvalid_1's auc: 0.820751\tvalid_1's binary_logloss: 0.0599993\n",
      "[221]\ttraining's auc: 0.817\ttraining's binary_logloss: 0.082121\tvalid_1's auc: 0.820996\tvalid_1's binary_logloss: 0.0599889\n",
      "[222]\ttraining's auc: 0.817003\ttraining's binary_logloss: 0.0821191\tvalid_1's auc: 0.820983\tvalid_1's binary_logloss: 0.0599843\n",
      "[223]\ttraining's auc: 0.817024\ttraining's binary_logloss: 0.0821135\tvalid_1's auc: 0.82083\tvalid_1's binary_logloss: 0.059994\n",
      "[224]\ttraining's auc: 0.817113\ttraining's binary_logloss: 0.0821071\tvalid_1's auc: 0.820921\tvalid_1's binary_logloss: 0.0599912\n",
      "[225]\ttraining's auc: 0.817179\ttraining's binary_logloss: 0.0821007\tvalid_1's auc: 0.820941\tvalid_1's binary_logloss: 0.0599962\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's auc: 0.813119\ttraining's binary_logloss: 0.082688\tvalid_1's auc: 0.821795\tvalid_1's binary_logloss: 0.0600174\n",
      "8\n",
      "[1]\ttraining's auc: 0.7369\ttraining's binary_logloss: 0.0916053\tvalid_1's auc: 0.7262\tvalid_1's binary_logloss: 0.088886\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.793624\ttraining's binary_logloss: 0.0901081\tvalid_1's auc: 0.767404\tvalid_1's binary_logloss: 0.0878256\n",
      "[3]\ttraining's auc: 0.798711\ttraining's binary_logloss: 0.0895489\tvalid_1's auc: 0.774005\tvalid_1's binary_logloss: 0.0873619\n",
      "[4]\ttraining's auc: 0.799412\ttraining's binary_logloss: 0.0890054\tvalid_1's auc: 0.77414\tvalid_1's binary_logloss: 0.0869067\n",
      "[5]\ttraining's auc: 0.803779\ttraining's binary_logloss: 0.0880829\tvalid_1's auc: 0.776585\tvalid_1's binary_logloss: 0.0862555\n",
      "[6]\ttraining's auc: 0.804211\ttraining's binary_logloss: 0.087227\tvalid_1's auc: 0.776126\tvalid_1's binary_logloss: 0.0856483\n",
      "[7]\ttraining's auc: 0.803314\ttraining's binary_logloss: 0.0868094\tvalid_1's auc: 0.775453\tvalid_1's binary_logloss: 0.0852977\n",
      "[8]\ttraining's auc: 0.804279\ttraining's binary_logloss: 0.0860924\tvalid_1's auc: 0.775941\tvalid_1's binary_logloss: 0.0847639\n",
      "[9]\ttraining's auc: 0.805975\ttraining's binary_logloss: 0.0854646\tvalid_1's auc: 0.777475\tvalid_1's binary_logloss: 0.0842941\n",
      "[10]\ttraining's auc: 0.805989\ttraining's binary_logloss: 0.0851829\tvalid_1's auc: 0.776597\tvalid_1's binary_logloss: 0.0840807\n",
      "[11]\ttraining's auc: 0.806146\ttraining's binary_logloss: 0.084626\tvalid_1's auc: 0.776615\tvalid_1's binary_logloss: 0.0836775\n",
      "[12]\ttraining's auc: 0.807735\ttraining's binary_logloss: 0.0841373\tvalid_1's auc: 0.777433\tvalid_1's binary_logloss: 0.0833524\n",
      "[13]\ttraining's auc: 0.80815\ttraining's binary_logloss: 0.083907\tvalid_1's auc: 0.778567\tvalid_1's binary_logloss: 0.0831794\n",
      "[14]\ttraining's auc: 0.8085\ttraining's binary_logloss: 0.0834762\tvalid_1's auc: 0.779139\tvalid_1's binary_logloss: 0.0828748\n",
      "[15]\ttraining's auc: 0.8088\ttraining's binary_logloss: 0.0831041\tvalid_1's auc: 0.779599\tvalid_1's binary_logloss: 0.0826197\n",
      "[16]\ttraining's auc: 0.808836\ttraining's binary_logloss: 0.0827816\tvalid_1's auc: 0.779159\tvalid_1's binary_logloss: 0.0824344\n",
      "[17]\ttraining's auc: 0.808764\ttraining's binary_logloss: 0.0825583\tvalid_1's auc: 0.779135\tvalid_1's binary_logloss: 0.0822425\n",
      "[18]\ttraining's auc: 0.809898\ttraining's binary_logloss: 0.0822904\tvalid_1's auc: 0.779895\tvalid_1's binary_logloss: 0.08208\n",
      "[19]\ttraining's auc: 0.810305\ttraining's binary_logloss: 0.0820217\tvalid_1's auc: 0.78017\tvalid_1's binary_logloss: 0.0818671\n",
      "[20]\ttraining's auc: 0.810257\ttraining's binary_logloss: 0.0818533\tvalid_1's auc: 0.78061\tvalid_1's binary_logloss: 0.081711\n",
      "[21]\ttraining's auc: 0.810229\ttraining's binary_logloss: 0.081637\tvalid_1's auc: 0.780498\tvalid_1's binary_logloss: 0.0815919\n",
      "[22]\ttraining's auc: 0.81049\ttraining's binary_logloss: 0.0814333\tvalid_1's auc: 0.780998\tvalid_1's binary_logloss: 0.0814317\n",
      "[23]\ttraining's auc: 0.810853\ttraining's binary_logloss: 0.0812843\tvalid_1's auc: 0.782034\tvalid_1's binary_logloss: 0.0812936\n",
      "[24]\ttraining's auc: 0.810865\ttraining's binary_logloss: 0.0811005\tvalid_1's auc: 0.781915\tvalid_1's binary_logloss: 0.0812019\n",
      "[25]\ttraining's auc: 0.811411\ttraining's binary_logloss: 0.0809179\tvalid_1's auc: 0.782555\tvalid_1's binary_logloss: 0.0810784\n",
      "[26]\ttraining's auc: 0.811831\ttraining's binary_logloss: 0.0807615\tvalid_1's auc: 0.782595\tvalid_1's binary_logloss: 0.0810016\n",
      "[27]\ttraining's auc: 0.812533\ttraining's binary_logloss: 0.0806293\tvalid_1's auc: 0.782433\tvalid_1's binary_logloss: 0.0809393\n",
      "[28]\ttraining's auc: 0.813004\ttraining's binary_logloss: 0.0805518\tvalid_1's auc: 0.782505\tvalid_1's binary_logloss: 0.0808556\n",
      "[29]\ttraining's auc: 0.813944\ttraining's binary_logloss: 0.0804244\tvalid_1's auc: 0.78287\tvalid_1's binary_logloss: 0.0807739\n",
      "[30]\ttraining's auc: 0.81393\ttraining's binary_logloss: 0.0803039\tvalid_1's auc: 0.782935\tvalid_1's binary_logloss: 0.080679\n",
      "[31]\ttraining's auc: 0.814248\ttraining's binary_logloss: 0.0801919\tvalid_1's auc: 0.78356\tvalid_1's binary_logloss: 0.0806119\n",
      "[32]\ttraining's auc: 0.814152\ttraining's binary_logloss: 0.0801182\tvalid_1's auc: 0.783896\tvalid_1's binary_logloss: 0.080538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]\ttraining's auc: 0.814973\ttraining's binary_logloss: 0.0800265\tvalid_1's auc: 0.785014\tvalid_1's binary_logloss: 0.0804548\n",
      "[34]\ttraining's auc: 0.814946\ttraining's binary_logloss: 0.0799604\tvalid_1's auc: 0.784776\tvalid_1's binary_logloss: 0.0804281\n",
      "[35]\ttraining's auc: 0.815168\ttraining's binary_logloss: 0.07987\tvalid_1's auc: 0.784543\tvalid_1's binary_logloss: 0.0803984\n",
      "[36]\ttraining's auc: 0.815285\ttraining's binary_logloss: 0.0798056\tvalid_1's auc: 0.784537\tvalid_1's binary_logloss: 0.0803779\n",
      "[37]\ttraining's auc: 0.816009\ttraining's binary_logloss: 0.0797318\tvalid_1's auc: 0.785455\tvalid_1's binary_logloss: 0.0803199\n",
      "[38]\ttraining's auc: 0.816104\ttraining's binary_logloss: 0.0796535\tvalid_1's auc: 0.785651\tvalid_1's binary_logloss: 0.0802644\n",
      "[39]\ttraining's auc: 0.816478\ttraining's binary_logloss: 0.0795767\tvalid_1's auc: 0.786218\tvalid_1's binary_logloss: 0.0801931\n",
      "[40]\ttraining's auc: 0.816644\ttraining's binary_logloss: 0.0795068\tvalid_1's auc: 0.785947\tvalid_1's binary_logloss: 0.0801397\n",
      "[41]\ttraining's auc: 0.816972\ttraining's binary_logloss: 0.0794396\tvalid_1's auc: 0.786279\tvalid_1's binary_logloss: 0.0800832\n",
      "[42]\ttraining's auc: 0.817289\ttraining's binary_logloss: 0.079396\tvalid_1's auc: 0.786501\tvalid_1's binary_logloss: 0.0800641\n",
      "[43]\ttraining's auc: 0.817678\ttraining's binary_logloss: 0.0793413\tvalid_1's auc: 0.786424\tvalid_1's binary_logloss: 0.0799994\n",
      "[44]\ttraining's auc: 0.817764\ttraining's binary_logloss: 0.0793085\tvalid_1's auc: 0.786383\tvalid_1's binary_logloss: 0.0799888\n",
      "[45]\ttraining's auc: 0.818065\ttraining's binary_logloss: 0.0792525\tvalid_1's auc: 0.786374\tvalid_1's binary_logloss: 0.0799347\n",
      "[46]\ttraining's auc: 0.818213\ttraining's binary_logloss: 0.0792125\tvalid_1's auc: 0.786818\tvalid_1's binary_logloss: 0.0798919\n",
      "[47]\ttraining's auc: 0.818225\ttraining's binary_logloss: 0.0791659\tvalid_1's auc: 0.786802\tvalid_1's binary_logloss: 0.0798885\n",
      "[48]\ttraining's auc: 0.818294\ttraining's binary_logloss: 0.0791129\tvalid_1's auc: 0.786973\tvalid_1's binary_logloss: 0.0798449\n",
      "[49]\ttraining's auc: 0.818384\ttraining's binary_logloss: 0.0790677\tvalid_1's auc: 0.787172\tvalid_1's binary_logloss: 0.0797988\n",
      "[50]\ttraining's auc: 0.81875\ttraining's binary_logloss: 0.0790338\tvalid_1's auc: 0.787674\tvalid_1's binary_logloss: 0.0797501\n",
      "[51]\ttraining's auc: 0.819018\ttraining's binary_logloss: 0.0790031\tvalid_1's auc: 0.787511\tvalid_1's binary_logloss: 0.0797522\n",
      "[52]\ttraining's auc: 0.819135\ttraining's binary_logloss: 0.0789693\tvalid_1's auc: 0.78737\tvalid_1's binary_logloss: 0.0797677\n",
      "[53]\ttraining's auc: 0.819253\ttraining's binary_logloss: 0.0789426\tvalid_1's auc: 0.78691\tvalid_1's binary_logloss: 0.0797747\n",
      "[54]\ttraining's auc: 0.819314\ttraining's binary_logloss: 0.0789076\tvalid_1's auc: 0.786886\tvalid_1's binary_logloss: 0.0797468\n",
      "[55]\ttraining's auc: 0.819596\ttraining's binary_logloss: 0.0788797\tvalid_1's auc: 0.787097\tvalid_1's binary_logloss: 0.0797247\n",
      "[56]\ttraining's auc: 0.819635\ttraining's binary_logloss: 0.078849\tvalid_1's auc: 0.78727\tvalid_1's binary_logloss: 0.0797196\n",
      "[57]\ttraining's auc: 0.819524\ttraining's binary_logloss: 0.0788176\tvalid_1's auc: 0.787202\tvalid_1's binary_logloss: 0.0797061\n",
      "[58]\ttraining's auc: 0.819885\ttraining's binary_logloss: 0.0787809\tvalid_1's auc: 0.786986\tvalid_1's binary_logloss: 0.0796773\n",
      "[59]\ttraining's auc: 0.820132\ttraining's binary_logloss: 0.0787563\tvalid_1's auc: 0.787051\tvalid_1's binary_logloss: 0.0796595\n",
      "[60]\ttraining's auc: 0.820314\ttraining's binary_logloss: 0.0787336\tvalid_1's auc: 0.787165\tvalid_1's binary_logloss: 0.0796406\n",
      "[61]\ttraining's auc: 0.820354\ttraining's binary_logloss: 0.0787033\tvalid_1's auc: 0.786894\tvalid_1's binary_logloss: 0.079616\n",
      "[62]\ttraining's auc: 0.820356\ttraining's binary_logloss: 0.078681\tvalid_1's auc: 0.786521\tvalid_1's binary_logloss: 0.0795994\n",
      "[63]\ttraining's auc: 0.820373\ttraining's binary_logloss: 0.0786642\tvalid_1's auc: 0.786666\tvalid_1's binary_logloss: 0.0795999\n",
      "[64]\ttraining's auc: 0.820427\ttraining's binary_logloss: 0.0786379\tvalid_1's auc: 0.786603\tvalid_1's binary_logloss: 0.0795844\n",
      "[65]\ttraining's auc: 0.820394\ttraining's binary_logloss: 0.078617\tvalid_1's auc: 0.786761\tvalid_1's binary_logloss: 0.0795779\n",
      "[66]\ttraining's auc: 0.820447\ttraining's binary_logloss: 0.0785933\tvalid_1's auc: 0.786886\tvalid_1's binary_logloss: 0.0795861\n",
      "[67]\ttraining's auc: 0.820571\ttraining's binary_logloss: 0.0785753\tvalid_1's auc: 0.786924\tvalid_1's binary_logloss: 0.0795749\n",
      "[68]\ttraining's auc: 0.82087\ttraining's binary_logloss: 0.0785515\tvalid_1's auc: 0.786913\tvalid_1's binary_logloss: 0.0795443\n",
      "[69]\ttraining's auc: 0.820836\ttraining's binary_logloss: 0.0785265\tvalid_1's auc: 0.787007\tvalid_1's binary_logloss: 0.0795287\n",
      "[70]\ttraining's auc: 0.820941\ttraining's binary_logloss: 0.07851\tvalid_1's auc: 0.787047\tvalid_1's binary_logloss: 0.0795128\n",
      "[71]\ttraining's auc: 0.821038\ttraining's binary_logloss: 0.0784937\tvalid_1's auc: 0.787206\tvalid_1's binary_logloss: 0.0794998\n",
      "[72]\ttraining's auc: 0.821196\ttraining's binary_logloss: 0.0784731\tvalid_1's auc: 0.787411\tvalid_1's binary_logloss: 0.0794832\n",
      "[73]\ttraining's auc: 0.821244\ttraining's binary_logloss: 0.0784582\tvalid_1's auc: 0.787389\tvalid_1's binary_logloss: 0.079457\n",
      "[74]\ttraining's auc: 0.821283\ttraining's binary_logloss: 0.0784464\tvalid_1's auc: 0.787436\tvalid_1's binary_logloss: 0.0794639\n",
      "[75]\ttraining's auc: 0.821328\ttraining's binary_logloss: 0.0784297\tvalid_1's auc: 0.787239\tvalid_1's binary_logloss: 0.0794601\n",
      "[76]\ttraining's auc: 0.821475\ttraining's binary_logloss: 0.0784187\tvalid_1's auc: 0.787371\tvalid_1's binary_logloss: 0.0794386\n",
      "[77]\ttraining's auc: 0.821516\ttraining's binary_logloss: 0.0784014\tvalid_1's auc: 0.787178\tvalid_1's binary_logloss: 0.0794354\n",
      "[78]\ttraining's auc: 0.821563\ttraining's binary_logloss: 0.0783877\tvalid_1's auc: 0.78719\tvalid_1's binary_logloss: 0.0794215\n",
      "[79]\ttraining's auc: 0.821637\ttraining's binary_logloss: 0.0783782\tvalid_1's auc: 0.787271\tvalid_1's binary_logloss: 0.0794005\n",
      "[80]\ttraining's auc: 0.82165\ttraining's binary_logloss: 0.0783677\tvalid_1's auc: 0.787199\tvalid_1's binary_logloss: 0.0794142\n",
      "[81]\ttraining's auc: 0.821708\ttraining's binary_logloss: 0.0783533\tvalid_1's auc: 0.787559\tvalid_1's binary_logloss: 0.0794078\n",
      "[82]\ttraining's auc: 0.821803\ttraining's binary_logloss: 0.0783399\tvalid_1's auc: 0.787354\tvalid_1's binary_logloss: 0.0794103\n",
      "[83]\ttraining's auc: 0.821853\ttraining's binary_logloss: 0.0783251\tvalid_1's auc: 0.787425\tvalid_1's binary_logloss: 0.079407\n",
      "[84]\ttraining's auc: 0.821942\ttraining's binary_logloss: 0.0783127\tvalid_1's auc: 0.787451\tvalid_1's binary_logloss: 0.07942\n",
      "[85]\ttraining's auc: 0.821994\ttraining's binary_logloss: 0.0783047\tvalid_1's auc: 0.787432\tvalid_1's binary_logloss: 0.0794058\n",
      "[86]\ttraining's auc: 0.822117\ttraining's binary_logloss: 0.078291\tvalid_1's auc: 0.787689\tvalid_1's binary_logloss: 0.0793852\n",
      "[87]\ttraining's auc: 0.822195\ttraining's binary_logloss: 0.0782852\tvalid_1's auc: 0.787637\tvalid_1's binary_logloss: 0.0793912\n",
      "[88]\ttraining's auc: 0.822232\ttraining's binary_logloss: 0.0782745\tvalid_1's auc: 0.787571\tvalid_1's binary_logloss: 0.0794053\n",
      "[89]\ttraining's auc: 0.822295\ttraining's binary_logloss: 0.0782632\tvalid_1's auc: 0.787588\tvalid_1's binary_logloss: 0.0794102\n",
      "[90]\ttraining's auc: 0.822334\ttraining's binary_logloss: 0.0782498\tvalid_1's auc: 0.787749\tvalid_1's binary_logloss: 0.0793941\n",
      "[91]\ttraining's auc: 0.82241\ttraining's binary_logloss: 0.0782236\tvalid_1's auc: 0.787906\tvalid_1's binary_logloss: 0.0793664\n",
      "[92]\ttraining's auc: 0.82244\ttraining's binary_logloss: 0.078216\tvalid_1's auc: 0.787842\tvalid_1's binary_logloss: 0.079383\n",
      "[93]\ttraining's auc: 0.822526\ttraining's binary_logloss: 0.0782096\tvalid_1's auc: 0.787842\tvalid_1's binary_logloss: 0.0793805\n",
      "[94]\ttraining's auc: 0.822594\ttraining's binary_logloss: 0.078194\tvalid_1's auc: 0.787794\tvalid_1's binary_logloss: 0.0793719\n",
      "[95]\ttraining's auc: 0.822673\ttraining's binary_logloss: 0.0781781\tvalid_1's auc: 0.787804\tvalid_1's binary_logloss: 0.0793498\n",
      "[96]\ttraining's auc: 0.822747\ttraining's binary_logloss: 0.0781702\tvalid_1's auc: 0.787792\tvalid_1's binary_logloss: 0.0793445\n",
      "[97]\ttraining's auc: 0.822802\ttraining's binary_logloss: 0.078157\tvalid_1's auc: 0.787729\tvalid_1's binary_logloss: 0.0793392\n",
      "[98]\ttraining's auc: 0.82288\ttraining's binary_logloss: 0.0781479\tvalid_1's auc: 0.787745\tvalid_1's binary_logloss: 0.0793338\n",
      "[99]\ttraining's auc: 0.822883\ttraining's binary_logloss: 0.0781373\tvalid_1's auc: 0.787548\tvalid_1's binary_logloss: 0.0793386\n",
      "[100]\ttraining's auc: 0.822914\ttraining's binary_logloss: 0.07813\tvalid_1's auc: 0.787542\tvalid_1's binary_logloss: 0.0793532\n",
      "[101]\ttraining's auc: 0.82305\ttraining's binary_logloss: 0.078119\tvalid_1's auc: 0.787621\tvalid_1's binary_logloss: 0.0793474\n",
      "[102]\ttraining's auc: 0.823132\ttraining's binary_logloss: 0.0781044\tvalid_1's auc: 0.787705\tvalid_1's binary_logloss: 0.079351\n",
      "[103]\ttraining's auc: 0.823185\ttraining's binary_logloss: 0.0780994\tvalid_1's auc: 0.787751\tvalid_1's binary_logloss: 0.0793397\n",
      "[104]\ttraining's auc: 0.823246\ttraining's binary_logloss: 0.0780871\tvalid_1's auc: 0.787614\tvalid_1's binary_logloss: 0.0793326\n",
      "[105]\ttraining's auc: 0.823308\ttraining's binary_logloss: 0.0780803\tvalid_1's auc: 0.787395\tvalid_1's binary_logloss: 0.0793431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106]\ttraining's auc: 0.823391\ttraining's binary_logloss: 0.0780711\tvalid_1's auc: 0.787651\tvalid_1's binary_logloss: 0.079327\n",
      "[107]\ttraining's auc: 0.823408\ttraining's binary_logloss: 0.0780652\tvalid_1's auc: 0.787602\tvalid_1's binary_logloss: 0.0793386\n",
      "[108]\ttraining's auc: 0.823459\ttraining's binary_logloss: 0.0780561\tvalid_1's auc: 0.787448\tvalid_1's binary_logloss: 0.0793527\n",
      "[109]\ttraining's auc: 0.823511\ttraining's binary_logloss: 0.0780513\tvalid_1's auc: 0.787332\tvalid_1's binary_logloss: 0.0793512\n",
      "[110]\ttraining's auc: 0.823507\ttraining's binary_logloss: 0.0780462\tvalid_1's auc: 0.78735\tvalid_1's binary_logloss: 0.0793553\n",
      "[111]\ttraining's auc: 0.823527\ttraining's binary_logloss: 0.0780347\tvalid_1's auc: 0.787337\tvalid_1's binary_logloss: 0.07935\n",
      "[112]\ttraining's auc: 0.82369\ttraining's binary_logloss: 0.0780229\tvalid_1's auc: 0.787286\tvalid_1's binary_logloss: 0.0793605\n",
      "[113]\ttraining's auc: 0.823708\ttraining's binary_logloss: 0.0780184\tvalid_1's auc: 0.787252\tvalid_1's binary_logloss: 0.0793774\n",
      "[114]\ttraining's auc: 0.823756\ttraining's binary_logloss: 0.0780121\tvalid_1's auc: 0.787226\tvalid_1's binary_logloss: 0.0793885\n",
      "[115]\ttraining's auc: 0.823782\ttraining's binary_logloss: 0.0780076\tvalid_1's auc: 0.787351\tvalid_1's binary_logloss: 0.0793852\n",
      "[116]\ttraining's auc: 0.823817\ttraining's binary_logloss: 0.0780034\tvalid_1's auc: 0.787426\tvalid_1's binary_logloss: 0.0793775\n",
      "[117]\ttraining's auc: 0.823853\ttraining's binary_logloss: 0.0779989\tvalid_1's auc: 0.787427\tvalid_1's binary_logloss: 0.07938\n",
      "[118]\ttraining's auc: 0.823905\ttraining's binary_logloss: 0.077992\tvalid_1's auc: 0.78754\tvalid_1's binary_logloss: 0.0793736\n",
      "[119]\ttraining's auc: 0.823966\ttraining's binary_logloss: 0.0779878\tvalid_1's auc: 0.787518\tvalid_1's binary_logloss: 0.0793709\n",
      "[120]\ttraining's auc: 0.823979\ttraining's binary_logloss: 0.0779811\tvalid_1's auc: 0.787685\tvalid_1's binary_logloss: 0.0793688\n",
      "[121]\ttraining's auc: 0.824062\ttraining's binary_logloss: 0.077971\tvalid_1's auc: 0.787591\tvalid_1's binary_logloss: 0.0793597\n",
      "[122]\ttraining's auc: 0.824113\ttraining's binary_logloss: 0.0779644\tvalid_1's auc: 0.78769\tvalid_1's binary_logloss: 0.0793503\n",
      "[123]\ttraining's auc: 0.824167\ttraining's binary_logloss: 0.0779581\tvalid_1's auc: 0.787764\tvalid_1's binary_logloss: 0.0793507\n",
      "[124]\ttraining's auc: 0.824189\ttraining's binary_logloss: 0.0779543\tvalid_1's auc: 0.787802\tvalid_1's binary_logloss: 0.0793521\n",
      "[125]\ttraining's auc: 0.824283\ttraining's binary_logloss: 0.0779489\tvalid_1's auc: 0.787708\tvalid_1's binary_logloss: 0.0793555\n",
      "[126]\ttraining's auc: 0.824374\ttraining's binary_logloss: 0.0779426\tvalid_1's auc: 0.787595\tvalid_1's binary_logloss: 0.0793642\n",
      "[127]\ttraining's auc: 0.824421\ttraining's binary_logloss: 0.0779353\tvalid_1's auc: 0.787618\tvalid_1's binary_logloss: 0.0793692\n",
      "[128]\ttraining's auc: 0.824429\ttraining's binary_logloss: 0.0779318\tvalid_1's auc: 0.787667\tvalid_1's binary_logloss: 0.0793629\n",
      "[129]\ttraining's auc: 0.824484\ttraining's binary_logloss: 0.0779197\tvalid_1's auc: 0.787896\tvalid_1's binary_logloss: 0.0793373\n",
      "[130]\ttraining's auc: 0.824523\ttraining's binary_logloss: 0.0779126\tvalid_1's auc: 0.787862\tvalid_1's binary_logloss: 0.079339\n",
      "[131]\ttraining's auc: 0.824511\ttraining's binary_logloss: 0.0779061\tvalid_1's auc: 0.788\tvalid_1's binary_logloss: 0.0793325\n",
      "[132]\ttraining's auc: 0.82458\ttraining's binary_logloss: 0.0779011\tvalid_1's auc: 0.787837\tvalid_1's binary_logloss: 0.0793417\n",
      "[133]\ttraining's auc: 0.82465\ttraining's binary_logloss: 0.0778964\tvalid_1's auc: 0.787811\tvalid_1's binary_logloss: 0.0793358\n",
      "[134]\ttraining's auc: 0.824743\ttraining's binary_logloss: 0.0778911\tvalid_1's auc: 0.787731\tvalid_1's binary_logloss: 0.0793395\n",
      "[135]\ttraining's auc: 0.824718\ttraining's binary_logloss: 0.0778892\tvalid_1's auc: 0.787747\tvalid_1's binary_logloss: 0.0793383\n",
      "[136]\ttraining's auc: 0.824783\ttraining's binary_logloss: 0.0778814\tvalid_1's auc: 0.787817\tvalid_1's binary_logloss: 0.0793307\n",
      "[137]\ttraining's auc: 0.824804\ttraining's binary_logloss: 0.0778775\tvalid_1's auc: 0.787979\tvalid_1's binary_logloss: 0.0793249\n",
      "[138]\ttraining's auc: 0.824815\ttraining's binary_logloss: 0.077874\tvalid_1's auc: 0.788014\tvalid_1's binary_logloss: 0.0793225\n",
      "[139]\ttraining's auc: 0.824817\ttraining's binary_logloss: 0.0778708\tvalid_1's auc: 0.78814\tvalid_1's binary_logloss: 0.0793217\n",
      "[140]\ttraining's auc: 0.824826\ttraining's binary_logloss: 0.0778678\tvalid_1's auc: 0.788283\tvalid_1's binary_logloss: 0.0793126\n",
      "[141]\ttraining's auc: 0.824923\ttraining's binary_logloss: 0.0778593\tvalid_1's auc: 0.788352\tvalid_1's binary_logloss: 0.0793161\n",
      "[142]\ttraining's auc: 0.824937\ttraining's binary_logloss: 0.0778499\tvalid_1's auc: 0.788325\tvalid_1's binary_logloss: 0.0793155\n",
      "[143]\ttraining's auc: 0.825\ttraining's binary_logloss: 0.0778447\tvalid_1's auc: 0.788353\tvalid_1's binary_logloss: 0.0793174\n",
      "[144]\ttraining's auc: 0.825083\ttraining's binary_logloss: 0.0778386\tvalid_1's auc: 0.788273\tvalid_1's binary_logloss: 0.0793239\n",
      "[145]\ttraining's auc: 0.825079\ttraining's binary_logloss: 0.077832\tvalid_1's auc: 0.788178\tvalid_1's binary_logloss: 0.0793341\n",
      "[146]\ttraining's auc: 0.825109\ttraining's binary_logloss: 0.0778258\tvalid_1's auc: 0.788168\tvalid_1's binary_logloss: 0.0793398\n",
      "[147]\ttraining's auc: 0.825181\ttraining's binary_logloss: 0.0778186\tvalid_1's auc: 0.788136\tvalid_1's binary_logloss: 0.0793431\n",
      "[148]\ttraining's auc: 0.825174\ttraining's binary_logloss: 0.0778149\tvalid_1's auc: 0.78811\tvalid_1's binary_logloss: 0.0793459\n",
      "[149]\ttraining's auc: 0.825223\ttraining's binary_logloss: 0.0778096\tvalid_1's auc: 0.78808\tvalid_1's binary_logloss: 0.0793474\n",
      "[150]\ttraining's auc: 0.825264\ttraining's binary_logloss: 0.0778053\tvalid_1's auc: 0.788007\tvalid_1's binary_logloss: 0.0793433\n",
      "[151]\ttraining's auc: 0.825297\ttraining's binary_logloss: 0.0778016\tvalid_1's auc: 0.787972\tvalid_1's binary_logloss: 0.0793514\n",
      "[152]\ttraining's auc: 0.825337\ttraining's binary_logloss: 0.077791\tvalid_1's auc: 0.788006\tvalid_1's binary_logloss: 0.0793466\n",
      "[153]\ttraining's auc: 0.825371\ttraining's binary_logloss: 0.0777874\tvalid_1's auc: 0.78795\tvalid_1's binary_logloss: 0.0793444\n",
      "[154]\ttraining's auc: 0.825431\ttraining's binary_logloss: 0.0777818\tvalid_1's auc: 0.78792\tvalid_1's binary_logloss: 0.0793438\n",
      "[155]\ttraining's auc: 0.825485\ttraining's binary_logloss: 0.0777752\tvalid_1's auc: 0.787745\tvalid_1's binary_logloss: 0.0793478\n",
      "[156]\ttraining's auc: 0.825613\ttraining's binary_logloss: 0.0777633\tvalid_1's auc: 0.787789\tvalid_1's binary_logloss: 0.0793531\n",
      "[157]\ttraining's auc: 0.825672\ttraining's binary_logloss: 0.0777567\tvalid_1's auc: 0.787879\tvalid_1's binary_logloss: 0.0793447\n",
      "[158]\ttraining's auc: 0.825658\ttraining's binary_logloss: 0.0777484\tvalid_1's auc: 0.787878\tvalid_1's binary_logloss: 0.0793361\n",
      "[159]\ttraining's auc: 0.825685\ttraining's binary_logloss: 0.077729\tvalid_1's auc: 0.787963\tvalid_1's binary_logloss: 0.0793188\n",
      "[160]\ttraining's auc: 0.82572\ttraining's binary_logloss: 0.0777233\tvalid_1's auc: 0.788013\tvalid_1's binary_logloss: 0.0793237\n",
      "[161]\ttraining's auc: 0.825772\ttraining's binary_logloss: 0.0777168\tvalid_1's auc: 0.787858\tvalid_1's binary_logloss: 0.0793436\n",
      "[162]\ttraining's auc: 0.825782\ttraining's binary_logloss: 0.0777134\tvalid_1's auc: 0.787852\tvalid_1's binary_logloss: 0.0793385\n",
      "[163]\ttraining's auc: 0.825843\ttraining's binary_logloss: 0.0777054\tvalid_1's auc: 0.787826\tvalid_1's binary_logloss: 0.0793507\n",
      "[164]\ttraining's auc: 0.825888\ttraining's binary_logloss: 0.077703\tvalid_1's auc: 0.787791\tvalid_1's binary_logloss: 0.0793579\n",
      "[165]\ttraining's auc: 0.825964\ttraining's binary_logloss: 0.0776942\tvalid_1's auc: 0.787754\tvalid_1's binary_logloss: 0.0793678\n",
      "[166]\ttraining's auc: 0.825973\ttraining's binary_logloss: 0.0776913\tvalid_1's auc: 0.787863\tvalid_1's binary_logloss: 0.0793605\n",
      "[167]\ttraining's auc: 0.825993\ttraining's binary_logloss: 0.0776847\tvalid_1's auc: 0.787737\tvalid_1's binary_logloss: 0.0793614\n",
      "[168]\ttraining's auc: 0.826015\ttraining's binary_logloss: 0.0776824\tvalid_1's auc: 0.787725\tvalid_1's binary_logloss: 0.0793556\n",
      "[169]\ttraining's auc: 0.826101\ttraining's binary_logloss: 0.0776756\tvalid_1's auc: 0.787627\tvalid_1's binary_logloss: 0.0793684\n",
      "[170]\ttraining's auc: 0.826166\ttraining's binary_logloss: 0.0776707\tvalid_1's auc: 0.78755\tvalid_1's binary_logloss: 0.079367\n",
      "[171]\ttraining's auc: 0.826187\ttraining's binary_logloss: 0.0776678\tvalid_1's auc: 0.787563\tvalid_1's binary_logloss: 0.0793643\n",
      "[172]\ttraining's auc: 0.82625\ttraining's binary_logloss: 0.0776648\tvalid_1's auc: 0.787604\tvalid_1's binary_logloss: 0.0793723\n",
      "[173]\ttraining's auc: 0.826296\ttraining's binary_logloss: 0.0776628\tvalid_1's auc: 0.787565\tvalid_1's binary_logloss: 0.0793775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[174]\ttraining's auc: 0.826317\ttraining's binary_logloss: 0.0776589\tvalid_1's auc: 0.787618\tvalid_1's binary_logloss: 0.0793724\n",
      "[175]\ttraining's auc: 0.826365\ttraining's binary_logloss: 0.0776509\tvalid_1's auc: 0.787598\tvalid_1's binary_logloss: 0.0793771\n",
      "[176]\ttraining's auc: 0.826413\ttraining's binary_logloss: 0.0776469\tvalid_1's auc: 0.787607\tvalid_1's binary_logloss: 0.0793783\n",
      "[177]\ttraining's auc: 0.826463\ttraining's binary_logloss: 0.077643\tvalid_1's auc: 0.787621\tvalid_1's binary_logloss: 0.0793848\n",
      "[178]\ttraining's auc: 0.826527\ttraining's binary_logloss: 0.077638\tvalid_1's auc: 0.787618\tvalid_1's binary_logloss: 0.0793778\n",
      "[179]\ttraining's auc: 0.826526\ttraining's binary_logloss: 0.0776327\tvalid_1's auc: 0.787583\tvalid_1's binary_logloss: 0.0793926\n",
      "[180]\ttraining's auc: 0.826577\ttraining's binary_logloss: 0.0776282\tvalid_1's auc: 0.787546\tvalid_1's binary_logloss: 0.0793975\n",
      "[181]\ttraining's auc: 0.826595\ttraining's binary_logloss: 0.0776268\tvalid_1's auc: 0.787523\tvalid_1's binary_logloss: 0.0794039\n",
      "[182]\ttraining's auc: 0.826589\ttraining's binary_logloss: 0.0776196\tvalid_1's auc: 0.787427\tvalid_1's binary_logloss: 0.0794095\n",
      "[183]\ttraining's auc: 0.826638\ttraining's binary_logloss: 0.0776147\tvalid_1's auc: 0.787523\tvalid_1's binary_logloss: 0.0794007\n",
      "[184]\ttraining's auc: 0.826679\ttraining's binary_logloss: 0.0776126\tvalid_1's auc: 0.787394\tvalid_1's binary_logloss: 0.0794048\n",
      "[185]\ttraining's auc: 0.826683\ttraining's binary_logloss: 0.0776099\tvalid_1's auc: 0.787474\tvalid_1's binary_logloss: 0.0793973\n",
      "[186]\ttraining's auc: 0.826754\ttraining's binary_logloss: 0.0776025\tvalid_1's auc: 0.787451\tvalid_1's binary_logloss: 0.0794022\n",
      "[187]\ttraining's auc: 0.826799\ttraining's binary_logloss: 0.0775942\tvalid_1's auc: 0.787448\tvalid_1's binary_logloss: 0.0793935\n",
      "[188]\ttraining's auc: 0.826839\ttraining's binary_logloss: 0.0775895\tvalid_1's auc: 0.787499\tvalid_1's binary_logloss: 0.0793901\n",
      "[189]\ttraining's auc: 0.826867\ttraining's binary_logloss: 0.0775812\tvalid_1's auc: 0.787523\tvalid_1's binary_logloss: 0.0793911\n",
      "[190]\ttraining's auc: 0.826921\ttraining's binary_logloss: 0.0775756\tvalid_1's auc: 0.787506\tvalid_1's binary_logloss: 0.0794006\n",
      "[191]\ttraining's auc: 0.826901\ttraining's binary_logloss: 0.0775739\tvalid_1's auc: 0.78748\tvalid_1's binary_logloss: 0.0794022\n",
      "[192]\ttraining's auc: 0.826885\ttraining's binary_logloss: 0.0775721\tvalid_1's auc: 0.787445\tvalid_1's binary_logloss: 0.079408\n",
      "[193]\ttraining's auc: 0.826881\ttraining's binary_logloss: 0.0775694\tvalid_1's auc: 0.787338\tvalid_1's binary_logloss: 0.0794196\n",
      "[194]\ttraining's auc: 0.826876\ttraining's binary_logloss: 0.0775676\tvalid_1's auc: 0.787348\tvalid_1's binary_logloss: 0.0794247\n",
      "[195]\ttraining's auc: 0.826929\ttraining's binary_logloss: 0.0775621\tvalid_1's auc: 0.787236\tvalid_1's binary_logloss: 0.0794231\n",
      "[196]\ttraining's auc: 0.826947\ttraining's binary_logloss: 0.0775562\tvalid_1's auc: 0.78716\tvalid_1's binary_logloss: 0.0794249\n",
      "[197]\ttraining's auc: 0.826999\ttraining's binary_logloss: 0.0775376\tvalid_1's auc: 0.787241\tvalid_1's binary_logloss: 0.0794024\n",
      "[198]\ttraining's auc: 0.827058\ttraining's binary_logloss: 0.0775312\tvalid_1's auc: 0.787194\tvalid_1's binary_logloss: 0.0793981\n",
      "[199]\ttraining's auc: 0.827082\ttraining's binary_logloss: 0.0775254\tvalid_1's auc: 0.787203\tvalid_1's binary_logloss: 0.0793966\n",
      "[200]\ttraining's auc: 0.827148\ttraining's binary_logloss: 0.0775217\tvalid_1's auc: 0.787103\tvalid_1's binary_logloss: 0.07941\n",
      "[201]\ttraining's auc: 0.827152\ttraining's binary_logloss: 0.0775103\tvalid_1's auc: 0.787117\tvalid_1's binary_logloss: 0.0794003\n",
      "[202]\ttraining's auc: 0.827211\ttraining's binary_logloss: 0.0775049\tvalid_1's auc: 0.787192\tvalid_1's binary_logloss: 0.079398\n",
      "[203]\ttraining's auc: 0.827235\ttraining's binary_logloss: 0.0774902\tvalid_1's auc: 0.787189\tvalid_1's binary_logloss: 0.0793946\n",
      "[204]\ttraining's auc: 0.827262\ttraining's binary_logloss: 0.0774884\tvalid_1's auc: 0.787147\tvalid_1's binary_logloss: 0.0793963\n",
      "[205]\ttraining's auc: 0.82726\ttraining's binary_logloss: 0.0774859\tvalid_1's auc: 0.787101\tvalid_1's binary_logloss: 0.0793955\n",
      "[206]\ttraining's auc: 0.827292\ttraining's binary_logloss: 0.0774814\tvalid_1's auc: 0.787137\tvalid_1's binary_logloss: 0.0793906\n",
      "[207]\ttraining's auc: 0.827343\ttraining's binary_logloss: 0.077478\tvalid_1's auc: 0.787076\tvalid_1's binary_logloss: 0.0794013\n",
      "[208]\ttraining's auc: 0.827343\ttraining's binary_logloss: 0.0774746\tvalid_1's auc: 0.787112\tvalid_1's binary_logloss: 0.079403\n",
      "[209]\ttraining's auc: 0.827353\ttraining's binary_logloss: 0.0774714\tvalid_1's auc: 0.787188\tvalid_1's binary_logloss: 0.0794005\n",
      "[210]\ttraining's auc: 0.827382\ttraining's binary_logloss: 0.0774693\tvalid_1's auc: 0.787162\tvalid_1's binary_logloss: 0.0793985\n",
      "[211]\ttraining's auc: 0.827402\ttraining's binary_logloss: 0.0774668\tvalid_1's auc: 0.787093\tvalid_1's binary_logloss: 0.0794024\n",
      "[212]\ttraining's auc: 0.827469\ttraining's binary_logloss: 0.0774593\tvalid_1's auc: 0.787151\tvalid_1's binary_logloss: 0.0793975\n",
      "[213]\ttraining's auc: 0.827511\ttraining's binary_logloss: 0.0774538\tvalid_1's auc: 0.787134\tvalid_1's binary_logloss: 0.0794059\n",
      "[214]\ttraining's auc: 0.827502\ttraining's binary_logloss: 0.0774496\tvalid_1's auc: 0.78686\tvalid_1's binary_logloss: 0.0794286\n",
      "[215]\ttraining's auc: 0.827518\ttraining's binary_logloss: 0.0774469\tvalid_1's auc: 0.786847\tvalid_1's binary_logloss: 0.0794253\n",
      "[216]\ttraining's auc: 0.827543\ttraining's binary_logloss: 0.0774427\tvalid_1's auc: 0.786826\tvalid_1's binary_logloss: 0.0794141\n",
      "[217]\ttraining's auc: 0.827547\ttraining's binary_logloss: 0.0774406\tvalid_1's auc: 0.786824\tvalid_1's binary_logloss: 0.0794049\n",
      "[218]\ttraining's auc: 0.827565\ttraining's binary_logloss: 0.0774358\tvalid_1's auc: 0.786819\tvalid_1's binary_logloss: 0.0794086\n",
      "[219]\ttraining's auc: 0.827579\ttraining's binary_logloss: 0.0774324\tvalid_1's auc: 0.786808\tvalid_1's binary_logloss: 0.0794215\n",
      "[220]\ttraining's auc: 0.827605\ttraining's binary_logloss: 0.0774282\tvalid_1's auc: 0.786917\tvalid_1's binary_logloss: 0.0794059\n",
      "[221]\ttraining's auc: 0.827655\ttraining's binary_logloss: 0.0774197\tvalid_1's auc: 0.786786\tvalid_1's binary_logloss: 0.0793997\n",
      "[222]\ttraining's auc: 0.827698\ttraining's binary_logloss: 0.0774184\tvalid_1's auc: 0.78679\tvalid_1's binary_logloss: 0.0793977\n",
      "[223]\ttraining's auc: 0.82771\ttraining's binary_logloss: 0.0774165\tvalid_1's auc: 0.786709\tvalid_1's binary_logloss: 0.0793992\n",
      "[224]\ttraining's auc: 0.827712\ttraining's binary_logloss: 0.077413\tvalid_1's auc: 0.786664\tvalid_1's binary_logloss: 0.0794038\n",
      "[225]\ttraining's auc: 0.827779\ttraining's binary_logloss: 0.0774083\tvalid_1's auc: 0.786625\tvalid_1's binary_logloss: 0.0794039\n",
      "[226]\ttraining's auc: 0.827795\ttraining's binary_logloss: 0.0774063\tvalid_1's auc: 0.786628\tvalid_1's binary_logloss: 0.0794098\n",
      "[227]\ttraining's auc: 0.827835\ttraining's binary_logloss: 0.0773923\tvalid_1's auc: 0.786697\tvalid_1's binary_logloss: 0.0793883\n",
      "[228]\ttraining's auc: 0.827842\ttraining's binary_logloss: 0.0773898\tvalid_1's auc: 0.786608\tvalid_1's binary_logloss: 0.0793921\n",
      "[229]\ttraining's auc: 0.827879\ttraining's binary_logloss: 0.0773825\tvalid_1's auc: 0.786525\tvalid_1's binary_logloss: 0.0793926\n",
      "[230]\ttraining's auc: 0.82795\ttraining's binary_logloss: 0.077377\tvalid_1's auc: 0.786513\tvalid_1's binary_logloss: 0.0794009\n",
      "[231]\ttraining's auc: 0.828009\ttraining's binary_logloss: 0.0773708\tvalid_1's auc: 0.786345\tvalid_1's binary_logloss: 0.0794141\n",
      "[232]\ttraining's auc: 0.828056\ttraining's binary_logloss: 0.0773597\tvalid_1's auc: 0.786291\tvalid_1's binary_logloss: 0.0794111\n",
      "[233]\ttraining's auc: 0.828098\ttraining's binary_logloss: 0.077354\tvalid_1's auc: 0.786204\tvalid_1's binary_logloss: 0.0794064\n",
      "[234]\ttraining's auc: 0.828128\ttraining's binary_logloss: 0.0773508\tvalid_1's auc: 0.786085\tvalid_1's binary_logloss: 0.0794093\n",
      "[235]\ttraining's auc: 0.82815\ttraining's binary_logloss: 0.0773497\tvalid_1's auc: 0.786007\tvalid_1's binary_logloss: 0.0794137\n",
      "[236]\ttraining's auc: 0.828221\ttraining's binary_logloss: 0.0773449\tvalid_1's auc: 0.785877\tvalid_1's binary_logloss: 0.0794173\n",
      "[237]\ttraining's auc: 0.828236\ttraining's binary_logloss: 0.0773401\tvalid_1's auc: 0.785818\tvalid_1's binary_logloss: 0.0794281\n",
      "[238]\ttraining's auc: 0.828256\ttraining's binary_logloss: 0.0773382\tvalid_1's auc: 0.785858\tvalid_1's binary_logloss: 0.0794186\n",
      "[239]\ttraining's auc: 0.828285\ttraining's binary_logloss: 0.0773344\tvalid_1's auc: 0.785886\tvalid_1's binary_logloss: 0.0794185\n",
      "[240]\ttraining's auc: 0.828326\ttraining's binary_logloss: 0.0773297\tvalid_1's auc: 0.785828\tvalid_1's binary_logloss: 0.0794238\n",
      "Early stopping, best iteration is:\n",
      "[140]\ttraining's auc: 0.824826\ttraining's binary_logloss: 0.0778678\tvalid_1's auc: 0.788283\tvalid_1's binary_logloss: 0.0793126\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# 准备用来保存 特征结果   训练集ks值 测试集ks值的list\n",
    "feature_lst ={}\n",
    "ks_train_lst=[]\n",
    "ks_test_lst = []\n",
    "for rk in set(df_train['rank']):\n",
    "    #遍历rank 中的每一箱 一共是5箱\n",
    "    # 遍历到当前的箱 作为交叉验证的测试数据\n",
    "    ttest = df_train[df_train['rank']==rk]\n",
    "    # 剩下的4箱作为训练数据\n",
    "    ttrain = df_train[df_train['rank']!=rk]\n",
    "    \n",
    "    train = ttrain[lst]  # 从交叉验证的训练集中取出特征\n",
    "    train_y = ttrain.bad_ind   #从交叉验证的训练集中取出目标\n",
    "    \n",
    "    test = ttest[lst]\n",
    "    test_y = ttest.bad_ind\n",
    "    \n",
    "    # 调用封装好的LGB_test函数，传入训练集和测试集数据 \n",
    "    # 返回一个lgbm模型 和auc的值\n",
    "    model,auc = LGB_test(train,train_y,test,test_y)\n",
    "    # 从model 中获取传入特征的重要程度\n",
    "    feature = pd.DataFrame({'name':model.booster_.feature_name(),'importance':model.feature_importances_}).sort_values(by=['importance'],ascending = False)\n",
    "    \n",
    "    #计算训练集 测试集 验证集上的ks和auc\n",
    "    y_pred_train_lgb = model.predict_proba(train)[:,1]   #取出训练集 测试集 预测结果 是坏人的概率\n",
    "    y_pred_test_lgb = model.predict_proba(test)[:,1]\n",
    "    train_fpr_lgb,train_tpr_lgb,_ = roc_curve(train_y,y_pred_train_lgb) # 计算训练集和测试集的 tpr和fpr\n",
    "    test_fpr_lgb,test_tpr_lgb,_ = roc_curve(test_y,y_pred_test_lgb)\n",
    "    train_ks = abs(train_fpr_lgb-train_tpr_lgb).max()\n",
    "    test_ks = abs(test_fpr_lgb-test_tpr_lgb).max()\n",
    "    \n",
    "    train_auc = metrics.auc(train_fpr_lgb,train_tpr_lgb)\n",
    "    test_auc = metrics.auc(test_fpr_lgb,test_tpr_lgb)\n",
    "    \n",
    "    ks_train_lst.append(train_ks)\n",
    "    ks_test_lst.append(test_ks)\n",
    "    \n",
    "    feature_lst[str(rk)] = feature[feature.importance>=20].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ks = np.mean(ks_train_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4893612378549733"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ks = np.mean(ks_test_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4717273838273967"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank\n",
       "1    15966\n",
       "2    15966\n",
       "3    15966\n",
       "4    15966\n",
       "5    15967\n",
       "Name: rank, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['rank'].groupby(df_train['rank']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1    finance_info\n",
       " Name: name, dtype: object, '2': 1    finance_info\n",
       " 0     person_info\n",
       " 2     credit_info\n",
       " 3        act_info\n",
       " 6        mj_score\n",
       " Name: name, dtype: object, '3': 1    finance_info\n",
       " 0     person_info\n",
       " 2     credit_info\n",
       " 3        act_info\n",
       " Name: name, dtype: object, '4': 1    finance_info\n",
       " 0     person_info\n",
       " 2     credit_info\n",
       " 3        act_info\n",
       " 6        mj_score\n",
       " 4        td_score\n",
       " Name: name, dtype: object, '5': 1    finance_info\n",
       " 2     credit_info\n",
       " 0     person_info\n",
       " 3        act_info\n",
       " 6        mj_score\n",
       " 4        td_score\n",
       " Name: name, dtype: object}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_lst={}\n",
    "for i in range(1,6):\n",
    "    ft_lst[str(i)] = feature_lst[str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_lst=list(set(ft_lst['1']) & set(ft_lst['2']) \n",
    "    & set(ft_lst['3']) & set(ft_lst['4']) &set(ft_lst['5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.737137\ttraining's binary_logloss: 0.0832707\tvalid_1's auc: 0.712178\tvalid_1's binary_logloss: 0.12168\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.779956\ttraining's binary_logloss: 0.0821329\tvalid_1's auc: 0.773038\tvalid_1's binary_logloss: 0.119538\n",
      "[3]\ttraining's auc: 0.787657\ttraining's binary_logloss: 0.0816239\tvalid_1's auc: 0.759829\tvalid_1's binary_logloss: 0.118773\n",
      "[4]\ttraining's auc: 0.787083\ttraining's binary_logloss: 0.0811169\tvalid_1's auc: 0.758327\tvalid_1's binary_logloss: 0.117919\n",
      "[5]\ttraining's auc: 0.791363\ttraining's binary_logloss: 0.0803378\tvalid_1's auc: 0.768679\tvalid_1's binary_logloss: 0.116488\n",
      "[6]\ttraining's auc: 0.797614\ttraining's binary_logloss: 0.0796057\tvalid_1's auc: 0.779753\tvalid_1's binary_logloss: 0.11516\n",
      "[7]\ttraining's auc: 0.796785\ttraining's binary_logloss: 0.0792409\tvalid_1's auc: 0.779428\tvalid_1's binary_logloss: 0.114638\n",
      "[8]\ttraining's auc: 0.799178\ttraining's binary_logloss: 0.0786552\tvalid_1's auc: 0.779952\tvalid_1's binary_logloss: 0.1136\n",
      "[9]\ttraining's auc: 0.800233\ttraining's binary_logloss: 0.078141\tvalid_1's auc: 0.780585\tvalid_1's binary_logloss: 0.112795\n",
      "[10]\ttraining's auc: 0.800095\ttraining's binary_logloss: 0.0778623\tvalid_1's auc: 0.779255\tvalid_1's binary_logloss: 0.11246\n",
      "[11]\ttraining's auc: 0.800564\ttraining's binary_logloss: 0.0773838\tvalid_1's auc: 0.780632\tvalid_1's binary_logloss: 0.11162\n",
      "[12]\ttraining's auc: 0.801518\ttraining's binary_logloss: 0.0769709\tvalid_1's auc: 0.782005\tvalid_1's binary_logloss: 0.110988\n",
      "[13]\ttraining's auc: 0.799616\ttraining's binary_logloss: 0.076757\tvalid_1's auc: 0.779543\tvalid_1's binary_logloss: 0.110771\n",
      "[14]\ttraining's auc: 0.799979\ttraining's binary_logloss: 0.0764021\tvalid_1's auc: 0.780339\tvalid_1's binary_logloss: 0.110206\n",
      "[15]\ttraining's auc: 0.803135\ttraining's binary_logloss: 0.0760872\tvalid_1's auc: 0.782372\tvalid_1's binary_logloss: 0.109794\n",
      "[16]\ttraining's auc: 0.803352\ttraining's binary_logloss: 0.0758013\tvalid_1's auc: 0.783064\tvalid_1's binary_logloss: 0.109309\n",
      "[17]\ttraining's auc: 0.804747\ttraining's binary_logloss: 0.0755999\tvalid_1's auc: 0.783873\tvalid_1's binary_logloss: 0.109072\n",
      "[18]\ttraining's auc: 0.804488\ttraining's binary_logloss: 0.0753487\tvalid_1's auc: 0.784544\tvalid_1's binary_logloss: 0.108687\n",
      "[19]\ttraining's auc: 0.805255\ttraining's binary_logloss: 0.0751014\tvalid_1's auc: 0.784966\tvalid_1's binary_logloss: 0.10833\n",
      "[20]\ttraining's auc: 0.805515\ttraining's binary_logloss: 0.0749265\tvalid_1's auc: 0.784932\tvalid_1's binary_logloss: 0.108144\n",
      "[21]\ttraining's auc: 0.805492\ttraining's binary_logloss: 0.074729\tvalid_1's auc: 0.785172\tvalid_1's binary_logloss: 0.107857\n",
      "[22]\ttraining's auc: 0.806313\ttraining's binary_logloss: 0.0745607\tvalid_1's auc: 0.785839\tvalid_1's binary_logloss: 0.107622\n",
      "[23]\ttraining's auc: 0.806817\ttraining's binary_logloss: 0.074424\tvalid_1's auc: 0.785816\tvalid_1's binary_logloss: 0.107488\n",
      "[24]\ttraining's auc: 0.807193\ttraining's binary_logloss: 0.0742699\tvalid_1's auc: 0.78552\tvalid_1's binary_logloss: 0.107392\n",
      "[25]\ttraining's auc: 0.807639\ttraining's binary_logloss: 0.0741103\tvalid_1's auc: 0.785228\tvalid_1's binary_logloss: 0.10721\n",
      "[26]\ttraining's auc: 0.808227\ttraining's binary_logloss: 0.0739871\tvalid_1's auc: 0.784998\tvalid_1's binary_logloss: 0.107082\n",
      "[27]\ttraining's auc: 0.809528\ttraining's binary_logloss: 0.0738892\tvalid_1's auc: 0.784879\tvalid_1's binary_logloss: 0.106981\n",
      "[28]\ttraining's auc: 0.811116\ttraining's binary_logloss: 0.0737893\tvalid_1's auc: 0.786362\tvalid_1's binary_logloss: 0.106936\n",
      "[29]\ttraining's auc: 0.810897\ttraining's binary_logloss: 0.073679\tvalid_1's auc: 0.786837\tvalid_1's binary_logloss: 0.106795\n",
      "[30]\ttraining's auc: 0.811648\ttraining's binary_logloss: 0.0735682\tvalid_1's auc: 0.786791\tvalid_1's binary_logloss: 0.106699\n",
      "[31]\ttraining's auc: 0.811873\ttraining's binary_logloss: 0.0734598\tvalid_1's auc: 0.786316\tvalid_1's binary_logloss: 0.106619\n",
      "[32]\ttraining's auc: 0.811835\ttraining's binary_logloss: 0.0733832\tvalid_1's auc: 0.786031\tvalid_1's binary_logloss: 0.106599\n",
      "[33]\ttraining's auc: 0.811977\ttraining's binary_logloss: 0.073282\tvalid_1's auc: 0.786137\tvalid_1's binary_logloss: 0.106495\n",
      "[34]\ttraining's auc: 0.812127\ttraining's binary_logloss: 0.0732173\tvalid_1's auc: 0.785708\tvalid_1's binary_logloss: 0.106511\n",
      "[35]\ttraining's auc: 0.812001\ttraining's binary_logloss: 0.0731508\tvalid_1's auc: 0.785861\tvalid_1's binary_logloss: 0.106454\n",
      "[36]\ttraining's auc: 0.812269\ttraining's binary_logloss: 0.0730878\tvalid_1's auc: 0.785533\tvalid_1's binary_logloss: 0.106435\n",
      "[37]\ttraining's auc: 0.81302\ttraining's binary_logloss: 0.0730101\tvalid_1's auc: 0.784796\tvalid_1's binary_logloss: 0.106412\n",
      "[38]\ttraining's auc: 0.813302\ttraining's binary_logloss: 0.0729402\tvalid_1's auc: 0.784632\tvalid_1's binary_logloss: 0.106409\n",
      "[39]\ttraining's auc: 0.813896\ttraining's binary_logloss: 0.0728764\tvalid_1's auc: 0.784974\tvalid_1's binary_logloss: 0.106342\n",
      "[40]\ttraining's auc: 0.814032\ttraining's binary_logloss: 0.072824\tvalid_1's auc: 0.785171\tvalid_1's binary_logloss: 0.106288\n",
      "[41]\ttraining's auc: 0.814233\ttraining's binary_logloss: 0.0727596\tvalid_1's auc: 0.785623\tvalid_1's binary_logloss: 0.106237\n",
      "[42]\ttraining's auc: 0.814391\ttraining's binary_logloss: 0.0727135\tvalid_1's auc: 0.785634\tvalid_1's binary_logloss: 0.106207\n",
      "[43]\ttraining's auc: 0.814671\ttraining's binary_logloss: 0.0726635\tvalid_1's auc: 0.785777\tvalid_1's binary_logloss: 0.106172\n",
      "[44]\ttraining's auc: 0.814689\ttraining's binary_logloss: 0.0726168\tvalid_1's auc: 0.785387\tvalid_1's binary_logloss: 0.106188\n",
      "[45]\ttraining's auc: 0.814518\ttraining's binary_logloss: 0.0725737\tvalid_1's auc: 0.78547\tvalid_1's binary_logloss: 0.10613\n",
      "[46]\ttraining's auc: 0.814832\ttraining's binary_logloss: 0.0725258\tvalid_1's auc: 0.785709\tvalid_1's binary_logloss: 0.106099\n",
      "[47]\ttraining's auc: 0.815099\ttraining's binary_logloss: 0.0724814\tvalid_1's auc: 0.785959\tvalid_1's binary_logloss: 0.106053\n",
      "[48]\ttraining's auc: 0.815353\ttraining's binary_logloss: 0.0724374\tvalid_1's auc: 0.785874\tvalid_1's binary_logloss: 0.106026\n",
      "[49]\ttraining's auc: 0.81525\ttraining's binary_logloss: 0.0723973\tvalid_1's auc: 0.78591\tvalid_1's binary_logloss: 0.106027\n",
      "[50]\ttraining's auc: 0.815296\ttraining's binary_logloss: 0.0723627\tvalid_1's auc: 0.78581\tvalid_1's binary_logloss: 0.106005\n",
      "[51]\ttraining's auc: 0.815512\ttraining's binary_logloss: 0.0723276\tvalid_1's auc: 0.785415\tvalid_1's binary_logloss: 0.10604\n",
      "[52]\ttraining's auc: 0.815828\ttraining's binary_logloss: 0.0723091\tvalid_1's auc: 0.785942\tvalid_1's binary_logloss: 0.106002\n",
      "[53]\ttraining's auc: 0.8156\ttraining's binary_logloss: 0.072295\tvalid_1's auc: 0.785885\tvalid_1's binary_logloss: 0.105995\n",
      "[54]\ttraining's auc: 0.815635\ttraining's binary_logloss: 0.0722595\tvalid_1's auc: 0.785942\tvalid_1's binary_logloss: 0.10599\n",
      "[55]\ttraining's auc: 0.815678\ttraining's binary_logloss: 0.0722314\tvalid_1's auc: 0.785967\tvalid_1's binary_logloss: 0.106\n",
      "[56]\ttraining's auc: 0.815706\ttraining's binary_logloss: 0.0721984\tvalid_1's auc: 0.785853\tvalid_1's binary_logloss: 0.105979\n",
      "[57]\ttraining's auc: 0.816073\ttraining's binary_logloss: 0.0721753\tvalid_1's auc: 0.786098\tvalid_1's binary_logloss: 0.105963\n",
      "[58]\ttraining's auc: 0.8161\ttraining's binary_logloss: 0.0721507\tvalid_1's auc: 0.785843\tvalid_1's binary_logloss: 0.10596\n",
      "[59]\ttraining's auc: 0.816179\ttraining's binary_logloss: 0.0721195\tvalid_1's auc: 0.78596\tvalid_1's binary_logloss: 0.105927\n",
      "[60]\ttraining's auc: 0.816269\ttraining's binary_logloss: 0.072096\tvalid_1's auc: 0.786205\tvalid_1's binary_logloss: 0.105923\n",
      "[61]\ttraining's auc: 0.816416\ttraining's binary_logloss: 0.0720742\tvalid_1's auc: 0.786516\tvalid_1's binary_logloss: 0.105911\n",
      "[62]\ttraining's auc: 0.816535\ttraining's binary_logloss: 0.072049\tvalid_1's auc: 0.786509\tvalid_1's binary_logloss: 0.10592\n",
      "[63]\ttraining's auc: 0.816589\ttraining's binary_logloss: 0.072023\tvalid_1's auc: 0.786443\tvalid_1's binary_logloss: 0.10595\n",
      "[64]\ttraining's auc: 0.816668\ttraining's binary_logloss: 0.072005\tvalid_1's auc: 0.786688\tvalid_1's binary_logloss: 0.105935\n",
      "[65]\ttraining's auc: 0.816827\ttraining's binary_logloss: 0.071983\tvalid_1's auc: 0.786675\tvalid_1's binary_logloss: 0.105958\n",
      "[66]\ttraining's auc: 0.816955\ttraining's binary_logloss: 0.0719667\tvalid_1's auc: 0.786444\tvalid_1's binary_logloss: 0.105989\n",
      "[67]\ttraining's auc: 0.817083\ttraining's binary_logloss: 0.0719441\tvalid_1's auc: 0.785922\tvalid_1's binary_logloss: 0.106031\n",
      "[68]\ttraining's auc: 0.817243\ttraining's binary_logloss: 0.0719268\tvalid_1's auc: 0.785906\tvalid_1's binary_logloss: 0.106044\n",
      "[69]\ttraining's auc: 0.817256\ttraining's binary_logloss: 0.0719066\tvalid_1's auc: 0.785847\tvalid_1's binary_logloss: 0.106065\n",
      "[70]\ttraining's auc: 0.817406\ttraining's binary_logloss: 0.071888\tvalid_1's auc: 0.785889\tvalid_1's binary_logloss: 0.106065\n",
      "[71]\ttraining's auc: 0.817542\ttraining's binary_logloss: 0.0718725\tvalid_1's auc: 0.785982\tvalid_1's binary_logloss: 0.106052\n",
      "[72]\ttraining's auc: 0.81753\ttraining's binary_logloss: 0.0718579\tvalid_1's auc: 0.785898\tvalid_1's binary_logloss: 0.10607\n",
      "[73]\ttraining's auc: 0.817572\ttraining's binary_logloss: 0.0718444\tvalid_1's auc: 0.785999\tvalid_1's binary_logloss: 0.106067\n",
      "[74]\ttraining's auc: 0.8177\ttraining's binary_logloss: 0.0718338\tvalid_1's auc: 0.786248\tvalid_1's binary_logloss: 0.106055\n",
      "[75]\ttraining's auc: 0.817776\ttraining's binary_logloss: 0.0718139\tvalid_1's auc: 0.786254\tvalid_1's binary_logloss: 0.10606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76]\ttraining's auc: 0.817746\ttraining's binary_logloss: 0.0717932\tvalid_1's auc: 0.786234\tvalid_1's binary_logloss: 0.106069\n",
      "[77]\ttraining's auc: 0.817805\ttraining's binary_logloss: 0.0717813\tvalid_1's auc: 0.786385\tvalid_1's binary_logloss: 0.106051\n",
      "[78]\ttraining's auc: 0.81785\ttraining's binary_logloss: 0.0717608\tvalid_1's auc: 0.786448\tvalid_1's binary_logloss: 0.106048\n",
      "[79]\ttraining's auc: 0.817856\ttraining's binary_logloss: 0.0717497\tvalid_1's auc: 0.786389\tvalid_1's binary_logloss: 0.106043\n",
      "[80]\ttraining's auc: 0.817805\ttraining's binary_logloss: 0.0717335\tvalid_1's auc: 0.78636\tvalid_1's binary_logloss: 0.106046\n",
      "[81]\ttraining's auc: 0.817929\ttraining's binary_logloss: 0.0717176\tvalid_1's auc: 0.786105\tvalid_1's binary_logloss: 0.106076\n",
      "[82]\ttraining's auc: 0.817987\ttraining's binary_logloss: 0.0717058\tvalid_1's auc: 0.786264\tvalid_1's binary_logloss: 0.106065\n",
      "[83]\ttraining's auc: 0.818062\ttraining's binary_logloss: 0.0716967\tvalid_1's auc: 0.786325\tvalid_1's binary_logloss: 0.106059\n",
      "[84]\ttraining's auc: 0.818091\ttraining's binary_logloss: 0.0716696\tvalid_1's auc: 0.786403\tvalid_1's binary_logloss: 0.106049\n",
      "[85]\ttraining's auc: 0.81818\ttraining's binary_logloss: 0.0716594\tvalid_1's auc: 0.786479\tvalid_1's binary_logloss: 0.106048\n",
      "[86]\ttraining's auc: 0.818214\ttraining's binary_logloss: 0.0716463\tvalid_1's auc: 0.786461\tvalid_1's binary_logloss: 0.10606\n",
      "[87]\ttraining's auc: 0.818102\ttraining's binary_logloss: 0.0716312\tvalid_1's auc: 0.786457\tvalid_1's binary_logloss: 0.106056\n",
      "[88]\ttraining's auc: 0.818067\ttraining's binary_logloss: 0.0716195\tvalid_1's auc: 0.786229\tvalid_1's binary_logloss: 0.106095\n",
      "[89]\ttraining's auc: 0.818104\ttraining's binary_logloss: 0.0716098\tvalid_1's auc: 0.786207\tvalid_1's binary_logloss: 0.106104\n",
      "[90]\ttraining's auc: 0.818199\ttraining's binary_logloss: 0.0716011\tvalid_1's auc: 0.786273\tvalid_1's binary_logloss: 0.106097\n",
      "[91]\ttraining's auc: 0.818391\ttraining's binary_logloss: 0.0715871\tvalid_1's auc: 0.7861\tvalid_1's binary_logloss: 0.106126\n",
      "[92]\ttraining's auc: 0.818523\ttraining's binary_logloss: 0.0715764\tvalid_1's auc: 0.786037\tvalid_1's binary_logloss: 0.106121\n",
      "[93]\ttraining's auc: 0.818597\ttraining's binary_logloss: 0.0715668\tvalid_1's auc: 0.786146\tvalid_1's binary_logloss: 0.106108\n",
      "[94]\ttraining's auc: 0.818624\ttraining's binary_logloss: 0.0715592\tvalid_1's auc: 0.786339\tvalid_1's binary_logloss: 0.106085\n",
      "[95]\ttraining's auc: 0.818724\ttraining's binary_logloss: 0.0715506\tvalid_1's auc: 0.786396\tvalid_1's binary_logloss: 0.106081\n",
      "[96]\ttraining's auc: 0.818797\ttraining's binary_logloss: 0.0715474\tvalid_1's auc: 0.786419\tvalid_1's binary_logloss: 0.106079\n",
      "[97]\ttraining's auc: 0.818848\ttraining's binary_logloss: 0.0715404\tvalid_1's auc: 0.786248\tvalid_1's binary_logloss: 0.106119\n",
      "[98]\ttraining's auc: 0.818902\ttraining's binary_logloss: 0.071534\tvalid_1's auc: 0.786302\tvalid_1's binary_logloss: 0.106112\n",
      "[99]\ttraining's auc: 0.818911\ttraining's binary_logloss: 0.071526\tvalid_1's auc: 0.786098\tvalid_1's binary_logloss: 0.106131\n",
      "[100]\ttraining's auc: 0.81893\ttraining's binary_logloss: 0.0715171\tvalid_1's auc: 0.786155\tvalid_1's binary_logloss: 0.10613\n",
      "[101]\ttraining's auc: 0.818953\ttraining's binary_logloss: 0.0715093\tvalid_1's auc: 0.786286\tvalid_1's binary_logloss: 0.10611\n",
      "[102]\ttraining's auc: 0.818995\ttraining's binary_logloss: 0.0715053\tvalid_1's auc: 0.786287\tvalid_1's binary_logloss: 0.106115\n",
      "[103]\ttraining's auc: 0.819091\ttraining's binary_logloss: 0.0714988\tvalid_1's auc: 0.78631\tvalid_1's binary_logloss: 0.106116\n",
      "[104]\ttraining's auc: 0.819228\ttraining's binary_logloss: 0.0714904\tvalid_1's auc: 0.786354\tvalid_1's binary_logloss: 0.106121\n",
      "[105]\ttraining's auc: 0.819244\ttraining's binary_logloss: 0.0714846\tvalid_1's auc: 0.786111\tvalid_1's binary_logloss: 0.106136\n",
      "[106]\ttraining's auc: 0.819265\ttraining's binary_logloss: 0.071478\tvalid_1's auc: 0.786237\tvalid_1's binary_logloss: 0.106122\n",
      "[107]\ttraining's auc: 0.819366\ttraining's binary_logloss: 0.0714687\tvalid_1's auc: 0.786319\tvalid_1's binary_logloss: 0.106117\n",
      "[108]\ttraining's auc: 0.819407\ttraining's binary_logloss: 0.0714625\tvalid_1's auc: 0.786366\tvalid_1's binary_logloss: 0.106104\n",
      "[109]\ttraining's auc: 0.819394\ttraining's binary_logloss: 0.0714565\tvalid_1's auc: 0.78624\tvalid_1's binary_logloss: 0.106119\n",
      "[110]\ttraining's auc: 0.819456\ttraining's binary_logloss: 0.0714378\tvalid_1's auc: 0.786298\tvalid_1's binary_logloss: 0.106121\n",
      "[111]\ttraining's auc: 0.819495\ttraining's binary_logloss: 0.0714317\tvalid_1's auc: 0.786337\tvalid_1's binary_logloss: 0.106128\n",
      "[112]\ttraining's auc: 0.819593\ttraining's binary_logloss: 0.0714241\tvalid_1's auc: 0.786212\tvalid_1's binary_logloss: 0.10614\n",
      "[113]\ttraining's auc: 0.819588\ttraining's binary_logloss: 0.0714217\tvalid_1's auc: 0.786266\tvalid_1's binary_logloss: 0.106136\n",
      "[114]\ttraining's auc: 0.819637\ttraining's binary_logloss: 0.0714143\tvalid_1's auc: 0.786454\tvalid_1's binary_logloss: 0.106111\n",
      "[115]\ttraining's auc: 0.819691\ttraining's binary_logloss: 0.0714069\tvalid_1's auc: 0.786437\tvalid_1's binary_logloss: 0.106119\n",
      "[116]\ttraining's auc: 0.819697\ttraining's binary_logloss: 0.0714035\tvalid_1's auc: 0.786476\tvalid_1's binary_logloss: 0.106111\n",
      "[117]\ttraining's auc: 0.81972\ttraining's binary_logloss: 0.0713982\tvalid_1's auc: 0.786557\tvalid_1's binary_logloss: 0.106108\n",
      "[118]\ttraining's auc: 0.819713\ttraining's binary_logloss: 0.0713928\tvalid_1's auc: 0.786523\tvalid_1's binary_logloss: 0.106116\n",
      "[119]\ttraining's auc: 0.819763\ttraining's binary_logloss: 0.0713878\tvalid_1's auc: 0.786595\tvalid_1's binary_logloss: 0.106118\n",
      "[120]\ttraining's auc: 0.819796\ttraining's binary_logloss: 0.0713836\tvalid_1's auc: 0.786625\tvalid_1's binary_logloss: 0.106106\n",
      "[121]\ttraining's auc: 0.819797\ttraining's binary_logloss: 0.0713798\tvalid_1's auc: 0.78641\tvalid_1's binary_logloss: 0.106126\n",
      "[122]\ttraining's auc: 0.81984\ttraining's binary_logloss: 0.0713757\tvalid_1's auc: 0.786368\tvalid_1's binary_logloss: 0.106127\n",
      "[123]\ttraining's auc: 0.819883\ttraining's binary_logloss: 0.0713706\tvalid_1's auc: 0.78633\tvalid_1's binary_logloss: 0.106133\n",
      "[124]\ttraining's auc: 0.819958\ttraining's binary_logloss: 0.0713496\tvalid_1's auc: 0.786431\tvalid_1's binary_logloss: 0.10612\n",
      "[125]\ttraining's auc: 0.820053\ttraining's binary_logloss: 0.0713432\tvalid_1's auc: 0.786387\tvalid_1's binary_logloss: 0.106119\n",
      "[126]\ttraining's auc: 0.820094\ttraining's binary_logloss: 0.0713362\tvalid_1's auc: 0.786264\tvalid_1's binary_logloss: 0.106145\n",
      "[127]\ttraining's auc: 0.820124\ttraining's binary_logloss: 0.0713233\tvalid_1's auc: 0.786321\tvalid_1's binary_logloss: 0.106139\n",
      "[128]\ttraining's auc: 0.82014\ttraining's binary_logloss: 0.0713187\tvalid_1's auc: 0.786278\tvalid_1's binary_logloss: 0.106147\n",
      "[129]\ttraining's auc: 0.820194\ttraining's binary_logloss: 0.0713123\tvalid_1's auc: 0.786063\tvalid_1's binary_logloss: 0.106171\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's auc: 0.810897\ttraining's binary_logloss: 0.073679\tvalid_1's auc: 0.786837\tvalid_1's binary_logloss: 0.106795\n",
      "8\n",
      "[1]\ttraining's auc: 0.741457\ttraining's binary_logloss: 0.0863868\tvalid_1's auc: 0.713623\tvalid_1's binary_logloss: 0.109309\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.78475\ttraining's binary_logloss: 0.0852072\tvalid_1's auc: 0.771443\tvalid_1's binary_logloss: 0.107672\n",
      "[3]\ttraining's auc: 0.789005\ttraining's binary_logloss: 0.0846673\tvalid_1's auc: 0.773894\tvalid_1's binary_logloss: 0.107001\n",
      "[4]\ttraining's auc: 0.785614\ttraining's binary_logloss: 0.0841296\tvalid_1's auc: 0.768015\tvalid_1's binary_logloss: 0.106362\n",
      "[5]\ttraining's auc: 0.79808\ttraining's binary_logloss: 0.0832829\tvalid_1's auc: 0.782823\tvalid_1's binary_logloss: 0.105157\n",
      "[6]\ttraining's auc: 0.798957\ttraining's binary_logloss: 0.0825228\tvalid_1's auc: 0.783147\tvalid_1's binary_logloss: 0.104134\n",
      "[7]\ttraining's auc: 0.799081\ttraining's binary_logloss: 0.0821122\tvalid_1's auc: 0.781683\tvalid_1's binary_logloss: 0.103707\n",
      "[8]\ttraining's auc: 0.799412\ttraining's binary_logloss: 0.0814982\tvalid_1's auc: 0.783838\tvalid_1's binary_logloss: 0.102936\n",
      "[9]\ttraining's auc: 0.801202\ttraining's binary_logloss: 0.0808916\tvalid_1's auc: 0.785921\tvalid_1's binary_logloss: 0.102128\n",
      "[10]\ttraining's auc: 0.801876\ttraining's binary_logloss: 0.0806186\tvalid_1's auc: 0.785232\tvalid_1's binary_logloss: 0.101833\n",
      "[11]\ttraining's auc: 0.802208\ttraining's binary_logloss: 0.0801273\tvalid_1's auc: 0.784914\tvalid_1's binary_logloss: 0.101233\n",
      "[12]\ttraining's auc: 0.802796\ttraining's binary_logloss: 0.0797167\tvalid_1's auc: 0.786252\tvalid_1's binary_logloss: 0.100718\n",
      "[13]\ttraining's auc: 0.802697\ttraining's binary_logloss: 0.0795035\tvalid_1's auc: 0.785844\tvalid_1's binary_logloss: 0.100485\n",
      "[14]\ttraining's auc: 0.80318\ttraining's binary_logloss: 0.0791192\tvalid_1's auc: 0.786648\tvalid_1's binary_logloss: 0.100034\n",
      "[15]\ttraining's auc: 0.803128\ttraining's binary_logloss: 0.0787713\tvalid_1's auc: 0.787153\tvalid_1's binary_logloss: 0.0996265\n",
      "[16]\ttraining's auc: 0.803674\ttraining's binary_logloss: 0.0784644\tvalid_1's auc: 0.787695\tvalid_1's binary_logloss: 0.09926\n",
      "[17]\ttraining's auc: 0.804562\ttraining's binary_logloss: 0.0782762\tvalid_1's auc: 0.787497\tvalid_1's binary_logloss: 0.0990753\n",
      "[18]\ttraining's auc: 0.804588\ttraining's binary_logloss: 0.0780198\tvalid_1's auc: 0.787855\tvalid_1's binary_logloss: 0.0987797\n",
      "[19]\ttraining's auc: 0.804856\ttraining's binary_logloss: 0.0777733\tvalid_1's auc: 0.788215\tvalid_1's binary_logloss: 0.0984624\n",
      "[20]\ttraining's auc: 0.805389\ttraining's binary_logloss: 0.0776052\tvalid_1's auc: 0.788883\tvalid_1's binary_logloss: 0.0982687\n",
      "[21]\ttraining's auc: 0.80535\ttraining's binary_logloss: 0.0774064\tvalid_1's auc: 0.789094\tvalid_1's binary_logloss: 0.0980445\n",
      "[22]\ttraining's auc: 0.805832\ttraining's binary_logloss: 0.0772279\tvalid_1's auc: 0.789989\tvalid_1's binary_logloss: 0.0978326\n",
      "[23]\ttraining's auc: 0.805626\ttraining's binary_logloss: 0.0770947\tvalid_1's auc: 0.789626\tvalid_1's binary_logloss: 0.0977211\n",
      "[24]\ttraining's auc: 0.805821\ttraining's binary_logloss: 0.0769216\tvalid_1's auc: 0.789687\tvalid_1's binary_logloss: 0.0975427\n",
      "[25]\ttraining's auc: 0.806713\ttraining's binary_logloss: 0.0767715\tvalid_1's auc: 0.790581\tvalid_1's binary_logloss: 0.0973363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\ttraining's auc: 0.806634\ttraining's binary_logloss: 0.0766375\tvalid_1's auc: 0.790566\tvalid_1's binary_logloss: 0.0972061\n",
      "[27]\ttraining's auc: 0.806535\ttraining's binary_logloss: 0.0765064\tvalid_1's auc: 0.79047\tvalid_1's binary_logloss: 0.0970804\n",
      "[28]\ttraining's auc: 0.807531\ttraining's binary_logloss: 0.0764124\tvalid_1's auc: 0.791324\tvalid_1's binary_logloss: 0.0969867\n",
      "[29]\ttraining's auc: 0.80751\ttraining's binary_logloss: 0.0763011\tvalid_1's auc: 0.79131\tvalid_1's binary_logloss: 0.0968865\n",
      "[30]\ttraining's auc: 0.807677\ttraining's binary_logloss: 0.0761941\tvalid_1's auc: 0.791657\tvalid_1's binary_logloss: 0.0967636\n",
      "[31]\ttraining's auc: 0.808178\ttraining's binary_logloss: 0.0760931\tvalid_1's auc: 0.792211\tvalid_1's binary_logloss: 0.0966492\n",
      "[32]\ttraining's auc: 0.808237\ttraining's binary_logloss: 0.0760263\tvalid_1's auc: 0.791882\tvalid_1's binary_logloss: 0.0966079\n",
      "[33]\ttraining's auc: 0.808377\ttraining's binary_logloss: 0.0759377\tvalid_1's auc: 0.792189\tvalid_1's binary_logloss: 0.0965059\n",
      "[34]\ttraining's auc: 0.808753\ttraining's binary_logloss: 0.0758853\tvalid_1's auc: 0.792333\tvalid_1's binary_logloss: 0.096474\n",
      "[35]\ttraining's auc: 0.808806\ttraining's binary_logloss: 0.0758101\tvalid_1's auc: 0.79303\tvalid_1's binary_logloss: 0.096386\n",
      "[36]\ttraining's auc: 0.808827\ttraining's binary_logloss: 0.0757494\tvalid_1's auc: 0.79308\tvalid_1's binary_logloss: 0.096316\n",
      "[37]\ttraining's auc: 0.809183\ttraining's binary_logloss: 0.0756719\tvalid_1's auc: 0.793709\tvalid_1's binary_logloss: 0.0962386\n",
      "[38]\ttraining's auc: 0.809257\ttraining's binary_logloss: 0.0756061\tvalid_1's auc: 0.794152\tvalid_1's binary_logloss: 0.0961597\n",
      "[39]\ttraining's auc: 0.809687\ttraining's binary_logloss: 0.0755395\tvalid_1's auc: 0.795144\tvalid_1's binary_logloss: 0.0960838\n",
      "[40]\ttraining's auc: 0.810185\ttraining's binary_logloss: 0.0754849\tvalid_1's auc: 0.795615\tvalid_1's binary_logloss: 0.0960232\n",
      "[41]\ttraining's auc: 0.810688\ttraining's binary_logloss: 0.0754276\tvalid_1's auc: 0.795945\tvalid_1's binary_logloss: 0.0959741\n",
      "[42]\ttraining's auc: 0.810748\ttraining's binary_logloss: 0.0753825\tvalid_1's auc: 0.795922\tvalid_1's binary_logloss: 0.0959403\n",
      "[43]\ttraining's auc: 0.811063\ttraining's binary_logloss: 0.0753409\tvalid_1's auc: 0.796153\tvalid_1's binary_logloss: 0.0959146\n",
      "[44]\ttraining's auc: 0.811224\ttraining's binary_logloss: 0.0752957\tvalid_1's auc: 0.796235\tvalid_1's binary_logloss: 0.0958662\n",
      "[45]\ttraining's auc: 0.811098\ttraining's binary_logloss: 0.0752433\tvalid_1's auc: 0.79586\tvalid_1's binary_logloss: 0.0958438\n",
      "[46]\ttraining's auc: 0.811677\ttraining's binary_logloss: 0.0751984\tvalid_1's auc: 0.796908\tvalid_1's binary_logloss: 0.095804\n",
      "[47]\ttraining's auc: 0.812068\ttraining's binary_logloss: 0.0751517\tvalid_1's auc: 0.797222\tvalid_1's binary_logloss: 0.0957643\n",
      "[48]\ttraining's auc: 0.812068\ttraining's binary_logloss: 0.0751066\tvalid_1's auc: 0.797407\tvalid_1's binary_logloss: 0.0957303\n",
      "[49]\ttraining's auc: 0.812315\ttraining's binary_logloss: 0.0750742\tvalid_1's auc: 0.797742\tvalid_1's binary_logloss: 0.0957043\n",
      "[50]\ttraining's auc: 0.812193\ttraining's binary_logloss: 0.075035\tvalid_1's auc: 0.797805\tvalid_1's binary_logloss: 0.0956603\n",
      "[51]\ttraining's auc: 0.812398\ttraining's binary_logloss: 0.0750107\tvalid_1's auc: 0.79826\tvalid_1's binary_logloss: 0.0956265\n",
      "[52]\ttraining's auc: 0.812448\ttraining's binary_logloss: 0.0749867\tvalid_1's auc: 0.7984\tvalid_1's binary_logloss: 0.0956\n",
      "[53]\ttraining's auc: 0.812505\ttraining's binary_logloss: 0.0749668\tvalid_1's auc: 0.798497\tvalid_1's binary_logloss: 0.0955708\n",
      "[54]\ttraining's auc: 0.812613\ttraining's binary_logloss: 0.0749391\tvalid_1's auc: 0.798727\tvalid_1's binary_logloss: 0.0955301\n",
      "[55]\ttraining's auc: 0.812745\ttraining's binary_logloss: 0.0749106\tvalid_1's auc: 0.798982\tvalid_1's binary_logloss: 0.0954986\n",
      "[56]\ttraining's auc: 0.813099\ttraining's binary_logloss: 0.0748768\tvalid_1's auc: 0.799148\tvalid_1's binary_logloss: 0.0954647\n",
      "[57]\ttraining's auc: 0.81328\ttraining's binary_logloss: 0.0748458\tvalid_1's auc: 0.799214\tvalid_1's binary_logloss: 0.0954446\n",
      "[58]\ttraining's auc: 0.813451\ttraining's binary_logloss: 0.074818\tvalid_1's auc: 0.799341\tvalid_1's binary_logloss: 0.0954327\n",
      "[59]\ttraining's auc: 0.813605\ttraining's binary_logloss: 0.0747929\tvalid_1's auc: 0.799612\tvalid_1's binary_logloss: 0.0954051\n",
      "[60]\ttraining's auc: 0.813714\ttraining's binary_logloss: 0.0747701\tvalid_1's auc: 0.799803\tvalid_1's binary_logloss: 0.0953861\n",
      "[61]\ttraining's auc: 0.813634\ttraining's binary_logloss: 0.0747407\tvalid_1's auc: 0.799942\tvalid_1's binary_logloss: 0.095374\n",
      "[62]\ttraining's auc: 0.813535\ttraining's binary_logloss: 0.074717\tvalid_1's auc: 0.800097\tvalid_1's binary_logloss: 0.0953561\n",
      "[63]\ttraining's auc: 0.813521\ttraining's binary_logloss: 0.0746957\tvalid_1's auc: 0.800189\tvalid_1's binary_logloss: 0.0953438\n",
      "[64]\ttraining's auc: 0.813528\ttraining's binary_logloss: 0.0746753\tvalid_1's auc: 0.800102\tvalid_1's binary_logloss: 0.0953255\n",
      "[65]\ttraining's auc: 0.81357\ttraining's binary_logloss: 0.0746536\tvalid_1's auc: 0.800311\tvalid_1's binary_logloss: 0.0953072\n",
      "[66]\ttraining's auc: 0.81374\ttraining's binary_logloss: 0.0746377\tvalid_1's auc: 0.800546\tvalid_1's binary_logloss: 0.0952973\n",
      "[67]\ttraining's auc: 0.813874\ttraining's binary_logloss: 0.0746233\tvalid_1's auc: 0.800887\tvalid_1's binary_logloss: 0.095278\n",
      "[68]\ttraining's auc: 0.814143\ttraining's binary_logloss: 0.0746075\tvalid_1's auc: 0.801114\tvalid_1's binary_logloss: 0.0952652\n",
      "[69]\ttraining's auc: 0.814221\ttraining's binary_logloss: 0.0745928\tvalid_1's auc: 0.801133\tvalid_1's binary_logloss: 0.0952573\n",
      "[70]\ttraining's auc: 0.814284\ttraining's binary_logloss: 0.0745781\tvalid_1's auc: 0.801393\tvalid_1's binary_logloss: 0.095239\n",
      "[71]\ttraining's auc: 0.814368\ttraining's binary_logloss: 0.0745616\tvalid_1's auc: 0.801597\tvalid_1's binary_logloss: 0.0952229\n",
      "[72]\ttraining's auc: 0.814504\ttraining's binary_logloss: 0.0745431\tvalid_1's auc: 0.802012\tvalid_1's binary_logloss: 0.0952005\n",
      "[73]\ttraining's auc: 0.814563\ttraining's binary_logloss: 0.0745305\tvalid_1's auc: 0.801893\tvalid_1's binary_logloss: 0.0952057\n",
      "[74]\ttraining's auc: 0.814562\ttraining's binary_logloss: 0.074523\tvalid_1's auc: 0.802004\tvalid_1's binary_logloss: 0.0952063\n",
      "[75]\ttraining's auc: 0.814597\ttraining's binary_logloss: 0.074509\tvalid_1's auc: 0.80196\tvalid_1's binary_logloss: 0.0951936\n",
      "[76]\ttraining's auc: 0.814794\ttraining's binary_logloss: 0.0744949\tvalid_1's auc: 0.802097\tvalid_1's binary_logloss: 0.0951746\n",
      "[77]\ttraining's auc: 0.814982\ttraining's binary_logloss: 0.0744796\tvalid_1's auc: 0.802227\tvalid_1's binary_logloss: 0.0951714\n",
      "[78]\ttraining's auc: 0.815019\ttraining's binary_logloss: 0.0744618\tvalid_1's auc: 0.802245\tvalid_1's binary_logloss: 0.0951604\n",
      "[79]\ttraining's auc: 0.815101\ttraining's binary_logloss: 0.0744485\tvalid_1's auc: 0.802421\tvalid_1's binary_logloss: 0.0951487\n",
      "[80]\ttraining's auc: 0.815151\ttraining's binary_logloss: 0.0744375\tvalid_1's auc: 0.802459\tvalid_1's binary_logloss: 0.0951442\n",
      "[81]\ttraining's auc: 0.815267\ttraining's binary_logloss: 0.0744249\tvalid_1's auc: 0.802373\tvalid_1's binary_logloss: 0.0951374\n",
      "[82]\ttraining's auc: 0.815474\ttraining's binary_logloss: 0.0744142\tvalid_1's auc: 0.802474\tvalid_1's binary_logloss: 0.0951315\n",
      "[83]\ttraining's auc: 0.81549\ttraining's binary_logloss: 0.0744026\tvalid_1's auc: 0.802452\tvalid_1's binary_logloss: 0.0951299\n",
      "[84]\ttraining's auc: 0.815595\ttraining's binary_logloss: 0.0743925\tvalid_1's auc: 0.802392\tvalid_1's binary_logloss: 0.0951259\n",
      "[85]\ttraining's auc: 0.815746\ttraining's binary_logloss: 0.0743791\tvalid_1's auc: 0.802338\tvalid_1's binary_logloss: 0.0951217\n",
      "[86]\ttraining's auc: 0.815849\ttraining's binary_logloss: 0.0743631\tvalid_1's auc: 0.802344\tvalid_1's binary_logloss: 0.095118\n",
      "[87]\ttraining's auc: 0.815906\ttraining's binary_logloss: 0.0743547\tvalid_1's auc: 0.802452\tvalid_1's binary_logloss: 0.0951125\n",
      "[88]\ttraining's auc: 0.815987\ttraining's binary_logloss: 0.0743414\tvalid_1's auc: 0.80263\tvalid_1's binary_logloss: 0.0950959\n",
      "[89]\ttraining's auc: 0.816043\ttraining's binary_logloss: 0.0743305\tvalid_1's auc: 0.802659\tvalid_1's binary_logloss: 0.0950899\n",
      "[90]\ttraining's auc: 0.816042\ttraining's binary_logloss: 0.0743172\tvalid_1's auc: 0.802765\tvalid_1's binary_logloss: 0.0950777\n",
      "[91]\ttraining's auc: 0.816235\ttraining's binary_logloss: 0.0743045\tvalid_1's auc: 0.802469\tvalid_1's binary_logloss: 0.0950805\n",
      "[92]\ttraining's auc: 0.816398\ttraining's binary_logloss: 0.0742931\tvalid_1's auc: 0.802498\tvalid_1's binary_logloss: 0.0950739\n",
      "[93]\ttraining's auc: 0.816512\ttraining's binary_logloss: 0.0742855\tvalid_1's auc: 0.802584\tvalid_1's binary_logloss: 0.0950732\n",
      "[94]\ttraining's auc: 0.816609\ttraining's binary_logloss: 0.0742719\tvalid_1's auc: 0.802594\tvalid_1's binary_logloss: 0.0950556\n",
      "[95]\ttraining's auc: 0.816697\ttraining's binary_logloss: 0.0742655\tvalid_1's auc: 0.802682\tvalid_1's binary_logloss: 0.0950482\n",
      "[96]\ttraining's auc: 0.816718\ttraining's binary_logloss: 0.0742601\tvalid_1's auc: 0.802768\tvalid_1's binary_logloss: 0.0950436\n",
      "[97]\ttraining's auc: 0.816783\ttraining's binary_logloss: 0.0742516\tvalid_1's auc: 0.80278\tvalid_1's binary_logloss: 0.0950438\n",
      "[98]\ttraining's auc: 0.816798\ttraining's binary_logloss: 0.0742465\tvalid_1's auc: 0.802738\tvalid_1's binary_logloss: 0.0950419\n",
      "[99]\ttraining's auc: 0.816856\ttraining's binary_logloss: 0.0742133\tvalid_1's auc: 0.802645\tvalid_1's binary_logloss: 0.0950279\n",
      "[100]\ttraining's auc: 0.816887\ttraining's binary_logloss: 0.0742047\tvalid_1's auc: 0.802575\tvalid_1's binary_logloss: 0.0950374\n",
      "[101]\ttraining's auc: 0.816917\ttraining's binary_logloss: 0.0742003\tvalid_1's auc: 0.802561\tvalid_1's binary_logloss: 0.0950398\n",
      "[102]\ttraining's auc: 0.816939\ttraining's binary_logloss: 0.0741954\tvalid_1's auc: 0.802565\tvalid_1's binary_logloss: 0.0950353\n",
      "[103]\ttraining's auc: 0.816968\ttraining's binary_logloss: 0.074186\tvalid_1's auc: 0.802548\tvalid_1's binary_logloss: 0.0950288\n",
      "[104]\ttraining's auc: 0.816986\ttraining's binary_logloss: 0.0741787\tvalid_1's auc: 0.802492\tvalid_1's binary_logloss: 0.0950306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105]\ttraining's auc: 0.817076\ttraining's binary_logloss: 0.0741712\tvalid_1's auc: 0.802443\tvalid_1's binary_logloss: 0.0950379\n",
      "[106]\ttraining's auc: 0.8174\ttraining's binary_logloss: 0.0741545\tvalid_1's auc: 0.802431\tvalid_1's binary_logloss: 0.0950465\n",
      "[107]\ttraining's auc: 0.817488\ttraining's binary_logloss: 0.074146\tvalid_1's auc: 0.802481\tvalid_1's binary_logloss: 0.0950438\n",
      "[108]\ttraining's auc: 0.8176\ttraining's binary_logloss: 0.0741379\tvalid_1's auc: 0.802441\tvalid_1's binary_logloss: 0.0950526\n",
      "[109]\ttraining's auc: 0.817602\ttraining's binary_logloss: 0.0741324\tvalid_1's auc: 0.802397\tvalid_1's binary_logloss: 0.0950563\n",
      "[110]\ttraining's auc: 0.817592\ttraining's binary_logloss: 0.0741088\tvalid_1's auc: 0.802309\tvalid_1's binary_logloss: 0.0950496\n",
      "[111]\ttraining's auc: 0.817624\ttraining's binary_logloss: 0.0741037\tvalid_1's auc: 0.802315\tvalid_1's binary_logloss: 0.0950413\n",
      "[112]\ttraining's auc: 0.817633\ttraining's binary_logloss: 0.0740973\tvalid_1's auc: 0.802264\tvalid_1's binary_logloss: 0.0950462\n",
      "[113]\ttraining's auc: 0.817686\ttraining's binary_logloss: 0.0740862\tvalid_1's auc: 0.802315\tvalid_1's binary_logloss: 0.0950487\n",
      "[114]\ttraining's auc: 0.817811\ttraining's binary_logloss: 0.0740763\tvalid_1's auc: 0.802212\tvalid_1's binary_logloss: 0.0950592\n",
      "[115]\ttraining's auc: 0.817815\ttraining's binary_logloss: 0.0740722\tvalid_1's auc: 0.802149\tvalid_1's binary_logloss: 0.0950681\n",
      "[116]\ttraining's auc: 0.817916\ttraining's binary_logloss: 0.0740635\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.095063\n",
      "[117]\ttraining's auc: 0.817986\ttraining's binary_logloss: 0.0740543\tvalid_1's auc: 0.802053\tvalid_1's binary_logloss: 0.0950708\n",
      "[118]\ttraining's auc: 0.818105\ttraining's binary_logloss: 0.0740477\tvalid_1's auc: 0.80198\tvalid_1's binary_logloss: 0.0950694\n",
      "[119]\ttraining's auc: 0.81822\ttraining's binary_logloss: 0.0740386\tvalid_1's auc: 0.801948\tvalid_1's binary_logloss: 0.0950725\n",
      "[120]\ttraining's auc: 0.818257\ttraining's binary_logloss: 0.0740326\tvalid_1's auc: 0.801958\tvalid_1's binary_logloss: 0.0950768\n",
      "[121]\ttraining's auc: 0.818331\ttraining's binary_logloss: 0.0740275\tvalid_1's auc: 0.801952\tvalid_1's binary_logloss: 0.0950769\n",
      "[122]\ttraining's auc: 0.818439\ttraining's binary_logloss: 0.0740214\tvalid_1's auc: 0.801875\tvalid_1's binary_logloss: 0.0950907\n",
      "[123]\ttraining's auc: 0.818463\ttraining's binary_logloss: 0.0740155\tvalid_1's auc: 0.80186\tvalid_1's binary_logloss: 0.0950991\n",
      "[124]\ttraining's auc: 0.818456\ttraining's binary_logloss: 0.0739921\tvalid_1's auc: 0.801753\tvalid_1's binary_logloss: 0.095094\n",
      "[125]\ttraining's auc: 0.818562\ttraining's binary_logloss: 0.0739821\tvalid_1's auc: 0.801819\tvalid_1's binary_logloss: 0.0950942\n",
      "[126]\ttraining's auc: 0.818554\ttraining's binary_logloss: 0.0739783\tvalid_1's auc: 0.801738\tvalid_1's binary_logloss: 0.0951069\n",
      "[127]\ttraining's auc: 0.81862\ttraining's binary_logloss: 0.0739709\tvalid_1's auc: 0.801746\tvalid_1's binary_logloss: 0.0951167\n",
      "[128]\ttraining's auc: 0.818659\ttraining's binary_logloss: 0.0739662\tvalid_1's auc: 0.801785\tvalid_1's binary_logloss: 0.0951113\n",
      "[129]\ttraining's auc: 0.818665\ttraining's binary_logloss: 0.0739622\tvalid_1's auc: 0.801756\tvalid_1's binary_logloss: 0.095114\n",
      "[130]\ttraining's auc: 0.818764\ttraining's binary_logloss: 0.0739552\tvalid_1's auc: 0.801818\tvalid_1's binary_logloss: 0.0951088\n",
      "[131]\ttraining's auc: 0.818858\ttraining's binary_logloss: 0.0739478\tvalid_1's auc: 0.801971\tvalid_1's binary_logloss: 0.095105\n",
      "[132]\ttraining's auc: 0.818933\ttraining's binary_logloss: 0.0739425\tvalid_1's auc: 0.801928\tvalid_1's binary_logloss: 0.0951129\n",
      "[133]\ttraining's auc: 0.819071\ttraining's binary_logloss: 0.0739346\tvalid_1's auc: 0.801949\tvalid_1's binary_logloss: 0.0951196\n",
      "[134]\ttraining's auc: 0.819143\ttraining's binary_logloss: 0.0739299\tvalid_1's auc: 0.801949\tvalid_1's binary_logloss: 0.0951235\n",
      "[135]\ttraining's auc: 0.819234\ttraining's binary_logloss: 0.0739223\tvalid_1's auc: 0.801948\tvalid_1's binary_logloss: 0.0951184\n",
      "[136]\ttraining's auc: 0.819415\ttraining's binary_logloss: 0.0739095\tvalid_1's auc: 0.801855\tvalid_1's binary_logloss: 0.09513\n",
      "[137]\ttraining's auc: 0.819446\ttraining's binary_logloss: 0.0739031\tvalid_1's auc: 0.801825\tvalid_1's binary_logloss: 0.0951303\n",
      "[138]\ttraining's auc: 0.819461\ttraining's binary_logloss: 0.0738988\tvalid_1's auc: 0.801859\tvalid_1's binary_logloss: 0.0951259\n",
      "[139]\ttraining's auc: 0.819546\ttraining's binary_logloss: 0.0738929\tvalid_1's auc: 0.801914\tvalid_1's binary_logloss: 0.0951219\n",
      "[140]\ttraining's auc: 0.819603\ttraining's binary_logloss: 0.0738854\tvalid_1's auc: 0.801728\tvalid_1's binary_logloss: 0.0951282\n",
      "[141]\ttraining's auc: 0.81963\ttraining's binary_logloss: 0.0738669\tvalid_1's auc: 0.801777\tvalid_1's binary_logloss: 0.095107\n",
      "[142]\ttraining's auc: 0.819694\ttraining's binary_logloss: 0.0738615\tvalid_1's auc: 0.801859\tvalid_1's binary_logloss: 0.0951036\n",
      "[143]\ttraining's auc: 0.819721\ttraining's binary_logloss: 0.0738539\tvalid_1's auc: 0.801846\tvalid_1's binary_logloss: 0.0951049\n",
      "[144]\ttraining's auc: 0.81965\ttraining's binary_logloss: 0.0738476\tvalid_1's auc: 0.801824\tvalid_1's binary_logloss: 0.0951036\n",
      "[145]\ttraining's auc: 0.819702\ttraining's binary_logloss: 0.0738367\tvalid_1's auc: 0.802133\tvalid_1's binary_logloss: 0.0950777\n",
      "[146]\ttraining's auc: 0.819798\ttraining's binary_logloss: 0.0738278\tvalid_1's auc: 0.802184\tvalid_1's binary_logloss: 0.0950806\n",
      "[147]\ttraining's auc: 0.819812\ttraining's binary_logloss: 0.0738235\tvalid_1's auc: 0.802117\tvalid_1's binary_logloss: 0.0950776\n",
      "[148]\ttraining's auc: 0.819831\ttraining's binary_logloss: 0.0738202\tvalid_1's auc: 0.802007\tvalid_1's binary_logloss: 0.0950854\n",
      "[149]\ttraining's auc: 0.819869\ttraining's binary_logloss: 0.0738173\tvalid_1's auc: 0.802015\tvalid_1's binary_logloss: 0.0950882\n",
      "[150]\ttraining's auc: 0.819959\ttraining's binary_logloss: 0.0738134\tvalid_1's auc: 0.801975\tvalid_1's binary_logloss: 0.0950914\n",
      "[151]\ttraining's auc: 0.819973\ttraining's binary_logloss: 0.0737944\tvalid_1's auc: 0.801927\tvalid_1's binary_logloss: 0.0950848\n",
      "[152]\ttraining's auc: 0.819996\ttraining's binary_logloss: 0.0737901\tvalid_1's auc: 0.802021\tvalid_1's binary_logloss: 0.0950817\n",
      "[153]\ttraining's auc: 0.820003\ttraining's binary_logloss: 0.073786\tvalid_1's auc: 0.801963\tvalid_1's binary_logloss: 0.0950871\n",
      "[154]\ttraining's auc: 0.820087\ttraining's binary_logloss: 0.0737786\tvalid_1's auc: 0.801939\tvalid_1's binary_logloss: 0.0950857\n",
      "[155]\ttraining's auc: 0.820148\ttraining's binary_logloss: 0.0737745\tvalid_1's auc: 0.8019\tvalid_1's binary_logloss: 0.0950877\n",
      "[156]\ttraining's auc: 0.820152\ttraining's binary_logloss: 0.0737723\tvalid_1's auc: 0.801933\tvalid_1's binary_logloss: 0.0950913\n",
      "[157]\ttraining's auc: 0.820185\ttraining's binary_logloss: 0.0737671\tvalid_1's auc: 0.802059\tvalid_1's binary_logloss: 0.0950855\n",
      "[158]\ttraining's auc: 0.820196\ttraining's binary_logloss: 0.0737641\tvalid_1's auc: 0.802073\tvalid_1's binary_logloss: 0.0950863\n",
      "[159]\ttraining's auc: 0.820228\ttraining's binary_logloss: 0.0737492\tvalid_1's auc: 0.802143\tvalid_1's binary_logloss: 0.0950674\n",
      "[160]\ttraining's auc: 0.820263\ttraining's binary_logloss: 0.0737427\tvalid_1's auc: 0.802189\tvalid_1's binary_logloss: 0.0950583\n",
      "[161]\ttraining's auc: 0.820275\ttraining's binary_logloss: 0.0737374\tvalid_1's auc: 0.802206\tvalid_1's binary_logloss: 0.0950577\n",
      "[162]\ttraining's auc: 0.820287\ttraining's binary_logloss: 0.0737342\tvalid_1's auc: 0.802236\tvalid_1's binary_logloss: 0.0950503\n",
      "[163]\ttraining's auc: 0.820297\ttraining's binary_logloss: 0.0737319\tvalid_1's auc: 0.802259\tvalid_1's binary_logloss: 0.0950501\n",
      "[164]\ttraining's auc: 0.820325\ttraining's binary_logloss: 0.0737185\tvalid_1's auc: 0.802264\tvalid_1's binary_logloss: 0.0950552\n",
      "[165]\ttraining's auc: 0.820341\ttraining's binary_logloss: 0.0737166\tvalid_1's auc: 0.802289\tvalid_1's binary_logloss: 0.0950501\n",
      "[166]\ttraining's auc: 0.820339\ttraining's binary_logloss: 0.073715\tvalid_1's auc: 0.80236\tvalid_1's binary_logloss: 0.0950499\n",
      "[167]\ttraining's auc: 0.820397\ttraining's binary_logloss: 0.0737079\tvalid_1's auc: 0.802275\tvalid_1's binary_logloss: 0.0950522\n",
      "[168]\ttraining's auc: 0.820458\ttraining's binary_logloss: 0.0737033\tvalid_1's auc: 0.802365\tvalid_1's binary_logloss: 0.0950485\n",
      "[169]\ttraining's auc: 0.820497\ttraining's binary_logloss: 0.0736885\tvalid_1's auc: 0.802386\tvalid_1's binary_logloss: 0.0950428\n",
      "[170]\ttraining's auc: 0.820583\ttraining's binary_logloss: 0.0736822\tvalid_1's auc: 0.802275\tvalid_1's binary_logloss: 0.0950511\n",
      "[171]\ttraining's auc: 0.820591\ttraining's binary_logloss: 0.0736788\tvalid_1's auc: 0.802257\tvalid_1's binary_logloss: 0.0950523\n",
      "[172]\ttraining's auc: 0.82066\ttraining's binary_logloss: 0.0736723\tvalid_1's auc: 0.802133\tvalid_1's binary_logloss: 0.0950562\n",
      "[173]\ttraining's auc: 0.820724\ttraining's binary_logloss: 0.0736681\tvalid_1's auc: 0.802077\tvalid_1's binary_logloss: 0.0950592\n",
      "[174]\ttraining's auc: 0.820824\ttraining's binary_logloss: 0.07366\tvalid_1's auc: 0.802019\tvalid_1's binary_logloss: 0.0950626\n",
      "[175]\ttraining's auc: 0.82091\ttraining's binary_logloss: 0.0736522\tvalid_1's auc: 0.802096\tvalid_1's binary_logloss: 0.0950604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176]\ttraining's auc: 0.820943\ttraining's binary_logloss: 0.073649\tvalid_1's auc: 0.8022\tvalid_1's binary_logloss: 0.0950437\n",
      "[177]\ttraining's auc: 0.820964\ttraining's binary_logloss: 0.0736455\tvalid_1's auc: 0.802107\tvalid_1's binary_logloss: 0.0950517\n",
      "[178]\ttraining's auc: 0.82104\ttraining's binary_logloss: 0.0736381\tvalid_1's auc: 0.802185\tvalid_1's binary_logloss: 0.0950498\n",
      "[179]\ttraining's auc: 0.821046\ttraining's binary_logloss: 0.0736369\tvalid_1's auc: 0.802196\tvalid_1's binary_logloss: 0.095051\n",
      "[180]\ttraining's auc: 0.821092\ttraining's binary_logloss: 0.0736316\tvalid_1's auc: 0.802213\tvalid_1's binary_logloss: 0.0950498\n",
      "[181]\ttraining's auc: 0.821091\ttraining's binary_logloss: 0.0736285\tvalid_1's auc: 0.802195\tvalid_1's binary_logloss: 0.0950463\n",
      "[182]\ttraining's auc: 0.821173\ttraining's binary_logloss: 0.073623\tvalid_1's auc: 0.802054\tvalid_1's binary_logloss: 0.0950586\n",
      "[183]\ttraining's auc: 0.821276\ttraining's binary_logloss: 0.0736181\tvalid_1's auc: 0.802058\tvalid_1's binary_logloss: 0.0950551\n",
      "[184]\ttraining's auc: 0.821302\ttraining's binary_logloss: 0.0736146\tvalid_1's auc: 0.80196\tvalid_1's binary_logloss: 0.0950624\n",
      "[185]\ttraining's auc: 0.821323\ttraining's binary_logloss: 0.0736109\tvalid_1's auc: 0.802067\tvalid_1's binary_logloss: 0.0950555\n",
      "[186]\ttraining's auc: 0.82134\ttraining's binary_logloss: 0.0736078\tvalid_1's auc: 0.802099\tvalid_1's binary_logloss: 0.0950544\n",
      "[187]\ttraining's auc: 0.821335\ttraining's binary_logloss: 0.0736012\tvalid_1's auc: 0.802016\tvalid_1's binary_logloss: 0.0950511\n",
      "[188]\ttraining's auc: 0.821401\ttraining's binary_logloss: 0.0735963\tvalid_1's auc: 0.801984\tvalid_1's binary_logloss: 0.0950564\n",
      "[189]\ttraining's auc: 0.821433\ttraining's binary_logloss: 0.073592\tvalid_1's auc: 0.801796\tvalid_1's binary_logloss: 0.0950681\n",
      "[190]\ttraining's auc: 0.821438\ttraining's binary_logloss: 0.0735892\tvalid_1's auc: 0.801722\tvalid_1's binary_logloss: 0.0950749\n",
      "[191]\ttraining's auc: 0.821501\ttraining's binary_logloss: 0.0735838\tvalid_1's auc: 0.801653\tvalid_1's binary_logloss: 0.0950755\n",
      "[192]\ttraining's auc: 0.821515\ttraining's binary_logloss: 0.0735815\tvalid_1's auc: 0.80165\tvalid_1's binary_logloss: 0.0950761\n",
      "[193]\ttraining's auc: 0.82166\ttraining's binary_logloss: 0.0735721\tvalid_1's auc: 0.801594\tvalid_1's binary_logloss: 0.0950799\n",
      "[194]\ttraining's auc: 0.821713\ttraining's binary_logloss: 0.0735686\tvalid_1's auc: 0.801585\tvalid_1's binary_logloss: 0.0950764\n",
      "[195]\ttraining's auc: 0.821698\ttraining's binary_logloss: 0.0735666\tvalid_1's auc: 0.801527\tvalid_1's binary_logloss: 0.0950831\n",
      "[196]\ttraining's auc: 0.821752\ttraining's binary_logloss: 0.0735631\tvalid_1's auc: 0.801404\tvalid_1's binary_logloss: 0.0950923\n",
      "[197]\ttraining's auc: 0.821803\ttraining's binary_logloss: 0.0735478\tvalid_1's auc: 0.80142\tvalid_1's binary_logloss: 0.0950945\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's auc: 0.816783\ttraining's binary_logloss: 0.0742516\tvalid_1's auc: 0.80278\tvalid_1's binary_logloss: 0.0950438\n",
      "8\n",
      "[1]\ttraining's auc: 0.730347\ttraining's binary_logloss: 0.0973531\tvalid_1's auc: 0.746153\tvalid_1's binary_logloss: 0.0662543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.784643\ttraining's binary_logloss: 0.0959369\tvalid_1's auc: 0.790691\tvalid_1's binary_logloss: 0.0654012\n",
      "[3]\ttraining's auc: 0.789082\ttraining's binary_logloss: 0.0953758\tvalid_1's auc: 0.802344\tvalid_1's binary_logloss: 0.0649805\n",
      "[4]\ttraining's auc: 0.786326\ttraining's binary_logloss: 0.0948066\tvalid_1's auc: 0.799455\tvalid_1's binary_logloss: 0.0645839\n",
      "[5]\ttraining's auc: 0.791919\ttraining's binary_logloss: 0.0938076\tvalid_1's auc: 0.805947\tvalid_1's binary_logloss: 0.0638862\n",
      "[6]\ttraining's auc: 0.791494\ttraining's binary_logloss: 0.0930058\tvalid_1's auc: 0.804091\tvalid_1's binary_logloss: 0.0633804\n",
      "[7]\ttraining's auc: 0.792345\ttraining's binary_logloss: 0.0926092\tvalid_1's auc: 0.804251\tvalid_1's binary_logloss: 0.0630972\n",
      "[8]\ttraining's auc: 0.793064\ttraining's binary_logloss: 0.0919349\tvalid_1's auc: 0.80601\tvalid_1's binary_logloss: 0.0625998\n",
      "[9]\ttraining's auc: 0.794182\ttraining's binary_logloss: 0.0913051\tvalid_1's auc: 0.808126\tvalid_1's binary_logloss: 0.0621007\n",
      "[10]\ttraining's auc: 0.794928\ttraining's binary_logloss: 0.0910205\tvalid_1's auc: 0.80572\tvalid_1's binary_logloss: 0.0618922\n",
      "[11]\ttraining's auc: 0.79524\ttraining's binary_logloss: 0.090501\tvalid_1's auc: 0.80703\tvalid_1's binary_logloss: 0.0614723\n",
      "[12]\ttraining's auc: 0.79574\ttraining's binary_logloss: 0.0900586\tvalid_1's auc: 0.808318\tvalid_1's binary_logloss: 0.0611114\n",
      "[13]\ttraining's auc: 0.79546\ttraining's binary_logloss: 0.0898371\tvalid_1's auc: 0.806084\tvalid_1's binary_logloss: 0.0609427\n",
      "[14]\ttraining's auc: 0.795859\ttraining's binary_logloss: 0.0894495\tvalid_1's auc: 0.807249\tvalid_1's binary_logloss: 0.060596\n",
      "[15]\ttraining's auc: 0.796052\ttraining's binary_logloss: 0.0890783\tvalid_1's auc: 0.808929\tvalid_1's binary_logloss: 0.0602894\n",
      "[16]\ttraining's auc: 0.796931\ttraining's binary_logloss: 0.0887567\tvalid_1's auc: 0.809481\tvalid_1's binary_logloss: 0.0600169\n",
      "[17]\ttraining's auc: 0.797487\ttraining's binary_logloss: 0.0885409\tvalid_1's auc: 0.810306\tvalid_1's binary_logloss: 0.0598276\n",
      "[18]\ttraining's auc: 0.797386\ttraining's binary_logloss: 0.088272\tvalid_1's auc: 0.810957\tvalid_1's binary_logloss: 0.0595831\n",
      "[19]\ttraining's auc: 0.797783\ttraining's binary_logloss: 0.0880119\tvalid_1's auc: 0.811418\tvalid_1's binary_logloss: 0.0593429\n",
      "[20]\ttraining's auc: 0.799486\ttraining's binary_logloss: 0.0878218\tvalid_1's auc: 0.810457\tvalid_1's binary_logloss: 0.0591831\n",
      "[21]\ttraining's auc: 0.799557\ttraining's binary_logloss: 0.0876093\tvalid_1's auc: 0.810367\tvalid_1's binary_logloss: 0.0589851\n",
      "[22]\ttraining's auc: 0.800037\ttraining's binary_logloss: 0.0874158\tvalid_1's auc: 0.811402\tvalid_1's binary_logloss: 0.0587923\n",
      "[23]\ttraining's auc: 0.800854\ttraining's binary_logloss: 0.087263\tvalid_1's auc: 0.811054\tvalid_1's binary_logloss: 0.0586657\n",
      "[24]\ttraining's auc: 0.800888\ttraining's binary_logloss: 0.0870833\tvalid_1's auc: 0.811045\tvalid_1's binary_logloss: 0.0584966\n",
      "[25]\ttraining's auc: 0.801352\ttraining's binary_logloss: 0.0868993\tvalid_1's auc: 0.811509\tvalid_1's binary_logloss: 0.0583259\n",
      "[26]\ttraining's auc: 0.801304\ttraining's binary_logloss: 0.0867486\tvalid_1's auc: 0.811852\tvalid_1's binary_logloss: 0.0581731\n",
      "[27]\ttraining's auc: 0.801356\ttraining's binary_logloss: 0.0866195\tvalid_1's auc: 0.811964\tvalid_1's binary_logloss: 0.058046\n",
      "[28]\ttraining's auc: 0.802675\ttraining's binary_logloss: 0.0865259\tvalid_1's auc: 0.812162\tvalid_1's binary_logloss: 0.0579675\n",
      "[29]\ttraining's auc: 0.802572\ttraining's binary_logloss: 0.0864057\tvalid_1's auc: 0.812596\tvalid_1's binary_logloss: 0.0578267\n",
      "[30]\ttraining's auc: 0.802746\ttraining's binary_logloss: 0.0862843\tvalid_1's auc: 0.813263\tvalid_1's binary_logloss: 0.0576991\n",
      "[31]\ttraining's auc: 0.803172\ttraining's binary_logloss: 0.0861779\tvalid_1's auc: 0.813785\tvalid_1's binary_logloss: 0.0575856\n",
      "[32]\ttraining's auc: 0.80326\ttraining's binary_logloss: 0.0861033\tvalid_1's auc: 0.813827\tvalid_1's binary_logloss: 0.057515\n",
      "[33]\ttraining's auc: 0.803658\ttraining's binary_logloss: 0.0860037\tvalid_1's auc: 0.813718\tvalid_1's binary_logloss: 0.0574186\n",
      "[34]\ttraining's auc: 0.804209\ttraining's binary_logloss: 0.0859439\tvalid_1's auc: 0.813551\tvalid_1's binary_logloss: 0.0573574\n",
      "[35]\ttraining's auc: 0.804444\ttraining's binary_logloss: 0.0858615\tvalid_1's auc: 0.813784\tvalid_1's binary_logloss: 0.0572712\n",
      "[36]\ttraining's auc: 0.804486\ttraining's binary_logloss: 0.0857884\tvalid_1's auc: 0.813859\tvalid_1's binary_logloss: 0.0572145\n",
      "[37]\ttraining's auc: 0.804945\ttraining's binary_logloss: 0.0857096\tvalid_1's auc: 0.81533\tvalid_1's binary_logloss: 0.0571436\n",
      "[38]\ttraining's auc: 0.80507\ttraining's binary_logloss: 0.0856327\tvalid_1's auc: 0.814838\tvalid_1's binary_logloss: 0.0570514\n",
      "[39]\ttraining's auc: 0.805467\ttraining's binary_logloss: 0.0855602\tvalid_1's auc: 0.815411\tvalid_1's binary_logloss: 0.0569847\n",
      "[40]\ttraining's auc: 0.805484\ttraining's binary_logloss: 0.0855052\tvalid_1's auc: 0.814968\tvalid_1's binary_logloss: 0.0569331\n",
      "[41]\ttraining's auc: 0.805575\ttraining's binary_logloss: 0.085437\tvalid_1's auc: 0.814742\tvalid_1's binary_logloss: 0.0568484\n",
      "[42]\ttraining's auc: 0.805705\ttraining's binary_logloss: 0.0853839\tvalid_1's auc: 0.814734\tvalid_1's binary_logloss: 0.0567924\n",
      "[43]\ttraining's auc: 0.805655\ttraining's binary_logloss: 0.0853263\tvalid_1's auc: 0.814792\tvalid_1's binary_logloss: 0.0567316\n",
      "[44]\ttraining's auc: 0.805827\ttraining's binary_logloss: 0.0852791\tvalid_1's auc: 0.814882\tvalid_1's binary_logloss: 0.0566794\n",
      "[45]\ttraining's auc: 0.806062\ttraining's binary_logloss: 0.0852219\tvalid_1's auc: 0.815107\tvalid_1's binary_logloss: 0.0566252\n",
      "[46]\ttraining's auc: 0.805973\ttraining's binary_logloss: 0.0851788\tvalid_1's auc: 0.814832\tvalid_1's binary_logloss: 0.05658\n",
      "[47]\ttraining's auc: 0.8062\ttraining's binary_logloss: 0.0851374\tvalid_1's auc: 0.814829\tvalid_1's binary_logloss: 0.0565284\n",
      "[48]\ttraining's auc: 0.806433\ttraining's binary_logloss: 0.0850893\tvalid_1's auc: 0.81472\tvalid_1's binary_logloss: 0.0564771\n",
      "[49]\ttraining's auc: 0.806647\ttraining's binary_logloss: 0.0850431\tvalid_1's auc: 0.81491\tvalid_1's binary_logloss: 0.0564311\n",
      "[50]\ttraining's auc: 0.806568\ttraining's binary_logloss: 0.0850022\tvalid_1's auc: 0.814637\tvalid_1's binary_logloss: 0.0563811\n",
      "[51]\ttraining's auc: 0.806722\ttraining's binary_logloss: 0.084969\tvalid_1's auc: 0.814831\tvalid_1's binary_logloss: 0.0563503\n",
      "[52]\ttraining's auc: 0.806686\ttraining's binary_logloss: 0.0849264\tvalid_1's auc: 0.815347\tvalid_1's binary_logloss: 0.0563003\n",
      "[53]\ttraining's auc: 0.806864\ttraining's binary_logloss: 0.0849003\tvalid_1's auc: 0.815294\tvalid_1's binary_logloss: 0.0562744\n",
      "[54]\ttraining's auc: 0.807012\ttraining's binary_logloss: 0.0848644\tvalid_1's auc: 0.815161\tvalid_1's binary_logloss: 0.0562394\n",
      "[55]\ttraining's auc: 0.807071\ttraining's binary_logloss: 0.0848348\tvalid_1's auc: 0.815044\tvalid_1's binary_logloss: 0.0562107\n",
      "[56]\ttraining's auc: 0.807192\ttraining's binary_logloss: 0.0848079\tvalid_1's auc: 0.815161\tvalid_1's binary_logloss: 0.0561835\n",
      "[57]\ttraining's auc: 0.807266\ttraining's binary_logloss: 0.0847812\tvalid_1's auc: 0.815412\tvalid_1's binary_logloss: 0.0561607\n",
      "[58]\ttraining's auc: 0.807522\ttraining's binary_logloss: 0.0847539\tvalid_1's auc: 0.815017\tvalid_1's binary_logloss: 0.0561352\n",
      "[59]\ttraining's auc: 0.807756\ttraining's binary_logloss: 0.0847271\tvalid_1's auc: 0.815526\tvalid_1's binary_logloss: 0.0561127\n",
      "[60]\ttraining's auc: 0.807906\ttraining's binary_logloss: 0.0847052\tvalid_1's auc: 0.815651\tvalid_1's binary_logloss: 0.0560871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61]\ttraining's auc: 0.807908\ttraining's binary_logloss: 0.0846771\tvalid_1's auc: 0.81586\tvalid_1's binary_logloss: 0.0560598\n",
      "[62]\ttraining's auc: 0.807825\ttraining's binary_logloss: 0.0846535\tvalid_1's auc: 0.815716\tvalid_1's binary_logloss: 0.0560395\n",
      "[63]\ttraining's auc: 0.807979\ttraining's binary_logloss: 0.0846277\tvalid_1's auc: 0.815459\tvalid_1's binary_logloss: 0.0560157\n",
      "[64]\ttraining's auc: 0.808122\ttraining's binary_logloss: 0.084603\tvalid_1's auc: 0.815693\tvalid_1's binary_logloss: 0.0559968\n",
      "[65]\ttraining's auc: 0.808225\ttraining's binary_logloss: 0.084582\tvalid_1's auc: 0.815806\tvalid_1's binary_logloss: 0.0559781\n",
      "[66]\ttraining's auc: 0.80833\ttraining's binary_logloss: 0.0845667\tvalid_1's auc: 0.815883\tvalid_1's binary_logloss: 0.0559607\n",
      "[67]\ttraining's auc: 0.808585\ttraining's binary_logloss: 0.0845463\tvalid_1's auc: 0.815894\tvalid_1's binary_logloss: 0.0559384\n",
      "[68]\ttraining's auc: 0.808854\ttraining's binary_logloss: 0.0845274\tvalid_1's auc: 0.815614\tvalid_1's binary_logloss: 0.0559353\n",
      "[69]\ttraining's auc: 0.808877\ttraining's binary_logloss: 0.0845188\tvalid_1's auc: 0.815212\tvalid_1's binary_logloss: 0.0559384\n",
      "[70]\ttraining's auc: 0.808971\ttraining's binary_logloss: 0.0845027\tvalid_1's auc: 0.815137\tvalid_1's binary_logloss: 0.0559341\n",
      "[71]\ttraining's auc: 0.809045\ttraining's binary_logloss: 0.0844853\tvalid_1's auc: 0.815219\tvalid_1's binary_logloss: 0.055911\n",
      "[72]\ttraining's auc: 0.809042\ttraining's binary_logloss: 0.0844673\tvalid_1's auc: 0.815066\tvalid_1's binary_logloss: 0.0558948\n",
      "[73]\ttraining's auc: 0.809116\ttraining's binary_logloss: 0.0844553\tvalid_1's auc: 0.815337\tvalid_1's binary_logloss: 0.0558831\n",
      "[74]\ttraining's auc: 0.809289\ttraining's binary_logloss: 0.0844443\tvalid_1's auc: 0.815503\tvalid_1's binary_logloss: 0.0558681\n",
      "[75]\ttraining's auc: 0.809309\ttraining's binary_logloss: 0.0844295\tvalid_1's auc: 0.81553\tvalid_1's binary_logloss: 0.0558534\n",
      "[76]\ttraining's auc: 0.809421\ttraining's binary_logloss: 0.0844129\tvalid_1's auc: 0.815692\tvalid_1's binary_logloss: 0.0558498\n",
      "[77]\ttraining's auc: 0.809427\ttraining's binary_logloss: 0.0843957\tvalid_1's auc: 0.81563\tvalid_1's binary_logloss: 0.0558328\n",
      "[78]\ttraining's auc: 0.809453\ttraining's binary_logloss: 0.0843765\tvalid_1's auc: 0.815666\tvalid_1's binary_logloss: 0.0558153\n",
      "[79]\ttraining's auc: 0.809528\ttraining's binary_logloss: 0.0843643\tvalid_1's auc: 0.815543\tvalid_1's binary_logloss: 0.0558216\n",
      "[80]\ttraining's auc: 0.809577\ttraining's binary_logloss: 0.0843499\tvalid_1's auc: 0.81583\tvalid_1's binary_logloss: 0.0557993\n",
      "[81]\ttraining's auc: 0.809609\ttraining's binary_logloss: 0.0843394\tvalid_1's auc: 0.815952\tvalid_1's binary_logloss: 0.0557891\n",
      "[82]\ttraining's auc: 0.809766\ttraining's binary_logloss: 0.0843312\tvalid_1's auc: 0.815966\tvalid_1's binary_logloss: 0.0557922\n",
      "[83]\ttraining's auc: 0.809899\ttraining's binary_logloss: 0.0843101\tvalid_1's auc: 0.816123\tvalid_1's binary_logloss: 0.0557687\n",
      "[84]\ttraining's auc: 0.809947\ttraining's binary_logloss: 0.0843024\tvalid_1's auc: 0.816103\tvalid_1's binary_logloss: 0.0557681\n",
      "[85]\ttraining's auc: 0.810048\ttraining's binary_logloss: 0.0842881\tvalid_1's auc: 0.816454\tvalid_1's binary_logloss: 0.0557638\n",
      "[86]\ttraining's auc: 0.810162\ttraining's binary_logloss: 0.0842728\tvalid_1's auc: 0.816742\tvalid_1's binary_logloss: 0.0557547\n",
      "[87]\ttraining's auc: 0.810217\ttraining's binary_logloss: 0.0842661\tvalid_1's auc: 0.816622\tvalid_1's binary_logloss: 0.0557495\n",
      "[88]\ttraining's auc: 0.81029\ttraining's binary_logloss: 0.0842544\tvalid_1's auc: 0.816682\tvalid_1's binary_logloss: 0.0557426\n",
      "[89]\ttraining's auc: 0.810337\ttraining's binary_logloss: 0.0842415\tvalid_1's auc: 0.816768\tvalid_1's binary_logloss: 0.0557346\n",
      "[90]\ttraining's auc: 0.810397\ttraining's binary_logloss: 0.0842351\tvalid_1's auc: 0.816723\tvalid_1's binary_logloss: 0.0557292\n",
      "[91]\ttraining's auc: 0.810544\ttraining's binary_logloss: 0.0842254\tvalid_1's auc: 0.816725\tvalid_1's binary_logloss: 0.0557352\n",
      "[92]\ttraining's auc: 0.810626\ttraining's binary_logloss: 0.0842153\tvalid_1's auc: 0.816878\tvalid_1's binary_logloss: 0.0557199\n",
      "[93]\ttraining's auc: 0.810682\ttraining's binary_logloss: 0.084208\tvalid_1's auc: 0.817028\tvalid_1's binary_logloss: 0.0557043\n",
      "[94]\ttraining's auc: 0.810723\ttraining's binary_logloss: 0.0841944\tvalid_1's auc: 0.817029\tvalid_1's binary_logloss: 0.0557083\n",
      "[95]\ttraining's auc: 0.810891\ttraining's binary_logloss: 0.0841806\tvalid_1's auc: 0.816979\tvalid_1's binary_logloss: 0.0556996\n",
      "[96]\ttraining's auc: 0.810885\ttraining's binary_logloss: 0.0841726\tvalid_1's auc: 0.816964\tvalid_1's binary_logloss: 0.0556878\n",
      "[97]\ttraining's auc: 0.810904\ttraining's binary_logloss: 0.084164\tvalid_1's auc: 0.816987\tvalid_1's binary_logloss: 0.0556789\n",
      "[98]\ttraining's auc: 0.810969\ttraining's binary_logloss: 0.0841569\tvalid_1's auc: 0.816706\tvalid_1's binary_logloss: 0.0556799\n",
      "[99]\ttraining's auc: 0.811\ttraining's binary_logloss: 0.0841486\tvalid_1's auc: 0.816578\tvalid_1's binary_logloss: 0.0556796\n",
      "[100]\ttraining's auc: 0.811023\ttraining's binary_logloss: 0.0841396\tvalid_1's auc: 0.816573\tvalid_1's binary_logloss: 0.0556673\n",
      "[101]\ttraining's auc: 0.811082\ttraining's binary_logloss: 0.0841317\tvalid_1's auc: 0.816623\tvalid_1's binary_logloss: 0.0556678\n",
      "[102]\ttraining's auc: 0.811115\ttraining's binary_logloss: 0.0841233\tvalid_1's auc: 0.816463\tvalid_1's binary_logloss: 0.0556686\n",
      "[103]\ttraining's auc: 0.811129\ttraining's binary_logloss: 0.0841152\tvalid_1's auc: 0.816507\tvalid_1's binary_logloss: 0.0556573\n",
      "[104]\ttraining's auc: 0.811194\ttraining's binary_logloss: 0.0841038\tvalid_1's auc: 0.81628\tvalid_1's binary_logloss: 0.0556554\n",
      "[105]\ttraining's auc: 0.811221\ttraining's binary_logloss: 0.084099\tvalid_1's auc: 0.81619\tvalid_1's binary_logloss: 0.0556605\n",
      "[106]\ttraining's auc: 0.81131\ttraining's binary_logloss: 0.0840896\tvalid_1's auc: 0.816408\tvalid_1's binary_logloss: 0.055658\n",
      "[107]\ttraining's auc: 0.811319\ttraining's binary_logloss: 0.0840826\tvalid_1's auc: 0.816327\tvalid_1's binary_logloss: 0.0556523\n",
      "[108]\ttraining's auc: 0.811399\ttraining's binary_logloss: 0.084074\tvalid_1's auc: 0.816593\tvalid_1's binary_logloss: 0.0556376\n",
      "[109]\ttraining's auc: 0.811488\ttraining's binary_logloss: 0.0840642\tvalid_1's auc: 0.816672\tvalid_1's binary_logloss: 0.0556311\n",
      "[110]\ttraining's auc: 0.811508\ttraining's binary_logloss: 0.084041\tvalid_1's auc: 0.816725\tvalid_1's binary_logloss: 0.055597\n",
      "[111]\ttraining's auc: 0.811534\ttraining's binary_logloss: 0.0840348\tvalid_1's auc: 0.81679\tvalid_1's binary_logloss: 0.05559\n",
      "[112]\ttraining's auc: 0.811644\ttraining's binary_logloss: 0.0840235\tvalid_1's auc: 0.816695\tvalid_1's binary_logloss: 0.0555803\n",
      "[113]\ttraining's auc: 0.811697\ttraining's binary_logloss: 0.0840188\tvalid_1's auc: 0.816542\tvalid_1's binary_logloss: 0.0555778\n",
      "[114]\ttraining's auc: 0.811812\ttraining's binary_logloss: 0.0840102\tvalid_1's auc: 0.816632\tvalid_1's binary_logloss: 0.055572\n",
      "[115]\ttraining's auc: 0.811866\ttraining's binary_logloss: 0.0839881\tvalid_1's auc: 0.816756\tvalid_1's binary_logloss: 0.055542\n",
      "[116]\ttraining's auc: 0.811941\ttraining's binary_logloss: 0.083982\tvalid_1's auc: 0.816655\tvalid_1's binary_logloss: 0.0555348\n",
      "[117]\ttraining's auc: 0.811962\ttraining's binary_logloss: 0.0839769\tvalid_1's auc: 0.816731\tvalid_1's binary_logloss: 0.0555246\n",
      "[118]\ttraining's auc: 0.812033\ttraining's binary_logloss: 0.0839671\tvalid_1's auc: 0.816513\tvalid_1's binary_logloss: 0.055535\n",
      "[119]\ttraining's auc: 0.812134\ttraining's binary_logloss: 0.083958\tvalid_1's auc: 0.816675\tvalid_1's binary_logloss: 0.0555292\n",
      "[120]\ttraining's auc: 0.812188\ttraining's binary_logloss: 0.0839506\tvalid_1's auc: 0.816855\tvalid_1's binary_logloss: 0.0555269\n",
      "[121]\ttraining's auc: 0.812211\ttraining's binary_logloss: 0.0839447\tvalid_1's auc: 0.816766\tvalid_1's binary_logloss: 0.0555208\n",
      "[122]\ttraining's auc: 0.812209\ttraining's binary_logloss: 0.0839376\tvalid_1's auc: 0.816905\tvalid_1's binary_logloss: 0.0555092\n",
      "[123]\ttraining's auc: 0.812227\ttraining's binary_logloss: 0.083932\tvalid_1's auc: 0.816791\tvalid_1's binary_logloss: 0.0555082\n",
      "[124]\ttraining's auc: 0.812235\ttraining's binary_logloss: 0.0839212\tvalid_1's auc: 0.816807\tvalid_1's binary_logloss: 0.0554858\n",
      "[125]\ttraining's auc: 0.812324\ttraining's binary_logloss: 0.0839061\tvalid_1's auc: 0.816606\tvalid_1's binary_logloss: 0.0554898\n",
      "[126]\ttraining's auc: 0.812445\ttraining's binary_logloss: 0.0838952\tvalid_1's auc: 0.816601\tvalid_1's binary_logloss: 0.0554877\n",
      "[127]\ttraining's auc: 0.812448\ttraining's binary_logloss: 0.0838909\tvalid_1's auc: 0.816622\tvalid_1's binary_logloss: 0.0554798\n",
      "[128]\ttraining's auc: 0.812476\ttraining's binary_logloss: 0.0838855\tvalid_1's auc: 0.816441\tvalid_1's binary_logloss: 0.0554872\n",
      "[129]\ttraining's auc: 0.812541\ttraining's binary_logloss: 0.0838795\tvalid_1's auc: 0.816417\tvalid_1's binary_logloss: 0.0554909\n",
      "[130]\ttraining's auc: 0.812635\ttraining's binary_logloss: 0.0838719\tvalid_1's auc: 0.81634\tvalid_1's binary_logloss: 0.0554934\n",
      "[131]\ttraining's auc: 0.812699\ttraining's binary_logloss: 0.0838656\tvalid_1's auc: 0.816408\tvalid_1's binary_logloss: 0.055488\n",
      "[132]\ttraining's auc: 0.81284\ttraining's binary_logloss: 0.0838555\tvalid_1's auc: 0.816359\tvalid_1's binary_logloss: 0.0554943\n",
      "[133]\ttraining's auc: 0.812861\ttraining's binary_logloss: 0.0838504\tvalid_1's auc: 0.816246\tvalid_1's binary_logloss: 0.0554984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[134]\ttraining's auc: 0.812865\ttraining's binary_logloss: 0.0838465\tvalid_1's auc: 0.816282\tvalid_1's binary_logloss: 0.0554834\n",
      "[135]\ttraining's auc: 0.812863\ttraining's binary_logloss: 0.0838421\tvalid_1's auc: 0.816134\tvalid_1's binary_logloss: 0.0554914\n",
      "[136]\ttraining's auc: 0.812889\ttraining's binary_logloss: 0.0838366\tvalid_1's auc: 0.816153\tvalid_1's binary_logloss: 0.0554912\n",
      "[137]\ttraining's auc: 0.812918\ttraining's binary_logloss: 0.0838319\tvalid_1's auc: 0.816121\tvalid_1's binary_logloss: 0.0554858\n",
      "[138]\ttraining's auc: 0.813006\ttraining's binary_logloss: 0.0838246\tvalid_1's auc: 0.815959\tvalid_1's binary_logloss: 0.0554931\n",
      "[139]\ttraining's auc: 0.813071\ttraining's binary_logloss: 0.0838158\tvalid_1's auc: 0.815998\tvalid_1's binary_logloss: 0.0554945\n",
      "[140]\ttraining's auc: 0.813133\ttraining's binary_logloss: 0.0838078\tvalid_1's auc: 0.815881\tvalid_1's binary_logloss: 0.0554977\n",
      "[141]\ttraining's auc: 0.813199\ttraining's binary_logloss: 0.083801\tvalid_1's auc: 0.815823\tvalid_1's binary_logloss: 0.0555011\n",
      "[142]\ttraining's auc: 0.813305\ttraining's binary_logloss: 0.0837922\tvalid_1's auc: 0.815685\tvalid_1's binary_logloss: 0.055499\n",
      "[143]\ttraining's auc: 0.813375\ttraining's binary_logloss: 0.0837872\tvalid_1's auc: 0.815654\tvalid_1's binary_logloss: 0.0555044\n",
      "[144]\ttraining's auc: 0.813392\ttraining's binary_logloss: 0.0837827\tvalid_1's auc: 0.815709\tvalid_1's binary_logloss: 0.0554975\n",
      "[145]\ttraining's auc: 0.813393\ttraining's binary_logloss: 0.083773\tvalid_1's auc: 0.815679\tvalid_1's binary_logloss: 0.0554819\n",
      "[146]\ttraining's auc: 0.813453\ttraining's binary_logloss: 0.0837654\tvalid_1's auc: 0.815367\tvalid_1's binary_logloss: 0.0554899\n",
      "[147]\ttraining's auc: 0.813504\ttraining's binary_logloss: 0.0837601\tvalid_1's auc: 0.815288\tvalid_1's binary_logloss: 0.0554886\n",
      "[148]\ttraining's auc: 0.813553\ttraining's binary_logloss: 0.083753\tvalid_1's auc: 0.815414\tvalid_1's binary_logloss: 0.0554872\n",
      "[149]\ttraining's auc: 0.813599\ttraining's binary_logloss: 0.0837481\tvalid_1's auc: 0.815351\tvalid_1's binary_logloss: 0.0554927\n",
      "[150]\ttraining's auc: 0.813616\ttraining's binary_logloss: 0.0837454\tvalid_1's auc: 0.815323\tvalid_1's binary_logloss: 0.0554984\n",
      "[151]\ttraining's auc: 0.813628\ttraining's binary_logloss: 0.0837397\tvalid_1's auc: 0.815408\tvalid_1's binary_logloss: 0.0554824\n",
      "[152]\ttraining's auc: 0.813704\ttraining's binary_logloss: 0.0837332\tvalid_1's auc: 0.815281\tvalid_1's binary_logloss: 0.0554865\n",
      "[153]\ttraining's auc: 0.813714\ttraining's binary_logloss: 0.0837292\tvalid_1's auc: 0.815339\tvalid_1's binary_logloss: 0.0554811\n",
      "[154]\ttraining's auc: 0.813726\ttraining's binary_logloss: 0.0837261\tvalid_1's auc: 0.81528\tvalid_1's binary_logloss: 0.0554864\n",
      "[155]\ttraining's auc: 0.813776\ttraining's binary_logloss: 0.0837209\tvalid_1's auc: 0.815182\tvalid_1's binary_logloss: 0.0554883\n",
      "[156]\ttraining's auc: 0.81378\ttraining's binary_logloss: 0.0837193\tvalid_1's auc: 0.815228\tvalid_1's binary_logloss: 0.0554887\n",
      "[157]\ttraining's auc: 0.81383\ttraining's binary_logloss: 0.0837121\tvalid_1's auc: 0.81528\tvalid_1's binary_logloss: 0.0554903\n",
      "[158]\ttraining's auc: 0.813835\ttraining's binary_logloss: 0.0837096\tvalid_1's auc: 0.815256\tvalid_1's binary_logloss: 0.0554954\n",
      "[159]\ttraining's auc: 0.813875\ttraining's binary_logloss: 0.0836899\tvalid_1's auc: 0.815323\tvalid_1's binary_logloss: 0.0554826\n",
      "[160]\ttraining's auc: 0.81393\ttraining's binary_logloss: 0.0836853\tvalid_1's auc: 0.815383\tvalid_1's binary_logloss: 0.0554774\n",
      "[161]\ttraining's auc: 0.813957\ttraining's binary_logloss: 0.0836789\tvalid_1's auc: 0.815375\tvalid_1's binary_logloss: 0.0554705\n",
      "[162]\ttraining's auc: 0.813994\ttraining's binary_logloss: 0.083666\tvalid_1's auc: 0.815531\tvalid_1's binary_logloss: 0.0554527\n",
      "[163]\ttraining's auc: 0.814058\ttraining's binary_logloss: 0.0836602\tvalid_1's auc: 0.815676\tvalid_1's binary_logloss: 0.0554442\n",
      "[164]\ttraining's auc: 0.814085\ttraining's binary_logloss: 0.0836569\tvalid_1's auc: 0.815799\tvalid_1's binary_logloss: 0.0554305\n",
      "[165]\ttraining's auc: 0.814116\ttraining's binary_logloss: 0.083654\tvalid_1's auc: 0.815778\tvalid_1's binary_logloss: 0.0554323\n",
      "[166]\ttraining's auc: 0.814124\ttraining's binary_logloss: 0.083651\tvalid_1's auc: 0.815747\tvalid_1's binary_logloss: 0.0554311\n",
      "[167]\ttraining's auc: 0.814138\ttraining's binary_logloss: 0.0836481\tvalid_1's auc: 0.815762\tvalid_1's binary_logloss: 0.0554241\n",
      "[168]\ttraining's auc: 0.814148\ttraining's binary_logloss: 0.0836438\tvalid_1's auc: 0.815754\tvalid_1's binary_logloss: 0.0554241\n",
      "[169]\ttraining's auc: 0.814178\ttraining's binary_logloss: 0.0836298\tvalid_1's auc: 0.815786\tvalid_1's binary_logloss: 0.0554117\n",
      "[170]\ttraining's auc: 0.814206\ttraining's binary_logloss: 0.0836258\tvalid_1's auc: 0.815884\tvalid_1's binary_logloss: 0.0554081\n",
      "[171]\ttraining's auc: 0.814216\ttraining's binary_logloss: 0.0836227\tvalid_1's auc: 0.815941\tvalid_1's binary_logloss: 0.055397\n",
      "[172]\ttraining's auc: 0.814237\ttraining's binary_logloss: 0.0836109\tvalid_1's auc: 0.815898\tvalid_1's binary_logloss: 0.0553878\n",
      "[173]\ttraining's auc: 0.814302\ttraining's binary_logloss: 0.0836048\tvalid_1's auc: 0.815716\tvalid_1's binary_logloss: 0.0554021\n",
      "[174]\ttraining's auc: 0.814368\ttraining's binary_logloss: 0.0835975\tvalid_1's auc: 0.815631\tvalid_1's binary_logloss: 0.0554097\n",
      "[175]\ttraining's auc: 0.814403\ttraining's binary_logloss: 0.083593\tvalid_1's auc: 0.815677\tvalid_1's binary_logloss: 0.05541\n",
      "[176]\ttraining's auc: 0.814425\ttraining's binary_logloss: 0.083589\tvalid_1's auc: 0.815744\tvalid_1's binary_logloss: 0.055407\n",
      "[177]\ttraining's auc: 0.814426\ttraining's binary_logloss: 0.0835857\tvalid_1's auc: 0.81576\tvalid_1's binary_logloss: 0.0554079\n",
      "[178]\ttraining's auc: 0.814497\ttraining's binary_logloss: 0.0835804\tvalid_1's auc: 0.815944\tvalid_1's binary_logloss: 0.0554055\n",
      "[179]\ttraining's auc: 0.814534\ttraining's binary_logloss: 0.0835758\tvalid_1's auc: 0.815994\tvalid_1's binary_logloss: 0.0554021\n",
      "[180]\ttraining's auc: 0.814579\ttraining's binary_logloss: 0.0835695\tvalid_1's auc: 0.816067\tvalid_1's binary_logloss: 0.0554038\n",
      "[181]\ttraining's auc: 0.81461\ttraining's binary_logloss: 0.0835651\tvalid_1's auc: 0.816039\tvalid_1's binary_logloss: 0.0554052\n",
      "[182]\ttraining's auc: 0.814604\ttraining's binary_logloss: 0.0835579\tvalid_1's auc: 0.815678\tvalid_1's binary_logloss: 0.0554098\n",
      "[183]\ttraining's auc: 0.814646\ttraining's binary_logloss: 0.0835537\tvalid_1's auc: 0.815526\tvalid_1's binary_logloss: 0.0554199\n",
      "[184]\ttraining's auc: 0.814668\ttraining's binary_logloss: 0.0835495\tvalid_1's auc: 0.815537\tvalid_1's binary_logloss: 0.0554238\n",
      "[185]\ttraining's auc: 0.814693\ttraining's binary_logloss: 0.0835455\tvalid_1's auc: 0.815463\tvalid_1's binary_logloss: 0.0554272\n",
      "[186]\ttraining's auc: 0.814727\ttraining's binary_logloss: 0.083542\tvalid_1's auc: 0.815518\tvalid_1's binary_logloss: 0.0554214\n",
      "[187]\ttraining's auc: 0.814759\ttraining's binary_logloss: 0.0835357\tvalid_1's auc: 0.815634\tvalid_1's binary_logloss: 0.0554154\n",
      "[188]\ttraining's auc: 0.814815\ttraining's binary_logloss: 0.0835318\tvalid_1's auc: 0.815721\tvalid_1's binary_logloss: 0.0554208\n",
      "[189]\ttraining's auc: 0.81481\ttraining's binary_logloss: 0.0835295\tvalid_1's auc: 0.815711\tvalid_1's binary_logloss: 0.055416\n",
      "[190]\ttraining's auc: 0.81487\ttraining's binary_logloss: 0.0835239\tvalid_1's auc: 0.815835\tvalid_1's binary_logloss: 0.0554041\n",
      "[191]\ttraining's auc: 0.814906\ttraining's binary_logloss: 0.0835216\tvalid_1's auc: 0.815789\tvalid_1's binary_logloss: 0.0554069\n",
      "[192]\ttraining's auc: 0.814962\ttraining's binary_logloss: 0.083518\tvalid_1's auc: 0.815633\tvalid_1's binary_logloss: 0.055411\n",
      "[193]\ttraining's auc: 0.81498\ttraining's binary_logloss: 0.0835152\tvalid_1's auc: 0.815639\tvalid_1's binary_logloss: 0.0554061\n",
      "[194]\ttraining's auc: 0.814999\ttraining's binary_logloss: 0.083511\tvalid_1's auc: 0.815608\tvalid_1's binary_logloss: 0.0554075\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's auc: 0.810723\ttraining's binary_logloss: 0.0841944\tvalid_1's auc: 0.817029\tvalid_1's binary_logloss: 0.0557083\n",
      "8\n",
      "[1]\ttraining's auc: 0.730749\ttraining's binary_logloss: 0.0961633\tvalid_1's auc: 0.742913\tvalid_1's binary_logloss: 0.0709548\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.784028\ttraining's binary_logloss: 0.0947491\tvalid_1's auc: 0.797433\tvalid_1's binary_logloss: 0.0699955\n",
      "[3]\ttraining's auc: 0.788859\ttraining's binary_logloss: 0.0942243\tvalid_1's auc: 0.804463\tvalid_1's binary_logloss: 0.0695991\n",
      "[4]\ttraining's auc: 0.788094\ttraining's binary_logloss: 0.0936544\tvalid_1's auc: 0.800355\tvalid_1's binary_logloss: 0.069149\n",
      "[5]\ttraining's auc: 0.793122\ttraining's binary_logloss: 0.0926345\tvalid_1's auc: 0.803236\tvalid_1's binary_logloss: 0.068461\n",
      "[6]\ttraining's auc: 0.794215\ttraining's binary_logloss: 0.0917177\tvalid_1's auc: 0.80357\tvalid_1's binary_logloss: 0.0678381\n",
      "[7]\ttraining's auc: 0.794273\ttraining's binary_logloss: 0.0913001\tvalid_1's auc: 0.802532\tvalid_1's binary_logloss: 0.0674945\n",
      "[8]\ttraining's auc: 0.794774\ttraining's binary_logloss: 0.0906156\tvalid_1's auc: 0.802836\tvalid_1's binary_logloss: 0.0670167\n",
      "[9]\ttraining's auc: 0.795662\ttraining's binary_logloss: 0.0899819\tvalid_1's auc: 0.803685\tvalid_1's binary_logloss: 0.0665586\n",
      "[10]\ttraining's auc: 0.796146\ttraining's binary_logloss: 0.0897168\tvalid_1's auc: 0.805366\tvalid_1's binary_logloss: 0.0663114\n",
      "[11]\ttraining's auc: 0.796625\ttraining's binary_logloss: 0.0892145\tvalid_1's auc: 0.807456\tvalid_1's binary_logloss: 0.0659167\n",
      "[12]\ttraining's auc: 0.79694\ttraining's binary_logloss: 0.0887677\tvalid_1's auc: 0.809563\tvalid_1's binary_logloss: 0.0655383\n",
      "[13]\ttraining's auc: 0.796783\ttraining's binary_logloss: 0.0885507\tvalid_1's auc: 0.809199\tvalid_1's binary_logloss: 0.0653411\n",
      "[14]\ttraining's auc: 0.796407\ttraining's binary_logloss: 0.0881473\tvalid_1's auc: 0.808661\tvalid_1's binary_logloss: 0.0650116\n",
      "[15]\ttraining's auc: 0.797193\ttraining's binary_logloss: 0.0877834\tvalid_1's auc: 0.80988\tvalid_1's binary_logloss: 0.0647292\n",
      "[16]\ttraining's auc: 0.79679\ttraining's binary_logloss: 0.0874629\tvalid_1's auc: 0.809688\tvalid_1's binary_logloss: 0.0644529\n",
      "[17]\ttraining's auc: 0.798097\ttraining's binary_logloss: 0.0872538\tvalid_1's auc: 0.810618\tvalid_1's binary_logloss: 0.0642563\n",
      "[18]\ttraining's auc: 0.798006\ttraining's binary_logloss: 0.0869944\tvalid_1's auc: 0.810322\tvalid_1's binary_logloss: 0.0640333\n",
      "[19]\ttraining's auc: 0.799009\ttraining's binary_logloss: 0.0867339\tvalid_1's auc: 0.812054\tvalid_1's binary_logloss: 0.0637932\n",
      "[20]\ttraining's auc: 0.799827\ttraining's binary_logloss: 0.0865587\tvalid_1's auc: 0.813022\tvalid_1's binary_logloss: 0.063626\n",
      "[21]\ttraining's auc: 0.799805\ttraining's binary_logloss: 0.086356\tvalid_1's auc: 0.813127\tvalid_1's binary_logloss: 0.0634464\n",
      "[22]\ttraining's auc: 0.800228\ttraining's binary_logloss: 0.0861655\tvalid_1's auc: 0.813698\tvalid_1's binary_logloss: 0.0632564\n",
      "[23]\ttraining's auc: 0.800426\ttraining's binary_logloss: 0.0860253\tvalid_1's auc: 0.81439\tvalid_1's binary_logloss: 0.0631232\n",
      "[24]\ttraining's auc: 0.800352\ttraining's binary_logloss: 0.0858502\tvalid_1's auc: 0.814154\tvalid_1's binary_logloss: 0.0629754\n",
      "[25]\ttraining's auc: 0.800805\ttraining's binary_logloss: 0.0856703\tvalid_1's auc: 0.81578\tvalid_1's binary_logloss: 0.0628145\n",
      "[26]\ttraining's auc: 0.800391\ttraining's binary_logloss: 0.0855272\tvalid_1's auc: 0.814905\tvalid_1's binary_logloss: 0.0626772\n",
      "[27]\ttraining's auc: 0.800352\ttraining's binary_logloss: 0.0854034\tvalid_1's auc: 0.814819\tvalid_1's binary_logloss: 0.0625652\n",
      "[28]\ttraining's auc: 0.801818\ttraining's binary_logloss: 0.0853141\tvalid_1's auc: 0.815369\tvalid_1's binary_logloss: 0.0624889\n",
      "[29]\ttraining's auc: 0.801923\ttraining's binary_logloss: 0.0851895\tvalid_1's auc: 0.816079\tvalid_1's binary_logloss: 0.0623599\n",
      "[30]\ttraining's auc: 0.802866\ttraining's binary_logloss: 0.0850684\tvalid_1's auc: 0.818307\tvalid_1's binary_logloss: 0.0622376\n",
      "[31]\ttraining's auc: 0.80303\ttraining's binary_logloss: 0.0849616\tvalid_1's auc: 0.817998\tvalid_1's binary_logloss: 0.0621342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32]\ttraining's auc: 0.8032\ttraining's binary_logloss: 0.0848904\tvalid_1's auc: 0.818715\tvalid_1's binary_logloss: 0.062045\n",
      "[33]\ttraining's auc: 0.803554\ttraining's binary_logloss: 0.084791\tvalid_1's auc: 0.818353\tvalid_1's binary_logloss: 0.0619613\n",
      "[34]\ttraining's auc: 0.803704\ttraining's binary_logloss: 0.0847369\tvalid_1's auc: 0.818047\tvalid_1's binary_logloss: 0.06189\n",
      "[35]\ttraining's auc: 0.804011\ttraining's binary_logloss: 0.0846602\tvalid_1's auc: 0.81893\tvalid_1's binary_logloss: 0.061801\n",
      "[36]\ttraining's auc: 0.80415\ttraining's binary_logloss: 0.084594\tvalid_1's auc: 0.819485\tvalid_1's binary_logloss: 0.0617198\n",
      "[37]\ttraining's auc: 0.804479\ttraining's binary_logloss: 0.0845205\tvalid_1's auc: 0.819578\tvalid_1's binary_logloss: 0.0616303\n",
      "[38]\ttraining's auc: 0.804591\ttraining's binary_logloss: 0.0844439\tvalid_1's auc: 0.819611\tvalid_1's binary_logloss: 0.061551\n",
      "[39]\ttraining's auc: 0.804917\ttraining's binary_logloss: 0.0843732\tvalid_1's auc: 0.81937\tvalid_1's binary_logloss: 0.0614767\n",
      "[40]\ttraining's auc: 0.805168\ttraining's binary_logloss: 0.084307\tvalid_1's auc: 0.81904\tvalid_1's binary_logloss: 0.0614045\n",
      "[41]\ttraining's auc: 0.805101\ttraining's binary_logloss: 0.0842394\tvalid_1's auc: 0.819597\tvalid_1's binary_logloss: 0.0613289\n",
      "[42]\ttraining's auc: 0.805366\ttraining's binary_logloss: 0.0841893\tvalid_1's auc: 0.819161\tvalid_1's binary_logloss: 0.0612731\n",
      "[43]\ttraining's auc: 0.805585\ttraining's binary_logloss: 0.0841439\tvalid_1's auc: 0.819247\tvalid_1's binary_logloss: 0.0612279\n",
      "[44]\ttraining's auc: 0.805655\ttraining's binary_logloss: 0.0841003\tvalid_1's auc: 0.81963\tvalid_1's binary_logloss: 0.0611558\n",
      "[45]\ttraining's auc: 0.805859\ttraining's binary_logloss: 0.0840439\tvalid_1's auc: 0.819395\tvalid_1's binary_logloss: 0.0611003\n",
      "[46]\ttraining's auc: 0.806262\ttraining's binary_logloss: 0.0839955\tvalid_1's auc: 0.820188\tvalid_1's binary_logloss: 0.0610605\n",
      "[47]\ttraining's auc: 0.806468\ttraining's binary_logloss: 0.0839516\tvalid_1's auc: 0.82017\tvalid_1's binary_logloss: 0.061004\n",
      "[48]\ttraining's auc: 0.8067\ttraining's binary_logloss: 0.0839061\tvalid_1's auc: 0.820392\tvalid_1's binary_logloss: 0.0609647\n",
      "[49]\ttraining's auc: 0.806929\ttraining's binary_logloss: 0.0838587\tvalid_1's auc: 0.820826\tvalid_1's binary_logloss: 0.0609038\n",
      "[50]\ttraining's auc: 0.807089\ttraining's binary_logloss: 0.0838216\tvalid_1's auc: 0.820821\tvalid_1's binary_logloss: 0.0608608\n",
      "[51]\ttraining's auc: 0.807181\ttraining's binary_logloss: 0.0837891\tvalid_1's auc: 0.821273\tvalid_1's binary_logloss: 0.0608166\n",
      "[52]\ttraining's auc: 0.807257\ttraining's binary_logloss: 0.0837462\tvalid_1's auc: 0.821287\tvalid_1's binary_logloss: 0.0607748\n",
      "[53]\ttraining's auc: 0.807363\ttraining's binary_logloss: 0.0837182\tvalid_1's auc: 0.821665\tvalid_1's binary_logloss: 0.0607496\n",
      "[54]\ttraining's auc: 0.80749\ttraining's binary_logloss: 0.0836762\tvalid_1's auc: 0.821429\tvalid_1's binary_logloss: 0.060718\n",
      "[55]\ttraining's auc: 0.807735\ttraining's binary_logloss: 0.0836466\tvalid_1's auc: 0.821384\tvalid_1's binary_logloss: 0.0606832\n",
      "[56]\ttraining's auc: 0.807724\ttraining's binary_logloss: 0.0836164\tvalid_1's auc: 0.820822\tvalid_1's binary_logloss: 0.0606668\n",
      "[57]\ttraining's auc: 0.807636\ttraining's binary_logloss: 0.0835872\tvalid_1's auc: 0.820919\tvalid_1's binary_logloss: 0.0606504\n",
      "[58]\ttraining's auc: 0.80759\ttraining's binary_logloss: 0.08356\tvalid_1's auc: 0.821101\tvalid_1's binary_logloss: 0.0606177\n",
      "[59]\ttraining's auc: 0.80776\ttraining's binary_logloss: 0.0835347\tvalid_1's auc: 0.821095\tvalid_1's binary_logloss: 0.0606016\n",
      "[60]\ttraining's auc: 0.807931\ttraining's binary_logloss: 0.0835121\tvalid_1's auc: 0.821164\tvalid_1's binary_logloss: 0.0605791\n",
      "[61]\ttraining's auc: 0.808173\ttraining's binary_logloss: 0.0834877\tvalid_1's auc: 0.821144\tvalid_1's binary_logloss: 0.0605648\n",
      "[62]\ttraining's auc: 0.808135\ttraining's binary_logloss: 0.0834663\tvalid_1's auc: 0.82103\tvalid_1's binary_logloss: 0.0605446\n",
      "[63]\ttraining's auc: 0.808258\ttraining's binary_logloss: 0.0834457\tvalid_1's auc: 0.820971\tvalid_1's binary_logloss: 0.0605161\n",
      "[64]\ttraining's auc: 0.808281\ttraining's binary_logloss: 0.0834215\tvalid_1's auc: 0.820993\tvalid_1's binary_logloss: 0.0604997\n",
      "[65]\ttraining's auc: 0.808472\ttraining's binary_logloss: 0.0833987\tvalid_1's auc: 0.821043\tvalid_1's binary_logloss: 0.0604765\n",
      "[66]\ttraining's auc: 0.808539\ttraining's binary_logloss: 0.0833827\tvalid_1's auc: 0.82095\tvalid_1's binary_logloss: 0.0604534\n",
      "[67]\ttraining's auc: 0.80868\ttraining's binary_logloss: 0.083365\tvalid_1's auc: 0.820823\tvalid_1's binary_logloss: 0.0604365\n",
      "[68]\ttraining's auc: 0.808902\ttraining's binary_logloss: 0.0833306\tvalid_1's auc: 0.821164\tvalid_1's binary_logloss: 0.0604114\n",
      "[69]\ttraining's auc: 0.808963\ttraining's binary_logloss: 0.0833054\tvalid_1's auc: 0.821152\tvalid_1's binary_logloss: 0.0603806\n",
      "[70]\ttraining's auc: 0.809065\ttraining's binary_logloss: 0.0832896\tvalid_1's auc: 0.820988\tvalid_1's binary_logloss: 0.0603731\n",
      "[71]\ttraining's auc: 0.809131\ttraining's binary_logloss: 0.0832733\tvalid_1's auc: 0.820796\tvalid_1's binary_logloss: 0.060353\n",
      "[72]\ttraining's auc: 0.809242\ttraining's binary_logloss: 0.0832494\tvalid_1's auc: 0.821042\tvalid_1's binary_logloss: 0.0603353\n",
      "[73]\ttraining's auc: 0.809251\ttraining's binary_logloss: 0.0832331\tvalid_1's auc: 0.820673\tvalid_1's binary_logloss: 0.0603286\n",
      "[74]\ttraining's auc: 0.809299\ttraining's binary_logloss: 0.083222\tvalid_1's auc: 0.820532\tvalid_1's binary_logloss: 0.0603274\n",
      "[75]\ttraining's auc: 0.809464\ttraining's binary_logloss: 0.0832105\tvalid_1's auc: 0.820394\tvalid_1's binary_logloss: 0.0603293\n",
      "[76]\ttraining's auc: 0.809585\ttraining's binary_logloss: 0.0831955\tvalid_1's auc: 0.820388\tvalid_1's binary_logloss: 0.0603156\n",
      "[77]\ttraining's auc: 0.809747\ttraining's binary_logloss: 0.0831809\tvalid_1's auc: 0.820271\tvalid_1's binary_logloss: 0.0603137\n",
      "[78]\ttraining's auc: 0.809796\ttraining's binary_logloss: 0.0831612\tvalid_1's auc: 0.820245\tvalid_1's binary_logloss: 0.0602973\n",
      "[79]\ttraining's auc: 0.809824\ttraining's binary_logloss: 0.0831457\tvalid_1's auc: 0.820242\tvalid_1's binary_logloss: 0.0602737\n",
      "[80]\ttraining's auc: 0.809846\ttraining's binary_logloss: 0.0831342\tvalid_1's auc: 0.820216\tvalid_1's binary_logloss: 0.0602666\n",
      "[81]\ttraining's auc: 0.809914\ttraining's binary_logloss: 0.0831249\tvalid_1's auc: 0.820202\tvalid_1's binary_logloss: 0.0602674\n",
      "[82]\ttraining's auc: 0.810072\ttraining's binary_logloss: 0.0831136\tvalid_1's auc: 0.820429\tvalid_1's binary_logloss: 0.0602719\n",
      "[83]\ttraining's auc: 0.810203\ttraining's binary_logloss: 0.0830954\tvalid_1's auc: 0.820795\tvalid_1's binary_logloss: 0.0602409\n",
      "[84]\ttraining's auc: 0.810357\ttraining's binary_logloss: 0.0830836\tvalid_1's auc: 0.820813\tvalid_1's binary_logloss: 0.060238\n",
      "[85]\ttraining's auc: 0.810445\ttraining's binary_logloss: 0.0830713\tvalid_1's auc: 0.820432\tvalid_1's binary_logloss: 0.0602427\n",
      "[86]\ttraining's auc: 0.810666\ttraining's binary_logloss: 0.0830504\tvalid_1's auc: 0.820626\tvalid_1's binary_logloss: 0.0602363\n",
      "[87]\ttraining's auc: 0.810741\ttraining's binary_logloss: 0.0830327\tvalid_1's auc: 0.820713\tvalid_1's binary_logloss: 0.0602196\n",
      "[88]\ttraining's auc: 0.810789\ttraining's binary_logloss: 0.0830221\tvalid_1's auc: 0.820649\tvalid_1's binary_logloss: 0.0602134\n",
      "[89]\ttraining's auc: 0.810902\ttraining's binary_logloss: 0.0830092\tvalid_1's auc: 0.820928\tvalid_1's binary_logloss: 0.0602072\n",
      "[90]\ttraining's auc: 0.811032\ttraining's binary_logloss: 0.082995\tvalid_1's auc: 0.820882\tvalid_1's binary_logloss: 0.0601896\n",
      "[91]\ttraining's auc: 0.811066\ttraining's binary_logloss: 0.0829881\tvalid_1's auc: 0.820881\tvalid_1's binary_logloss: 0.0601859\n",
      "[92]\ttraining's auc: 0.811259\ttraining's binary_logloss: 0.0829758\tvalid_1's auc: 0.820903\tvalid_1's binary_logloss: 0.060185\n",
      "[93]\ttraining's auc: 0.811381\ttraining's binary_logloss: 0.0829651\tvalid_1's auc: 0.821054\tvalid_1's binary_logloss: 0.0601818\n",
      "[94]\ttraining's auc: 0.811463\ttraining's binary_logloss: 0.0829539\tvalid_1's auc: 0.821084\tvalid_1's binary_logloss: 0.0601786\n",
      "[95]\ttraining's auc: 0.811544\ttraining's binary_logloss: 0.0829391\tvalid_1's auc: 0.821226\tvalid_1's binary_logloss: 0.0601635\n",
      "[96]\ttraining's auc: 0.811549\ttraining's binary_logloss: 0.0829323\tvalid_1's auc: 0.821141\tvalid_1's binary_logloss: 0.0601641\n",
      "[97]\ttraining's auc: 0.811578\ttraining's binary_logloss: 0.0829267\tvalid_1's auc: 0.821183\tvalid_1's binary_logloss: 0.0601605\n",
      "[98]\ttraining's auc: 0.811656\ttraining's binary_logloss: 0.0829193\tvalid_1's auc: 0.821278\tvalid_1's binary_logloss: 0.060157\n",
      "[99]\ttraining's auc: 0.811626\ttraining's binary_logloss: 0.0829081\tvalid_1's auc: 0.821307\tvalid_1's binary_logloss: 0.0601464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.811672\ttraining's binary_logloss: 0.0828978\tvalid_1's auc: 0.821349\tvalid_1's binary_logloss: 0.0601376\n",
      "[101]\ttraining's auc: 0.811739\ttraining's binary_logloss: 0.0828873\tvalid_1's auc: 0.821272\tvalid_1's binary_logloss: 0.0601442\n",
      "[102]\ttraining's auc: 0.811776\ttraining's binary_logloss: 0.0828784\tvalid_1's auc: 0.821243\tvalid_1's binary_logloss: 0.0601307\n",
      "[103]\ttraining's auc: 0.811866\ttraining's binary_logloss: 0.0828724\tvalid_1's auc: 0.821194\tvalid_1's binary_logloss: 0.0601363\n",
      "[104]\ttraining's auc: 0.811853\ttraining's binary_logloss: 0.0828615\tvalid_1's auc: 0.821196\tvalid_1's binary_logloss: 0.0601267\n",
      "[105]\ttraining's auc: 0.811929\ttraining's binary_logloss: 0.0828553\tvalid_1's auc: 0.821368\tvalid_1's binary_logloss: 0.0601072\n",
      "[106]\ttraining's auc: 0.812023\ttraining's binary_logloss: 0.0828443\tvalid_1's auc: 0.821415\tvalid_1's binary_logloss: 0.0601093\n",
      "[107]\ttraining's auc: 0.812052\ttraining's binary_logloss: 0.0828383\tvalid_1's auc: 0.821405\tvalid_1's binary_logloss: 0.0601062\n",
      "[108]\ttraining's auc: 0.812191\ttraining's binary_logloss: 0.0828266\tvalid_1's auc: 0.821293\tvalid_1's binary_logloss: 0.0601056\n",
      "[109]\ttraining's auc: 0.812247\ttraining's binary_logloss: 0.0828197\tvalid_1's auc: 0.821175\tvalid_1's binary_logloss: 0.0601072\n",
      "[110]\ttraining's auc: 0.8123\ttraining's binary_logloss: 0.0828126\tvalid_1's auc: 0.82121\tvalid_1's binary_logloss: 0.0601011\n",
      "[111]\ttraining's auc: 0.812325\ttraining's binary_logloss: 0.0828061\tvalid_1's auc: 0.821159\tvalid_1's binary_logloss: 0.0600955\n",
      "[112]\ttraining's auc: 0.812362\ttraining's binary_logloss: 0.082795\tvalid_1's auc: 0.821345\tvalid_1's binary_logloss: 0.0600771\n",
      "[113]\ttraining's auc: 0.812404\ttraining's binary_logloss: 0.0827782\tvalid_1's auc: 0.821364\tvalid_1's binary_logloss: 0.0600613\n",
      "[114]\ttraining's auc: 0.812475\ttraining's binary_logloss: 0.0827683\tvalid_1's auc: 0.82134\tvalid_1's binary_logloss: 0.0600647\n",
      "[115]\ttraining's auc: 0.812525\ttraining's binary_logloss: 0.0827628\tvalid_1's auc: 0.821321\tvalid_1's binary_logloss: 0.060064\n",
      "[116]\ttraining's auc: 0.812595\ttraining's binary_logloss: 0.0827561\tvalid_1's auc: 0.821365\tvalid_1's binary_logloss: 0.0600534\n",
      "[117]\ttraining's auc: 0.812622\ttraining's binary_logloss: 0.0827515\tvalid_1's auc: 0.821384\tvalid_1's binary_logloss: 0.0600524\n",
      "[118]\ttraining's auc: 0.812656\ttraining's binary_logloss: 0.0827469\tvalid_1's auc: 0.821383\tvalid_1's binary_logloss: 0.0600542\n",
      "[119]\ttraining's auc: 0.812781\ttraining's binary_logloss: 0.0827366\tvalid_1's auc: 0.821528\tvalid_1's binary_logloss: 0.0600541\n",
      "[120]\ttraining's auc: 0.812874\ttraining's binary_logloss: 0.0827277\tvalid_1's auc: 0.821715\tvalid_1's binary_logloss: 0.0600413\n",
      "[121]\ttraining's auc: 0.812917\ttraining's binary_logloss: 0.0827186\tvalid_1's auc: 0.821565\tvalid_1's binary_logloss: 0.0600364\n",
      "[122]\ttraining's auc: 0.813006\ttraining's binary_logloss: 0.08271\tvalid_1's auc: 0.821589\tvalid_1's binary_logloss: 0.0600399\n",
      "[123]\ttraining's auc: 0.813021\ttraining's binary_logloss: 0.0827034\tvalid_1's auc: 0.821694\tvalid_1's binary_logloss: 0.0600359\n",
      "[124]\ttraining's auc: 0.813044\ttraining's binary_logloss: 0.0826933\tvalid_1's auc: 0.821681\tvalid_1's binary_logloss: 0.0600237\n",
      "[125]\ttraining's auc: 0.813119\ttraining's binary_logloss: 0.082688\tvalid_1's auc: 0.821795\tvalid_1's binary_logloss: 0.0600174\n",
      "[126]\ttraining's auc: 0.813216\ttraining's binary_logloss: 0.0826821\tvalid_1's auc: 0.821783\tvalid_1's binary_logloss: 0.0600013\n",
      "[127]\ttraining's auc: 0.813249\ttraining's binary_logloss: 0.0826778\tvalid_1's auc: 0.821767\tvalid_1's binary_logloss: 0.0600024\n",
      "[128]\ttraining's auc: 0.813268\ttraining's binary_logloss: 0.082668\tvalid_1's auc: 0.821632\tvalid_1's binary_logloss: 0.0600261\n",
      "[129]\ttraining's auc: 0.813323\ttraining's binary_logloss: 0.0826608\tvalid_1's auc: 0.821584\tvalid_1's binary_logloss: 0.0600235\n",
      "[130]\ttraining's auc: 0.813384\ttraining's binary_logloss: 0.0826554\tvalid_1's auc: 0.821659\tvalid_1's binary_logloss: 0.0600134\n",
      "[131]\ttraining's auc: 0.8135\ttraining's binary_logloss: 0.0826488\tvalid_1's auc: 0.821627\tvalid_1's binary_logloss: 0.0600142\n",
      "[132]\ttraining's auc: 0.813568\ttraining's binary_logloss: 0.0826436\tvalid_1's auc: 0.821635\tvalid_1's binary_logloss: 0.0600165\n",
      "[133]\ttraining's auc: 0.81359\ttraining's binary_logloss: 0.0826381\tvalid_1's auc: 0.821556\tvalid_1's binary_logloss: 0.060016\n",
      "[134]\ttraining's auc: 0.813677\ttraining's binary_logloss: 0.0826315\tvalid_1's auc: 0.821542\tvalid_1's binary_logloss: 0.0600176\n",
      "[135]\ttraining's auc: 0.813703\ttraining's binary_logloss: 0.0826274\tvalid_1's auc: 0.821401\tvalid_1's binary_logloss: 0.060018\n",
      "[136]\ttraining's auc: 0.813712\ttraining's binary_logloss: 0.0826241\tvalid_1's auc: 0.821315\tvalid_1's binary_logloss: 0.0600189\n",
      "[137]\ttraining's auc: 0.813741\ttraining's binary_logloss: 0.0826197\tvalid_1's auc: 0.821362\tvalid_1's binary_logloss: 0.0600188\n",
      "[138]\ttraining's auc: 0.81375\ttraining's binary_logloss: 0.0826153\tvalid_1's auc: 0.821385\tvalid_1's binary_logloss: 0.0600158\n",
      "[139]\ttraining's auc: 0.813797\ttraining's binary_logloss: 0.08261\tvalid_1's auc: 0.821375\tvalid_1's binary_logloss: 0.0600182\n",
      "[140]\ttraining's auc: 0.813874\ttraining's binary_logloss: 0.0826028\tvalid_1's auc: 0.821267\tvalid_1's binary_logloss: 0.0600265\n",
      "[141]\ttraining's auc: 0.813955\ttraining's binary_logloss: 0.0825958\tvalid_1's auc: 0.821178\tvalid_1's binary_logloss: 0.0600343\n",
      "[142]\ttraining's auc: 0.813982\ttraining's binary_logloss: 0.0825833\tvalid_1's auc: 0.821238\tvalid_1's binary_logloss: 0.0600276\n",
      "[143]\ttraining's auc: 0.814039\ttraining's binary_logloss: 0.0825807\tvalid_1's auc: 0.82131\tvalid_1's binary_logloss: 0.0600209\n",
      "[144]\ttraining's auc: 0.814088\ttraining's binary_logloss: 0.0825761\tvalid_1's auc: 0.821281\tvalid_1's binary_logloss: 0.0600217\n",
      "[145]\ttraining's auc: 0.814122\ttraining's binary_logloss: 0.0825661\tvalid_1's auc: 0.821387\tvalid_1's binary_logloss: 0.0600102\n",
      "[146]\ttraining's auc: 0.81409\ttraining's binary_logloss: 0.082561\tvalid_1's auc: 0.821264\tvalid_1's binary_logloss: 0.0600136\n",
      "[147]\ttraining's auc: 0.814117\ttraining's binary_logloss: 0.0825569\tvalid_1's auc: 0.82129\tvalid_1's binary_logloss: 0.0600151\n",
      "[148]\ttraining's auc: 0.814148\ttraining's binary_logloss: 0.0825527\tvalid_1's auc: 0.821262\tvalid_1's binary_logloss: 0.0600157\n",
      "[149]\ttraining's auc: 0.81417\ttraining's binary_logloss: 0.0825475\tvalid_1's auc: 0.821183\tvalid_1's binary_logloss: 0.0600157\n",
      "[150]\ttraining's auc: 0.814211\ttraining's binary_logloss: 0.0825441\tvalid_1's auc: 0.821185\tvalid_1's binary_logloss: 0.0600186\n",
      "[151]\ttraining's auc: 0.814252\ttraining's binary_logloss: 0.0825278\tvalid_1's auc: 0.821409\tvalid_1's binary_logloss: 0.0599965\n",
      "[152]\ttraining's auc: 0.814293\ttraining's binary_logloss: 0.0825228\tvalid_1's auc: 0.821292\tvalid_1's binary_logloss: 0.0599981\n",
      "[153]\ttraining's auc: 0.814297\ttraining's binary_logloss: 0.0825193\tvalid_1's auc: 0.821381\tvalid_1's binary_logloss: 0.0599917\n",
      "[154]\ttraining's auc: 0.814325\ttraining's binary_logloss: 0.0825136\tvalid_1's auc: 0.821493\tvalid_1's binary_logloss: 0.0599887\n",
      "[155]\ttraining's auc: 0.81438\ttraining's binary_logloss: 0.0825076\tvalid_1's auc: 0.82136\tvalid_1's binary_logloss: 0.0599906\n",
      "[156]\ttraining's auc: 0.81443\ttraining's binary_logloss: 0.0825036\tvalid_1's auc: 0.821325\tvalid_1's binary_logloss: 0.0599898\n",
      "[157]\ttraining's auc: 0.814514\ttraining's binary_logloss: 0.0824935\tvalid_1's auc: 0.821218\tvalid_1's binary_logloss: 0.0599927\n",
      "[158]\ttraining's auc: 0.814527\ttraining's binary_logloss: 0.0824906\tvalid_1's auc: 0.82108\tvalid_1's binary_logloss: 0.0600016\n",
      "[159]\ttraining's auc: 0.81457\ttraining's binary_logloss: 0.0824697\tvalid_1's auc: 0.82096\tvalid_1's binary_logloss: 0.0600046\n",
      "[160]\ttraining's auc: 0.814641\ttraining's binary_logloss: 0.0824625\tvalid_1's auc: 0.820928\tvalid_1's binary_logloss: 0.0600086\n",
      "[161]\ttraining's auc: 0.814685\ttraining's binary_logloss: 0.0824566\tvalid_1's auc: 0.821109\tvalid_1's binary_logloss: 0.0599903\n",
      "[162]\ttraining's auc: 0.814727\ttraining's binary_logloss: 0.0824545\tvalid_1's auc: 0.8212\tvalid_1's binary_logloss: 0.0599849\n",
      "[163]\ttraining's auc: 0.814776\ttraining's binary_logloss: 0.0824503\tvalid_1's auc: 0.821302\tvalid_1's binary_logloss: 0.0599763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164]\ttraining's auc: 0.814829\ttraining's binary_logloss: 0.0824443\tvalid_1's auc: 0.820976\tvalid_1's binary_logloss: 0.0599816\n",
      "[165]\ttraining's auc: 0.8149\ttraining's binary_logloss: 0.0824396\tvalid_1's auc: 0.820881\tvalid_1's binary_logloss: 0.0599805\n",
      "[166]\ttraining's auc: 0.814997\ttraining's binary_logloss: 0.0824266\tvalid_1's auc: 0.820852\tvalid_1's binary_logloss: 0.0599968\n",
      "[167]\ttraining's auc: 0.815014\ttraining's binary_logloss: 0.0824233\tvalid_1's auc: 0.820927\tvalid_1's binary_logloss: 0.0599868\n",
      "[168]\ttraining's auc: 0.815013\ttraining's binary_logloss: 0.0824207\tvalid_1's auc: 0.8208\tvalid_1's binary_logloss: 0.0599936\n",
      "[169]\ttraining's auc: 0.81509\ttraining's binary_logloss: 0.0824145\tvalid_1's auc: 0.820815\tvalid_1's binary_logloss: 0.0599954\n",
      "[170]\ttraining's auc: 0.815097\ttraining's binary_logloss: 0.0824122\tvalid_1's auc: 0.820917\tvalid_1's binary_logloss: 0.0599933\n",
      "[171]\ttraining's auc: 0.815103\ttraining's binary_logloss: 0.082409\tvalid_1's auc: 0.820822\tvalid_1's binary_logloss: 0.0599925\n",
      "[172]\ttraining's auc: 0.815198\ttraining's binary_logloss: 0.0823915\tvalid_1's auc: 0.820884\tvalid_1's binary_logloss: 0.0600012\n",
      "[173]\ttraining's auc: 0.815222\ttraining's binary_logloss: 0.0823894\tvalid_1's auc: 0.821\tvalid_1's binary_logloss: 0.0600029\n",
      "[174]\ttraining's auc: 0.815255\ttraining's binary_logloss: 0.082384\tvalid_1's auc: 0.82078\tvalid_1's binary_logloss: 0.0600164\n",
      "[175]\ttraining's auc: 0.815369\ttraining's binary_logloss: 0.0823761\tvalid_1's auc: 0.820559\tvalid_1's binary_logloss: 0.0600307\n",
      "[176]\ttraining's auc: 0.815466\ttraining's binary_logloss: 0.0823674\tvalid_1's auc: 0.820595\tvalid_1's binary_logloss: 0.0600342\n",
      "[177]\ttraining's auc: 0.815487\ttraining's binary_logloss: 0.0823635\tvalid_1's auc: 0.820692\tvalid_1's binary_logloss: 0.0600314\n",
      "[178]\ttraining's auc: 0.815583\ttraining's binary_logloss: 0.0823559\tvalid_1's auc: 0.820668\tvalid_1's binary_logloss: 0.0600398\n",
      "[179]\ttraining's auc: 0.815687\ttraining's binary_logloss: 0.0823484\tvalid_1's auc: 0.820566\tvalid_1's binary_logloss: 0.060047\n",
      "[180]\ttraining's auc: 0.815706\ttraining's binary_logloss: 0.0823448\tvalid_1's auc: 0.820561\tvalid_1's binary_logloss: 0.060051\n",
      "[181]\ttraining's auc: 0.815737\ttraining's binary_logloss: 0.0823392\tvalid_1's auc: 0.820477\tvalid_1's binary_logloss: 0.06005\n",
      "[182]\ttraining's auc: 0.815722\ttraining's binary_logloss: 0.0823335\tvalid_1's auc: 0.820675\tvalid_1's binary_logloss: 0.06003\n",
      "[183]\ttraining's auc: 0.815745\ttraining's binary_logloss: 0.0823273\tvalid_1's auc: 0.820777\tvalid_1's binary_logloss: 0.0600256\n",
      "[184]\ttraining's auc: 0.815755\ttraining's binary_logloss: 0.0823253\tvalid_1's auc: 0.820866\tvalid_1's binary_logloss: 0.0600241\n",
      "[185]\ttraining's auc: 0.815829\ttraining's binary_logloss: 0.0823227\tvalid_1's auc: 0.820888\tvalid_1's binary_logloss: 0.0600228\n",
      "[186]\ttraining's auc: 0.815887\ttraining's binary_logloss: 0.0823157\tvalid_1's auc: 0.82077\tvalid_1's binary_logloss: 0.0600275\n",
      "[187]\ttraining's auc: 0.815929\ttraining's binary_logloss: 0.0823053\tvalid_1's auc: 0.82075\tvalid_1's binary_logloss: 0.0600366\n",
      "[188]\ttraining's auc: 0.815992\ttraining's binary_logloss: 0.0823002\tvalid_1's auc: 0.820815\tvalid_1's binary_logloss: 0.0600324\n",
      "[189]\ttraining's auc: 0.81606\ttraining's binary_logloss: 0.0822913\tvalid_1's auc: 0.820713\tvalid_1's binary_logloss: 0.0600395\n",
      "[190]\ttraining's auc: 0.816139\ttraining's binary_logloss: 0.0822851\tvalid_1's auc: 0.82074\tvalid_1's binary_logloss: 0.0600402\n",
      "[191]\ttraining's auc: 0.816213\ttraining's binary_logloss: 0.0822793\tvalid_1's auc: 0.820821\tvalid_1's binary_logloss: 0.0600409\n",
      "[192]\ttraining's auc: 0.816249\ttraining's binary_logloss: 0.0822733\tvalid_1's auc: 0.820999\tvalid_1's binary_logloss: 0.0600369\n",
      "[193]\ttraining's auc: 0.816205\ttraining's binary_logloss: 0.0822664\tvalid_1's auc: 0.821091\tvalid_1's binary_logloss: 0.0600323\n",
      "[194]\ttraining's auc: 0.816235\ttraining's binary_logloss: 0.0822621\tvalid_1's auc: 0.820952\tvalid_1's binary_logloss: 0.0600387\n",
      "[195]\ttraining's auc: 0.816252\ttraining's binary_logloss: 0.0822505\tvalid_1's auc: 0.820979\tvalid_1's binary_logloss: 0.0600292\n",
      "[196]\ttraining's auc: 0.816315\ttraining's binary_logloss: 0.0822465\tvalid_1's auc: 0.821024\tvalid_1's binary_logloss: 0.0600296\n",
      "[197]\ttraining's auc: 0.816356\ttraining's binary_logloss: 0.0822341\tvalid_1's auc: 0.821042\tvalid_1's binary_logloss: 0.0600237\n",
      "[198]\ttraining's auc: 0.816366\ttraining's binary_logloss: 0.0822317\tvalid_1's auc: 0.820935\tvalid_1's binary_logloss: 0.0600264\n",
      "[199]\ttraining's auc: 0.816393\ttraining's binary_logloss: 0.082226\tvalid_1's auc: 0.821061\tvalid_1's binary_logloss: 0.0600098\n",
      "[200]\ttraining's auc: 0.816488\ttraining's binary_logloss: 0.0822196\tvalid_1's auc: 0.821045\tvalid_1's binary_logloss: 0.0600129\n",
      "[201]\ttraining's auc: 0.816518\ttraining's binary_logloss: 0.0822179\tvalid_1's auc: 0.821047\tvalid_1's binary_logloss: 0.0600112\n",
      "[202]\ttraining's auc: 0.816547\ttraining's binary_logloss: 0.0822135\tvalid_1's auc: 0.820971\tvalid_1's binary_logloss: 0.0600017\n",
      "[203]\ttraining's auc: 0.816584\ttraining's binary_logloss: 0.0822088\tvalid_1's auc: 0.820758\tvalid_1's binary_logloss: 0.0600126\n",
      "[204]\ttraining's auc: 0.816601\ttraining's binary_logloss: 0.0821987\tvalid_1's auc: 0.820789\tvalid_1's binary_logloss: 0.0600005\n",
      "[205]\ttraining's auc: 0.816627\ttraining's binary_logloss: 0.0821949\tvalid_1's auc: 0.820564\tvalid_1's binary_logloss: 0.0600141\n",
      "[206]\ttraining's auc: 0.816667\ttraining's binary_logloss: 0.0821892\tvalid_1's auc: 0.820599\tvalid_1's binary_logloss: 0.0600205\n",
      "[207]\ttraining's auc: 0.816684\ttraining's binary_logloss: 0.0821831\tvalid_1's auc: 0.820521\tvalid_1's binary_logloss: 0.0600273\n",
      "[208]\ttraining's auc: 0.816712\ttraining's binary_logloss: 0.0821732\tvalid_1's auc: 0.820456\tvalid_1's binary_logloss: 0.060027\n",
      "[209]\ttraining's auc: 0.816755\ttraining's binary_logloss: 0.0821695\tvalid_1's auc: 0.820614\tvalid_1's binary_logloss: 0.0600191\n",
      "[210]\ttraining's auc: 0.816784\ttraining's binary_logloss: 0.0821682\tvalid_1's auc: 0.82067\tvalid_1's binary_logloss: 0.0600131\n",
      "[211]\ttraining's auc: 0.816821\ttraining's binary_logloss: 0.082164\tvalid_1's auc: 0.820598\tvalid_1's binary_logloss: 0.0600109\n",
      "[212]\ttraining's auc: 0.816849\ttraining's binary_logloss: 0.0821616\tvalid_1's auc: 0.820533\tvalid_1's binary_logloss: 0.0600131\n",
      "[213]\ttraining's auc: 0.816839\ttraining's binary_logloss: 0.0821587\tvalid_1's auc: 0.820506\tvalid_1's binary_logloss: 0.0600095\n",
      "[214]\ttraining's auc: 0.816874\ttraining's binary_logloss: 0.0821531\tvalid_1's auc: 0.820567\tvalid_1's binary_logloss: 0.0600023\n",
      "[215]\ttraining's auc: 0.816867\ttraining's binary_logloss: 0.0821499\tvalid_1's auc: 0.820573\tvalid_1's binary_logloss: 0.0600039\n",
      "[216]\ttraining's auc: 0.816881\ttraining's binary_logloss: 0.0821431\tvalid_1's auc: 0.82061\tvalid_1's binary_logloss: 0.06\n",
      "[217]\ttraining's auc: 0.816894\ttraining's binary_logloss: 0.0821404\tvalid_1's auc: 0.820641\tvalid_1's binary_logloss: 0.0600019\n",
      "[218]\ttraining's auc: 0.816938\ttraining's binary_logloss: 0.0821355\tvalid_1's auc: 0.820575\tvalid_1's binary_logloss: 0.0599994\n",
      "[219]\ttraining's auc: 0.817\ttraining's binary_logloss: 0.0821307\tvalid_1's auc: 0.820626\tvalid_1's binary_logloss: 0.0599999\n",
      "[220]\ttraining's auc: 0.816996\ttraining's binary_logloss: 0.0821268\tvalid_1's auc: 0.820751\tvalid_1's binary_logloss: 0.0599993\n",
      "[221]\ttraining's auc: 0.817\ttraining's binary_logloss: 0.082121\tvalid_1's auc: 0.820996\tvalid_1's binary_logloss: 0.0599889\n",
      "[222]\ttraining's auc: 0.817003\ttraining's binary_logloss: 0.0821191\tvalid_1's auc: 0.820983\tvalid_1's binary_logloss: 0.0599843\n",
      "[223]\ttraining's auc: 0.817024\ttraining's binary_logloss: 0.0821135\tvalid_1's auc: 0.82083\tvalid_1's binary_logloss: 0.059994\n",
      "[224]\ttraining's auc: 0.817113\ttraining's binary_logloss: 0.0821071\tvalid_1's auc: 0.820921\tvalid_1's binary_logloss: 0.0599912\n",
      "[225]\ttraining's auc: 0.817179\ttraining's binary_logloss: 0.0821007\tvalid_1's auc: 0.820941\tvalid_1's binary_logloss: 0.0599962\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's auc: 0.813119\ttraining's binary_logloss: 0.082688\tvalid_1's auc: 0.821795\tvalid_1's binary_logloss: 0.0600174\n",
      "8\n",
      "[1]\ttraining's auc: 0.7369\ttraining's binary_logloss: 0.0916053\tvalid_1's auc: 0.7262\tvalid_1's binary_logloss: 0.088886\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's auc: 0.793624\ttraining's binary_logloss: 0.0901081\tvalid_1's auc: 0.767404\tvalid_1's binary_logloss: 0.0878256\n",
      "[3]\ttraining's auc: 0.798711\ttraining's binary_logloss: 0.0895489\tvalid_1's auc: 0.774005\tvalid_1's binary_logloss: 0.0873619\n",
      "[4]\ttraining's auc: 0.799412\ttraining's binary_logloss: 0.0890054\tvalid_1's auc: 0.77414\tvalid_1's binary_logloss: 0.0869067\n",
      "[5]\ttraining's auc: 0.803779\ttraining's binary_logloss: 0.0880829\tvalid_1's auc: 0.776585\tvalid_1's binary_logloss: 0.0862555\n",
      "[6]\ttraining's auc: 0.804211\ttraining's binary_logloss: 0.087227\tvalid_1's auc: 0.776126\tvalid_1's binary_logloss: 0.0856483\n",
      "[7]\ttraining's auc: 0.803314\ttraining's binary_logloss: 0.0868094\tvalid_1's auc: 0.775453\tvalid_1's binary_logloss: 0.0852977\n",
      "[8]\ttraining's auc: 0.804279\ttraining's binary_logloss: 0.0860924\tvalid_1's auc: 0.775941\tvalid_1's binary_logloss: 0.0847639\n",
      "[9]\ttraining's auc: 0.805975\ttraining's binary_logloss: 0.0854646\tvalid_1's auc: 0.777475\tvalid_1's binary_logloss: 0.0842941\n",
      "[10]\ttraining's auc: 0.805989\ttraining's binary_logloss: 0.0851829\tvalid_1's auc: 0.776597\tvalid_1's binary_logloss: 0.0840807\n",
      "[11]\ttraining's auc: 0.806146\ttraining's binary_logloss: 0.084626\tvalid_1's auc: 0.776615\tvalid_1's binary_logloss: 0.0836775\n",
      "[12]\ttraining's auc: 0.807735\ttraining's binary_logloss: 0.0841373\tvalid_1's auc: 0.777433\tvalid_1's binary_logloss: 0.0833524\n",
      "[13]\ttraining's auc: 0.80815\ttraining's binary_logloss: 0.083907\tvalid_1's auc: 0.778567\tvalid_1's binary_logloss: 0.0831794\n",
      "[14]\ttraining's auc: 0.8085\ttraining's binary_logloss: 0.0834762\tvalid_1's auc: 0.779139\tvalid_1's binary_logloss: 0.0828748\n",
      "[15]\ttraining's auc: 0.8088\ttraining's binary_logloss: 0.0831041\tvalid_1's auc: 0.779599\tvalid_1's binary_logloss: 0.0826197\n",
      "[16]\ttraining's auc: 0.808836\ttraining's binary_logloss: 0.0827816\tvalid_1's auc: 0.779159\tvalid_1's binary_logloss: 0.0824344\n",
      "[17]\ttraining's auc: 0.808764\ttraining's binary_logloss: 0.0825583\tvalid_1's auc: 0.779135\tvalid_1's binary_logloss: 0.0822425\n",
      "[18]\ttraining's auc: 0.809898\ttraining's binary_logloss: 0.0822904\tvalid_1's auc: 0.779895\tvalid_1's binary_logloss: 0.08208\n",
      "[19]\ttraining's auc: 0.810305\ttraining's binary_logloss: 0.0820217\tvalid_1's auc: 0.78017\tvalid_1's binary_logloss: 0.0818671\n",
      "[20]\ttraining's auc: 0.810257\ttraining's binary_logloss: 0.0818533\tvalid_1's auc: 0.78061\tvalid_1's binary_logloss: 0.081711\n",
      "[21]\ttraining's auc: 0.810229\ttraining's binary_logloss: 0.081637\tvalid_1's auc: 0.780498\tvalid_1's binary_logloss: 0.0815919\n",
      "[22]\ttraining's auc: 0.81049\ttraining's binary_logloss: 0.0814333\tvalid_1's auc: 0.780998\tvalid_1's binary_logloss: 0.0814317\n",
      "[23]\ttraining's auc: 0.810853\ttraining's binary_logloss: 0.0812843\tvalid_1's auc: 0.782034\tvalid_1's binary_logloss: 0.0812936\n",
      "[24]\ttraining's auc: 0.810865\ttraining's binary_logloss: 0.0811005\tvalid_1's auc: 0.781915\tvalid_1's binary_logloss: 0.0812019\n",
      "[25]\ttraining's auc: 0.811411\ttraining's binary_logloss: 0.0809179\tvalid_1's auc: 0.782555\tvalid_1's binary_logloss: 0.0810784\n",
      "[26]\ttraining's auc: 0.811831\ttraining's binary_logloss: 0.0807615\tvalid_1's auc: 0.782595\tvalid_1's binary_logloss: 0.0810016\n",
      "[27]\ttraining's auc: 0.812533\ttraining's binary_logloss: 0.0806293\tvalid_1's auc: 0.782433\tvalid_1's binary_logloss: 0.0809393\n",
      "[28]\ttraining's auc: 0.813004\ttraining's binary_logloss: 0.0805518\tvalid_1's auc: 0.782505\tvalid_1's binary_logloss: 0.0808556\n",
      "[29]\ttraining's auc: 0.813944\ttraining's binary_logloss: 0.0804244\tvalid_1's auc: 0.78287\tvalid_1's binary_logloss: 0.0807739\n",
      "[30]\ttraining's auc: 0.81393\ttraining's binary_logloss: 0.0803039\tvalid_1's auc: 0.782935\tvalid_1's binary_logloss: 0.080679\n",
      "[31]\ttraining's auc: 0.814248\ttraining's binary_logloss: 0.0801919\tvalid_1's auc: 0.78356\tvalid_1's binary_logloss: 0.0806119\n",
      "[32]\ttraining's auc: 0.814152\ttraining's binary_logloss: 0.0801182\tvalid_1's auc: 0.783896\tvalid_1's binary_logloss: 0.080538\n",
      "[33]\ttraining's auc: 0.814973\ttraining's binary_logloss: 0.0800265\tvalid_1's auc: 0.785014\tvalid_1's binary_logloss: 0.0804548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34]\ttraining's auc: 0.814946\ttraining's binary_logloss: 0.0799604\tvalid_1's auc: 0.784776\tvalid_1's binary_logloss: 0.0804281\n",
      "[35]\ttraining's auc: 0.815168\ttraining's binary_logloss: 0.07987\tvalid_1's auc: 0.784543\tvalid_1's binary_logloss: 0.0803984\n",
      "[36]\ttraining's auc: 0.815285\ttraining's binary_logloss: 0.0798056\tvalid_1's auc: 0.784537\tvalid_1's binary_logloss: 0.0803779\n",
      "[37]\ttraining's auc: 0.816009\ttraining's binary_logloss: 0.0797318\tvalid_1's auc: 0.785455\tvalid_1's binary_logloss: 0.0803199\n",
      "[38]\ttraining's auc: 0.816104\ttraining's binary_logloss: 0.0796535\tvalid_1's auc: 0.785651\tvalid_1's binary_logloss: 0.0802644\n",
      "[39]\ttraining's auc: 0.816478\ttraining's binary_logloss: 0.0795767\tvalid_1's auc: 0.786218\tvalid_1's binary_logloss: 0.0801931\n",
      "[40]\ttraining's auc: 0.816644\ttraining's binary_logloss: 0.0795068\tvalid_1's auc: 0.785947\tvalid_1's binary_logloss: 0.0801397\n",
      "[41]\ttraining's auc: 0.816972\ttraining's binary_logloss: 0.0794396\tvalid_1's auc: 0.786279\tvalid_1's binary_logloss: 0.0800832\n",
      "[42]\ttraining's auc: 0.817289\ttraining's binary_logloss: 0.079396\tvalid_1's auc: 0.786501\tvalid_1's binary_logloss: 0.0800641\n",
      "[43]\ttraining's auc: 0.817678\ttraining's binary_logloss: 0.0793413\tvalid_1's auc: 0.786424\tvalid_1's binary_logloss: 0.0799994\n",
      "[44]\ttraining's auc: 0.817764\ttraining's binary_logloss: 0.0793085\tvalid_1's auc: 0.786383\tvalid_1's binary_logloss: 0.0799888\n",
      "[45]\ttraining's auc: 0.818065\ttraining's binary_logloss: 0.0792525\tvalid_1's auc: 0.786374\tvalid_1's binary_logloss: 0.0799347\n",
      "[46]\ttraining's auc: 0.818213\ttraining's binary_logloss: 0.0792125\tvalid_1's auc: 0.786818\tvalid_1's binary_logloss: 0.0798919\n",
      "[47]\ttraining's auc: 0.818225\ttraining's binary_logloss: 0.0791659\tvalid_1's auc: 0.786802\tvalid_1's binary_logloss: 0.0798885\n",
      "[48]\ttraining's auc: 0.818294\ttraining's binary_logloss: 0.0791129\tvalid_1's auc: 0.786973\tvalid_1's binary_logloss: 0.0798449\n",
      "[49]\ttraining's auc: 0.818384\ttraining's binary_logloss: 0.0790677\tvalid_1's auc: 0.787172\tvalid_1's binary_logloss: 0.0797988\n",
      "[50]\ttraining's auc: 0.81875\ttraining's binary_logloss: 0.0790338\tvalid_1's auc: 0.787674\tvalid_1's binary_logloss: 0.0797501\n",
      "[51]\ttraining's auc: 0.819018\ttraining's binary_logloss: 0.0790031\tvalid_1's auc: 0.787511\tvalid_1's binary_logloss: 0.0797522\n",
      "[52]\ttraining's auc: 0.819135\ttraining's binary_logloss: 0.0789693\tvalid_1's auc: 0.78737\tvalid_1's binary_logloss: 0.0797677\n",
      "[53]\ttraining's auc: 0.819253\ttraining's binary_logloss: 0.0789426\tvalid_1's auc: 0.78691\tvalid_1's binary_logloss: 0.0797747\n",
      "[54]\ttraining's auc: 0.819314\ttraining's binary_logloss: 0.0789076\tvalid_1's auc: 0.786886\tvalid_1's binary_logloss: 0.0797468\n",
      "[55]\ttraining's auc: 0.819596\ttraining's binary_logloss: 0.0788797\tvalid_1's auc: 0.787097\tvalid_1's binary_logloss: 0.0797247\n",
      "[56]\ttraining's auc: 0.819635\ttraining's binary_logloss: 0.078849\tvalid_1's auc: 0.78727\tvalid_1's binary_logloss: 0.0797196\n",
      "[57]\ttraining's auc: 0.819524\ttraining's binary_logloss: 0.0788176\tvalid_1's auc: 0.787202\tvalid_1's binary_logloss: 0.0797061\n",
      "[58]\ttraining's auc: 0.819885\ttraining's binary_logloss: 0.0787809\tvalid_1's auc: 0.786986\tvalid_1's binary_logloss: 0.0796773\n",
      "[59]\ttraining's auc: 0.820132\ttraining's binary_logloss: 0.0787563\tvalid_1's auc: 0.787051\tvalid_1's binary_logloss: 0.0796595\n",
      "[60]\ttraining's auc: 0.820314\ttraining's binary_logloss: 0.0787336\tvalid_1's auc: 0.787165\tvalid_1's binary_logloss: 0.0796406\n",
      "[61]\ttraining's auc: 0.820354\ttraining's binary_logloss: 0.0787033\tvalid_1's auc: 0.786894\tvalid_1's binary_logloss: 0.079616\n",
      "[62]\ttraining's auc: 0.820356\ttraining's binary_logloss: 0.078681\tvalid_1's auc: 0.786521\tvalid_1's binary_logloss: 0.0795994\n",
      "[63]\ttraining's auc: 0.820373\ttraining's binary_logloss: 0.0786642\tvalid_1's auc: 0.786666\tvalid_1's binary_logloss: 0.0795999\n",
      "[64]\ttraining's auc: 0.820427\ttraining's binary_logloss: 0.0786379\tvalid_1's auc: 0.786603\tvalid_1's binary_logloss: 0.0795844\n",
      "[65]\ttraining's auc: 0.820394\ttraining's binary_logloss: 0.078617\tvalid_1's auc: 0.786761\tvalid_1's binary_logloss: 0.0795779\n",
      "[66]\ttraining's auc: 0.820447\ttraining's binary_logloss: 0.0785933\tvalid_1's auc: 0.786886\tvalid_1's binary_logloss: 0.0795861\n",
      "[67]\ttraining's auc: 0.820571\ttraining's binary_logloss: 0.0785753\tvalid_1's auc: 0.786924\tvalid_1's binary_logloss: 0.0795749\n",
      "[68]\ttraining's auc: 0.82087\ttraining's binary_logloss: 0.0785515\tvalid_1's auc: 0.786913\tvalid_1's binary_logloss: 0.0795443\n",
      "[69]\ttraining's auc: 0.820836\ttraining's binary_logloss: 0.0785265\tvalid_1's auc: 0.787007\tvalid_1's binary_logloss: 0.0795287\n",
      "[70]\ttraining's auc: 0.820941\ttraining's binary_logloss: 0.07851\tvalid_1's auc: 0.787047\tvalid_1's binary_logloss: 0.0795128\n",
      "[71]\ttraining's auc: 0.821038\ttraining's binary_logloss: 0.0784937\tvalid_1's auc: 0.787206\tvalid_1's binary_logloss: 0.0794998\n",
      "[72]\ttraining's auc: 0.821196\ttraining's binary_logloss: 0.0784731\tvalid_1's auc: 0.787411\tvalid_1's binary_logloss: 0.0794832\n",
      "[73]\ttraining's auc: 0.821244\ttraining's binary_logloss: 0.0784582\tvalid_1's auc: 0.787389\tvalid_1's binary_logloss: 0.079457\n",
      "[74]\ttraining's auc: 0.821283\ttraining's binary_logloss: 0.0784464\tvalid_1's auc: 0.787436\tvalid_1's binary_logloss: 0.0794639\n",
      "[75]\ttraining's auc: 0.821328\ttraining's binary_logloss: 0.0784297\tvalid_1's auc: 0.787239\tvalid_1's binary_logloss: 0.0794601\n",
      "[76]\ttraining's auc: 0.821475\ttraining's binary_logloss: 0.0784187\tvalid_1's auc: 0.787371\tvalid_1's binary_logloss: 0.0794386\n",
      "[77]\ttraining's auc: 0.821516\ttraining's binary_logloss: 0.0784014\tvalid_1's auc: 0.787178\tvalid_1's binary_logloss: 0.0794354\n",
      "[78]\ttraining's auc: 0.821563\ttraining's binary_logloss: 0.0783877\tvalid_1's auc: 0.78719\tvalid_1's binary_logloss: 0.0794215\n",
      "[79]\ttraining's auc: 0.821637\ttraining's binary_logloss: 0.0783782\tvalid_1's auc: 0.787271\tvalid_1's binary_logloss: 0.0794005\n",
      "[80]\ttraining's auc: 0.82165\ttraining's binary_logloss: 0.0783677\tvalid_1's auc: 0.787199\tvalid_1's binary_logloss: 0.0794142\n",
      "[81]\ttraining's auc: 0.821708\ttraining's binary_logloss: 0.0783533\tvalid_1's auc: 0.787559\tvalid_1's binary_logloss: 0.0794078\n",
      "[82]\ttraining's auc: 0.821803\ttraining's binary_logloss: 0.0783399\tvalid_1's auc: 0.787354\tvalid_1's binary_logloss: 0.0794103\n",
      "[83]\ttraining's auc: 0.821853\ttraining's binary_logloss: 0.0783251\tvalid_1's auc: 0.787425\tvalid_1's binary_logloss: 0.079407\n",
      "[84]\ttraining's auc: 0.821942\ttraining's binary_logloss: 0.0783127\tvalid_1's auc: 0.787451\tvalid_1's binary_logloss: 0.07942\n",
      "[85]\ttraining's auc: 0.821994\ttraining's binary_logloss: 0.0783047\tvalid_1's auc: 0.787432\tvalid_1's binary_logloss: 0.0794058\n",
      "[86]\ttraining's auc: 0.822117\ttraining's binary_logloss: 0.078291\tvalid_1's auc: 0.787689\tvalid_1's binary_logloss: 0.0793852\n",
      "[87]\ttraining's auc: 0.822195\ttraining's binary_logloss: 0.0782852\tvalid_1's auc: 0.787637\tvalid_1's binary_logloss: 0.0793912\n",
      "[88]\ttraining's auc: 0.822232\ttraining's binary_logloss: 0.0782745\tvalid_1's auc: 0.787571\tvalid_1's binary_logloss: 0.0794053\n",
      "[89]\ttraining's auc: 0.822295\ttraining's binary_logloss: 0.0782632\tvalid_1's auc: 0.787588\tvalid_1's binary_logloss: 0.0794102\n",
      "[90]\ttraining's auc: 0.822334\ttraining's binary_logloss: 0.0782498\tvalid_1's auc: 0.787749\tvalid_1's binary_logloss: 0.0793941\n",
      "[91]\ttraining's auc: 0.82241\ttraining's binary_logloss: 0.0782236\tvalid_1's auc: 0.787906\tvalid_1's binary_logloss: 0.0793664\n",
      "[92]\ttraining's auc: 0.82244\ttraining's binary_logloss: 0.078216\tvalid_1's auc: 0.787842\tvalid_1's binary_logloss: 0.079383\n",
      "[93]\ttraining's auc: 0.822526\ttraining's binary_logloss: 0.0782096\tvalid_1's auc: 0.787842\tvalid_1's binary_logloss: 0.0793805\n",
      "[94]\ttraining's auc: 0.822594\ttraining's binary_logloss: 0.078194\tvalid_1's auc: 0.787794\tvalid_1's binary_logloss: 0.0793719\n",
      "[95]\ttraining's auc: 0.822673\ttraining's binary_logloss: 0.0781781\tvalid_1's auc: 0.787804\tvalid_1's binary_logloss: 0.0793498\n",
      "[96]\ttraining's auc: 0.822747\ttraining's binary_logloss: 0.0781702\tvalid_1's auc: 0.787792\tvalid_1's binary_logloss: 0.0793445\n",
      "[97]\ttraining's auc: 0.822802\ttraining's binary_logloss: 0.078157\tvalid_1's auc: 0.787729\tvalid_1's binary_logloss: 0.0793392\n",
      "[98]\ttraining's auc: 0.82288\ttraining's binary_logloss: 0.0781479\tvalid_1's auc: 0.787745\tvalid_1's binary_logloss: 0.0793338\n",
      "[99]\ttraining's auc: 0.822883\ttraining's binary_logloss: 0.0781373\tvalid_1's auc: 0.787548\tvalid_1's binary_logloss: 0.0793386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's auc: 0.822914\ttraining's binary_logloss: 0.07813\tvalid_1's auc: 0.787542\tvalid_1's binary_logloss: 0.0793532\n",
      "[101]\ttraining's auc: 0.82305\ttraining's binary_logloss: 0.078119\tvalid_1's auc: 0.787621\tvalid_1's binary_logloss: 0.0793474\n",
      "[102]\ttraining's auc: 0.823132\ttraining's binary_logloss: 0.0781044\tvalid_1's auc: 0.787705\tvalid_1's binary_logloss: 0.079351\n",
      "[103]\ttraining's auc: 0.823185\ttraining's binary_logloss: 0.0780994\tvalid_1's auc: 0.787751\tvalid_1's binary_logloss: 0.0793397\n",
      "[104]\ttraining's auc: 0.823246\ttraining's binary_logloss: 0.0780871\tvalid_1's auc: 0.787614\tvalid_1's binary_logloss: 0.0793326\n",
      "[105]\ttraining's auc: 0.823308\ttraining's binary_logloss: 0.0780803\tvalid_1's auc: 0.787395\tvalid_1's binary_logloss: 0.0793431\n",
      "[106]\ttraining's auc: 0.823391\ttraining's binary_logloss: 0.0780711\tvalid_1's auc: 0.787651\tvalid_1's binary_logloss: 0.079327\n",
      "[107]\ttraining's auc: 0.823408\ttraining's binary_logloss: 0.0780652\tvalid_1's auc: 0.787602\tvalid_1's binary_logloss: 0.0793386\n",
      "[108]\ttraining's auc: 0.823459\ttraining's binary_logloss: 0.0780561\tvalid_1's auc: 0.787448\tvalid_1's binary_logloss: 0.0793527\n",
      "[109]\ttraining's auc: 0.823511\ttraining's binary_logloss: 0.0780513\tvalid_1's auc: 0.787332\tvalid_1's binary_logloss: 0.0793512\n",
      "[110]\ttraining's auc: 0.823507\ttraining's binary_logloss: 0.0780462\tvalid_1's auc: 0.78735\tvalid_1's binary_logloss: 0.0793553\n",
      "[111]\ttraining's auc: 0.823527\ttraining's binary_logloss: 0.0780347\tvalid_1's auc: 0.787337\tvalid_1's binary_logloss: 0.07935\n",
      "[112]\ttraining's auc: 0.82369\ttraining's binary_logloss: 0.0780229\tvalid_1's auc: 0.787286\tvalid_1's binary_logloss: 0.0793605\n",
      "[113]\ttraining's auc: 0.823708\ttraining's binary_logloss: 0.0780184\tvalid_1's auc: 0.787252\tvalid_1's binary_logloss: 0.0793774\n",
      "[114]\ttraining's auc: 0.823756\ttraining's binary_logloss: 0.0780121\tvalid_1's auc: 0.787226\tvalid_1's binary_logloss: 0.0793885\n",
      "[115]\ttraining's auc: 0.823782\ttraining's binary_logloss: 0.0780076\tvalid_1's auc: 0.787351\tvalid_1's binary_logloss: 0.0793852\n",
      "[116]\ttraining's auc: 0.823817\ttraining's binary_logloss: 0.0780034\tvalid_1's auc: 0.787426\tvalid_1's binary_logloss: 0.0793775\n",
      "[117]\ttraining's auc: 0.823853\ttraining's binary_logloss: 0.0779989\tvalid_1's auc: 0.787427\tvalid_1's binary_logloss: 0.07938\n",
      "[118]\ttraining's auc: 0.823905\ttraining's binary_logloss: 0.077992\tvalid_1's auc: 0.78754\tvalid_1's binary_logloss: 0.0793736\n",
      "[119]\ttraining's auc: 0.823966\ttraining's binary_logloss: 0.0779878\tvalid_1's auc: 0.787518\tvalid_1's binary_logloss: 0.0793709\n",
      "[120]\ttraining's auc: 0.823979\ttraining's binary_logloss: 0.0779811\tvalid_1's auc: 0.787685\tvalid_1's binary_logloss: 0.0793688\n",
      "[121]\ttraining's auc: 0.824062\ttraining's binary_logloss: 0.077971\tvalid_1's auc: 0.787591\tvalid_1's binary_logloss: 0.0793597\n",
      "[122]\ttraining's auc: 0.824113\ttraining's binary_logloss: 0.0779644\tvalid_1's auc: 0.78769\tvalid_1's binary_logloss: 0.0793503\n",
      "[123]\ttraining's auc: 0.824167\ttraining's binary_logloss: 0.0779581\tvalid_1's auc: 0.787764\tvalid_1's binary_logloss: 0.0793507\n",
      "[124]\ttraining's auc: 0.824189\ttraining's binary_logloss: 0.0779543\tvalid_1's auc: 0.787802\tvalid_1's binary_logloss: 0.0793521\n",
      "[125]\ttraining's auc: 0.824283\ttraining's binary_logloss: 0.0779489\tvalid_1's auc: 0.787708\tvalid_1's binary_logloss: 0.0793555\n",
      "[126]\ttraining's auc: 0.824374\ttraining's binary_logloss: 0.0779426\tvalid_1's auc: 0.787595\tvalid_1's binary_logloss: 0.0793642\n",
      "[127]\ttraining's auc: 0.824421\ttraining's binary_logloss: 0.0779353\tvalid_1's auc: 0.787618\tvalid_1's binary_logloss: 0.0793692\n",
      "[128]\ttraining's auc: 0.824429\ttraining's binary_logloss: 0.0779318\tvalid_1's auc: 0.787667\tvalid_1's binary_logloss: 0.0793629\n",
      "[129]\ttraining's auc: 0.824484\ttraining's binary_logloss: 0.0779197\tvalid_1's auc: 0.787896\tvalid_1's binary_logloss: 0.0793373\n",
      "[130]\ttraining's auc: 0.824523\ttraining's binary_logloss: 0.0779126\tvalid_1's auc: 0.787862\tvalid_1's binary_logloss: 0.079339\n",
      "[131]\ttraining's auc: 0.824511\ttraining's binary_logloss: 0.0779061\tvalid_1's auc: 0.788\tvalid_1's binary_logloss: 0.0793325\n",
      "[132]\ttraining's auc: 0.82458\ttraining's binary_logloss: 0.0779011\tvalid_1's auc: 0.787837\tvalid_1's binary_logloss: 0.0793417\n",
      "[133]\ttraining's auc: 0.82465\ttraining's binary_logloss: 0.0778964\tvalid_1's auc: 0.787811\tvalid_1's binary_logloss: 0.0793358\n",
      "[134]\ttraining's auc: 0.824743\ttraining's binary_logloss: 0.0778911\tvalid_1's auc: 0.787731\tvalid_1's binary_logloss: 0.0793395\n",
      "[135]\ttraining's auc: 0.824718\ttraining's binary_logloss: 0.0778892\tvalid_1's auc: 0.787747\tvalid_1's binary_logloss: 0.0793383\n",
      "[136]\ttraining's auc: 0.824783\ttraining's binary_logloss: 0.0778814\tvalid_1's auc: 0.787817\tvalid_1's binary_logloss: 0.0793307\n",
      "[137]\ttraining's auc: 0.824804\ttraining's binary_logloss: 0.0778775\tvalid_1's auc: 0.787979\tvalid_1's binary_logloss: 0.0793249\n",
      "[138]\ttraining's auc: 0.824815\ttraining's binary_logloss: 0.077874\tvalid_1's auc: 0.788014\tvalid_1's binary_logloss: 0.0793225\n",
      "[139]\ttraining's auc: 0.824817\ttraining's binary_logloss: 0.0778708\tvalid_1's auc: 0.78814\tvalid_1's binary_logloss: 0.0793217\n",
      "[140]\ttraining's auc: 0.824826\ttraining's binary_logloss: 0.0778678\tvalid_1's auc: 0.788283\tvalid_1's binary_logloss: 0.0793126\n",
      "[141]\ttraining's auc: 0.824923\ttraining's binary_logloss: 0.0778593\tvalid_1's auc: 0.788352\tvalid_1's binary_logloss: 0.0793161\n",
      "[142]\ttraining's auc: 0.824937\ttraining's binary_logloss: 0.0778499\tvalid_1's auc: 0.788325\tvalid_1's binary_logloss: 0.0793155\n",
      "[143]\ttraining's auc: 0.825\ttraining's binary_logloss: 0.0778447\tvalid_1's auc: 0.788353\tvalid_1's binary_logloss: 0.0793174\n",
      "[144]\ttraining's auc: 0.825083\ttraining's binary_logloss: 0.0778386\tvalid_1's auc: 0.788273\tvalid_1's binary_logloss: 0.0793239\n",
      "[145]\ttraining's auc: 0.825079\ttraining's binary_logloss: 0.077832\tvalid_1's auc: 0.788178\tvalid_1's binary_logloss: 0.0793341\n",
      "[146]\ttraining's auc: 0.825109\ttraining's binary_logloss: 0.0778258\tvalid_1's auc: 0.788168\tvalid_1's binary_logloss: 0.0793398\n",
      "[147]\ttraining's auc: 0.825181\ttraining's binary_logloss: 0.0778186\tvalid_1's auc: 0.788136\tvalid_1's binary_logloss: 0.0793431\n",
      "[148]\ttraining's auc: 0.825174\ttraining's binary_logloss: 0.0778149\tvalid_1's auc: 0.78811\tvalid_1's binary_logloss: 0.0793459\n",
      "[149]\ttraining's auc: 0.825223\ttraining's binary_logloss: 0.0778096\tvalid_1's auc: 0.78808\tvalid_1's binary_logloss: 0.0793474\n",
      "[150]\ttraining's auc: 0.825264\ttraining's binary_logloss: 0.0778053\tvalid_1's auc: 0.788007\tvalid_1's binary_logloss: 0.0793433\n",
      "[151]\ttraining's auc: 0.825297\ttraining's binary_logloss: 0.0778016\tvalid_1's auc: 0.787972\tvalid_1's binary_logloss: 0.0793514\n",
      "[152]\ttraining's auc: 0.825337\ttraining's binary_logloss: 0.077791\tvalid_1's auc: 0.788006\tvalid_1's binary_logloss: 0.0793466\n",
      "[153]\ttraining's auc: 0.825371\ttraining's binary_logloss: 0.0777874\tvalid_1's auc: 0.78795\tvalid_1's binary_logloss: 0.0793444\n",
      "[154]\ttraining's auc: 0.825431\ttraining's binary_logloss: 0.0777818\tvalid_1's auc: 0.78792\tvalid_1's binary_logloss: 0.0793438\n",
      "[155]\ttraining's auc: 0.825485\ttraining's binary_logloss: 0.0777752\tvalid_1's auc: 0.787745\tvalid_1's binary_logloss: 0.0793478\n",
      "[156]\ttraining's auc: 0.825613\ttraining's binary_logloss: 0.0777633\tvalid_1's auc: 0.787789\tvalid_1's binary_logloss: 0.0793531\n",
      "[157]\ttraining's auc: 0.825672\ttraining's binary_logloss: 0.0777567\tvalid_1's auc: 0.787879\tvalid_1's binary_logloss: 0.0793447\n",
      "[158]\ttraining's auc: 0.825658\ttraining's binary_logloss: 0.0777484\tvalid_1's auc: 0.787878\tvalid_1's binary_logloss: 0.0793361\n",
      "[159]\ttraining's auc: 0.825685\ttraining's binary_logloss: 0.077729\tvalid_1's auc: 0.787963\tvalid_1's binary_logloss: 0.0793188\n",
      "[160]\ttraining's auc: 0.82572\ttraining's binary_logloss: 0.0777233\tvalid_1's auc: 0.788013\tvalid_1's binary_logloss: 0.0793237\n",
      "[161]\ttraining's auc: 0.825772\ttraining's binary_logloss: 0.0777168\tvalid_1's auc: 0.787858\tvalid_1's binary_logloss: 0.0793436\n",
      "[162]\ttraining's auc: 0.825782\ttraining's binary_logloss: 0.0777134\tvalid_1's auc: 0.787852\tvalid_1's binary_logloss: 0.0793385\n",
      "[163]\ttraining's auc: 0.825843\ttraining's binary_logloss: 0.0777054\tvalid_1's auc: 0.787826\tvalid_1's binary_logloss: 0.0793507\n",
      "[164]\ttraining's auc: 0.825888\ttraining's binary_logloss: 0.077703\tvalid_1's auc: 0.787791\tvalid_1's binary_logloss: 0.0793579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165]\ttraining's auc: 0.825964\ttraining's binary_logloss: 0.0776942\tvalid_1's auc: 0.787754\tvalid_1's binary_logloss: 0.0793678\n",
      "[166]\ttraining's auc: 0.825973\ttraining's binary_logloss: 0.0776913\tvalid_1's auc: 0.787863\tvalid_1's binary_logloss: 0.0793605\n",
      "[167]\ttraining's auc: 0.825993\ttraining's binary_logloss: 0.0776847\tvalid_1's auc: 0.787737\tvalid_1's binary_logloss: 0.0793614\n",
      "[168]\ttraining's auc: 0.826015\ttraining's binary_logloss: 0.0776824\tvalid_1's auc: 0.787725\tvalid_1's binary_logloss: 0.0793556\n",
      "[169]\ttraining's auc: 0.826101\ttraining's binary_logloss: 0.0776756\tvalid_1's auc: 0.787627\tvalid_1's binary_logloss: 0.0793684\n",
      "[170]\ttraining's auc: 0.826166\ttraining's binary_logloss: 0.0776707\tvalid_1's auc: 0.78755\tvalid_1's binary_logloss: 0.079367\n",
      "[171]\ttraining's auc: 0.826187\ttraining's binary_logloss: 0.0776678\tvalid_1's auc: 0.787563\tvalid_1's binary_logloss: 0.0793643\n",
      "[172]\ttraining's auc: 0.82625\ttraining's binary_logloss: 0.0776648\tvalid_1's auc: 0.787604\tvalid_1's binary_logloss: 0.0793723\n",
      "[173]\ttraining's auc: 0.826296\ttraining's binary_logloss: 0.0776628\tvalid_1's auc: 0.787565\tvalid_1's binary_logloss: 0.0793775\n",
      "[174]\ttraining's auc: 0.826317\ttraining's binary_logloss: 0.0776589\tvalid_1's auc: 0.787618\tvalid_1's binary_logloss: 0.0793724\n",
      "[175]\ttraining's auc: 0.826365\ttraining's binary_logloss: 0.0776509\tvalid_1's auc: 0.787598\tvalid_1's binary_logloss: 0.0793771\n",
      "[176]\ttraining's auc: 0.826413\ttraining's binary_logloss: 0.0776469\tvalid_1's auc: 0.787607\tvalid_1's binary_logloss: 0.0793783\n",
      "[177]\ttraining's auc: 0.826463\ttraining's binary_logloss: 0.077643\tvalid_1's auc: 0.787621\tvalid_1's binary_logloss: 0.0793848\n",
      "[178]\ttraining's auc: 0.826527\ttraining's binary_logloss: 0.077638\tvalid_1's auc: 0.787618\tvalid_1's binary_logloss: 0.0793778\n",
      "[179]\ttraining's auc: 0.826526\ttraining's binary_logloss: 0.0776327\tvalid_1's auc: 0.787583\tvalid_1's binary_logloss: 0.0793926\n",
      "[180]\ttraining's auc: 0.826577\ttraining's binary_logloss: 0.0776282\tvalid_1's auc: 0.787546\tvalid_1's binary_logloss: 0.0793975\n",
      "[181]\ttraining's auc: 0.826595\ttraining's binary_logloss: 0.0776268\tvalid_1's auc: 0.787523\tvalid_1's binary_logloss: 0.0794039\n",
      "[182]\ttraining's auc: 0.826589\ttraining's binary_logloss: 0.0776196\tvalid_1's auc: 0.787427\tvalid_1's binary_logloss: 0.0794095\n",
      "[183]\ttraining's auc: 0.826638\ttraining's binary_logloss: 0.0776147\tvalid_1's auc: 0.787523\tvalid_1's binary_logloss: 0.0794007\n",
      "[184]\ttraining's auc: 0.826679\ttraining's binary_logloss: 0.0776126\tvalid_1's auc: 0.787394\tvalid_1's binary_logloss: 0.0794048\n",
      "[185]\ttraining's auc: 0.826683\ttraining's binary_logloss: 0.0776099\tvalid_1's auc: 0.787474\tvalid_1's binary_logloss: 0.0793973\n",
      "[186]\ttraining's auc: 0.826754\ttraining's binary_logloss: 0.0776025\tvalid_1's auc: 0.787451\tvalid_1's binary_logloss: 0.0794022\n",
      "[187]\ttraining's auc: 0.826799\ttraining's binary_logloss: 0.0775942\tvalid_1's auc: 0.787448\tvalid_1's binary_logloss: 0.0793935\n",
      "[188]\ttraining's auc: 0.826839\ttraining's binary_logloss: 0.0775895\tvalid_1's auc: 0.787499\tvalid_1's binary_logloss: 0.0793901\n",
      "[189]\ttraining's auc: 0.826867\ttraining's binary_logloss: 0.0775812\tvalid_1's auc: 0.787523\tvalid_1's binary_logloss: 0.0793911\n",
      "[190]\ttraining's auc: 0.826921\ttraining's binary_logloss: 0.0775756\tvalid_1's auc: 0.787506\tvalid_1's binary_logloss: 0.0794006\n",
      "[191]\ttraining's auc: 0.826901\ttraining's binary_logloss: 0.0775739\tvalid_1's auc: 0.78748\tvalid_1's binary_logloss: 0.0794022\n",
      "[192]\ttraining's auc: 0.826885\ttraining's binary_logloss: 0.0775721\tvalid_1's auc: 0.787445\tvalid_1's binary_logloss: 0.079408\n",
      "[193]\ttraining's auc: 0.826881\ttraining's binary_logloss: 0.0775694\tvalid_1's auc: 0.787338\tvalid_1's binary_logloss: 0.0794196\n",
      "[194]\ttraining's auc: 0.826876\ttraining's binary_logloss: 0.0775676\tvalid_1's auc: 0.787348\tvalid_1's binary_logloss: 0.0794247\n",
      "[195]\ttraining's auc: 0.826929\ttraining's binary_logloss: 0.0775621\tvalid_1's auc: 0.787236\tvalid_1's binary_logloss: 0.0794231\n",
      "[196]\ttraining's auc: 0.826947\ttraining's binary_logloss: 0.0775562\tvalid_1's auc: 0.78716\tvalid_1's binary_logloss: 0.0794249\n",
      "[197]\ttraining's auc: 0.826999\ttraining's binary_logloss: 0.0775376\tvalid_1's auc: 0.787241\tvalid_1's binary_logloss: 0.0794024\n",
      "[198]\ttraining's auc: 0.827058\ttraining's binary_logloss: 0.0775312\tvalid_1's auc: 0.787194\tvalid_1's binary_logloss: 0.0793981\n",
      "[199]\ttraining's auc: 0.827082\ttraining's binary_logloss: 0.0775254\tvalid_1's auc: 0.787203\tvalid_1's binary_logloss: 0.0793966\n",
      "[200]\ttraining's auc: 0.827148\ttraining's binary_logloss: 0.0775217\tvalid_1's auc: 0.787103\tvalid_1's binary_logloss: 0.07941\n",
      "[201]\ttraining's auc: 0.827152\ttraining's binary_logloss: 0.0775103\tvalid_1's auc: 0.787117\tvalid_1's binary_logloss: 0.0794003\n",
      "[202]\ttraining's auc: 0.827211\ttraining's binary_logloss: 0.0775049\tvalid_1's auc: 0.787192\tvalid_1's binary_logloss: 0.079398\n",
      "[203]\ttraining's auc: 0.827235\ttraining's binary_logloss: 0.0774902\tvalid_1's auc: 0.787189\tvalid_1's binary_logloss: 0.0793946\n",
      "[204]\ttraining's auc: 0.827262\ttraining's binary_logloss: 0.0774884\tvalid_1's auc: 0.787147\tvalid_1's binary_logloss: 0.0793963\n",
      "[205]\ttraining's auc: 0.82726\ttraining's binary_logloss: 0.0774859\tvalid_1's auc: 0.787101\tvalid_1's binary_logloss: 0.0793955\n",
      "[206]\ttraining's auc: 0.827292\ttraining's binary_logloss: 0.0774814\tvalid_1's auc: 0.787137\tvalid_1's binary_logloss: 0.0793906\n",
      "[207]\ttraining's auc: 0.827343\ttraining's binary_logloss: 0.077478\tvalid_1's auc: 0.787076\tvalid_1's binary_logloss: 0.0794013\n",
      "[208]\ttraining's auc: 0.827343\ttraining's binary_logloss: 0.0774746\tvalid_1's auc: 0.787112\tvalid_1's binary_logloss: 0.079403\n",
      "[209]\ttraining's auc: 0.827353\ttraining's binary_logloss: 0.0774714\tvalid_1's auc: 0.787188\tvalid_1's binary_logloss: 0.0794005\n",
      "[210]\ttraining's auc: 0.827382\ttraining's binary_logloss: 0.0774693\tvalid_1's auc: 0.787162\tvalid_1's binary_logloss: 0.0793985\n",
      "[211]\ttraining's auc: 0.827402\ttraining's binary_logloss: 0.0774668\tvalid_1's auc: 0.787093\tvalid_1's binary_logloss: 0.0794024\n",
      "[212]\ttraining's auc: 0.827469\ttraining's binary_logloss: 0.0774593\tvalid_1's auc: 0.787151\tvalid_1's binary_logloss: 0.0793975\n",
      "[213]\ttraining's auc: 0.827511\ttraining's binary_logloss: 0.0774538\tvalid_1's auc: 0.787134\tvalid_1's binary_logloss: 0.0794059\n",
      "[214]\ttraining's auc: 0.827502\ttraining's binary_logloss: 0.0774496\tvalid_1's auc: 0.78686\tvalid_1's binary_logloss: 0.0794286\n",
      "[215]\ttraining's auc: 0.827518\ttraining's binary_logloss: 0.0774469\tvalid_1's auc: 0.786847\tvalid_1's binary_logloss: 0.0794253\n",
      "[216]\ttraining's auc: 0.827543\ttraining's binary_logloss: 0.0774427\tvalid_1's auc: 0.786826\tvalid_1's binary_logloss: 0.0794141\n",
      "[217]\ttraining's auc: 0.827547\ttraining's binary_logloss: 0.0774406\tvalid_1's auc: 0.786824\tvalid_1's binary_logloss: 0.0794049\n",
      "[218]\ttraining's auc: 0.827565\ttraining's binary_logloss: 0.0774358\tvalid_1's auc: 0.786819\tvalid_1's binary_logloss: 0.0794086\n",
      "[219]\ttraining's auc: 0.827579\ttraining's binary_logloss: 0.0774324\tvalid_1's auc: 0.786808\tvalid_1's binary_logloss: 0.0794215\n",
      "[220]\ttraining's auc: 0.827605\ttraining's binary_logloss: 0.0774282\tvalid_1's auc: 0.786917\tvalid_1's binary_logloss: 0.0794059\n",
      "[221]\ttraining's auc: 0.827655\ttraining's binary_logloss: 0.0774197\tvalid_1's auc: 0.786786\tvalid_1's binary_logloss: 0.0793997\n",
      "[222]\ttraining's auc: 0.827698\ttraining's binary_logloss: 0.0774184\tvalid_1's auc: 0.78679\tvalid_1's binary_logloss: 0.0793977\n",
      "[223]\ttraining's auc: 0.82771\ttraining's binary_logloss: 0.0774165\tvalid_1's auc: 0.786709\tvalid_1's binary_logloss: 0.0793992\n",
      "[224]\ttraining's auc: 0.827712\ttraining's binary_logloss: 0.077413\tvalid_1's auc: 0.786664\tvalid_1's binary_logloss: 0.0794038\n",
      "[225]\ttraining's auc: 0.827779\ttraining's binary_logloss: 0.0774083\tvalid_1's auc: 0.786625\tvalid_1's binary_logloss: 0.0794039\n",
      "[226]\ttraining's auc: 0.827795\ttraining's binary_logloss: 0.0774063\tvalid_1's auc: 0.786628\tvalid_1's binary_logloss: 0.0794098\n",
      "[227]\ttraining's auc: 0.827835\ttraining's binary_logloss: 0.0773923\tvalid_1's auc: 0.786697\tvalid_1's binary_logloss: 0.0793883\n",
      "[228]\ttraining's auc: 0.827842\ttraining's binary_logloss: 0.0773898\tvalid_1's auc: 0.786608\tvalid_1's binary_logloss: 0.0793921\n",
      "[229]\ttraining's auc: 0.827879\ttraining's binary_logloss: 0.0773825\tvalid_1's auc: 0.786525\tvalid_1's binary_logloss: 0.0793926\n",
      "[230]\ttraining's auc: 0.82795\ttraining's binary_logloss: 0.077377\tvalid_1's auc: 0.786513\tvalid_1's binary_logloss: 0.0794009\n",
      "[231]\ttraining's auc: 0.828009\ttraining's binary_logloss: 0.0773708\tvalid_1's auc: 0.786345\tvalid_1's binary_logloss: 0.0794141\n",
      "[232]\ttraining's auc: 0.828056\ttraining's binary_logloss: 0.0773597\tvalid_1's auc: 0.786291\tvalid_1's binary_logloss: 0.0794111\n",
      "[233]\ttraining's auc: 0.828098\ttraining's binary_logloss: 0.077354\tvalid_1's auc: 0.786204\tvalid_1's binary_logloss: 0.0794064\n",
      "[234]\ttraining's auc: 0.828128\ttraining's binary_logloss: 0.0773508\tvalid_1's auc: 0.786085\tvalid_1's binary_logloss: 0.0794093\n",
      "[235]\ttraining's auc: 0.82815\ttraining's binary_logloss: 0.0773497\tvalid_1's auc: 0.786007\tvalid_1's binary_logloss: 0.0794137\n",
      "[236]\ttraining's auc: 0.828221\ttraining's binary_logloss: 0.0773449\tvalid_1's auc: 0.785877\tvalid_1's binary_logloss: 0.0794173\n",
      "[237]\ttraining's auc: 0.828236\ttraining's binary_logloss: 0.0773401\tvalid_1's auc: 0.785818\tvalid_1's binary_logloss: 0.0794281\n",
      "[238]\ttraining's auc: 0.828256\ttraining's binary_logloss: 0.0773382\tvalid_1's auc: 0.785858\tvalid_1's binary_logloss: 0.0794186\n",
      "[239]\ttraining's auc: 0.828285\ttraining's binary_logloss: 0.0773344\tvalid_1's auc: 0.785886\tvalid_1's binary_logloss: 0.0794185\n",
      "[240]\ttraining's auc: 0.828326\ttraining's binary_logloss: 0.0773297\tvalid_1's auc: 0.785828\tvalid_1's binary_logloss: 0.0794238\n",
      "Early stopping, best iteration is:\n",
      "[140]\ttraining's auc: 0.824826\ttraining's binary_logloss: 0.0778678\tvalid_1's auc: 0.788283\tvalid_1's binary_logloss: 0.0793126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#定义lgb函数\n",
    "def LGB_test(train_x,train_y,test_x,test_y):\n",
    "    from multiprocessing import cpu_count\n",
    "    clf = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "        max_depth=2, n_estimators=800,max_features = 140, objective='binary',\n",
    "        subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "        learning_rate=0.05, min_child_weight=50,random_state=None,n_jobs=cpu_count()-1,\n",
    "        num_iterations = 800 #迭代次数\n",
    "    )\n",
    "    clf.fit(train_x, train_y,eval_set=[(train_x, train_y),(test_x,test_y)],eval_metric='auc',early_stopping_rounds=100)\n",
    "    print(clf.n_features_)\n",
    "\n",
    "    return clf,clf.best_score_[ 'valid_1']['auc']\n",
    "feature_lst = {}\n",
    "ks_train_lst = []\n",
    "ks_test_lst = []\n",
    "features = []\n",
    "for rk in set(df_train['rank']):   \n",
    "    # 1，2，3，4，5\n",
    "    # 测试集8.18以后作为跨时间验证集\n",
    "    \n",
    "    #定义模型训练集与测试集\n",
    "    ttest = df_train[df_train['rank'] ==  rk]\n",
    "    ttrain = df_train[df_train['rank'] !=  rk]\n",
    "    \n",
    "    train = ttrain[lst]\n",
    "    train_y = ttrain.bad_ind\n",
    "    \n",
    "    test = ttest[lst]\n",
    "    test_y = ttest.bad_ind    \n",
    "    \n",
    "#     start = time.time()\n",
    "    model,auc = LGB_test(train,train_y,test,test_y)                    \n",
    "#     end = time.time()\n",
    "    \n",
    "    #模型贡献度放在feture中\n",
    "    feature = pd.DataFrame(\n",
    "                {'name' : model.booster_.feature_name(),\n",
    "                'importance' : model.feature_importances_\n",
    "              }).sort_values(by =  ['importance'],ascending = False)\n",
    "    features.append(feature)\n",
    "       \n",
    "    #计算训练集、测试集、验证集上的KS和AUC\n",
    "\n",
    "    y_pred_train_lgb = model.predict_proba(train)[:, 1]\n",
    "    y_pred_test_lgb = model.predict_proba(test)[:, 1]\n",
    "\n",
    "\n",
    "    train_fpr_lgb, train_tpr_lgb, _ = roc_curve(train_y, y_pred_train_lgb)\n",
    "    test_fpr_lgb, test_tpr_lgb, _ = roc_curve(test_y, y_pred_test_lgb)\n",
    "\n",
    "\n",
    "    train_ks = abs(train_fpr_lgb - train_tpr_lgb).max()\n",
    "    test_ks = abs(test_fpr_lgb - test_tpr_lgb).max()\n",
    "\n",
    "\n",
    "    train_auc = metrics.auc(train_fpr_lgb, train_tpr_lgb)\n",
    "    test_auc = metrics.auc(test_fpr_lgb, test_tpr_lgb)\n",
    "    \n",
    "    ks_train_lst.append(train_ks)\n",
    "    ks_test_lst.append(test_ks)    \n",
    "\n",
    "    feature_lst[str(rk)] = feature[feature['importance']>=14].name\n",
    "    \n",
    "train_ks = np.mean(ks_train_lst)\n",
    "test_ks = np.mean(ks_test_lst)\n",
    "\n",
    "ft_lst = {}\n",
    "for i in range(1,6):\n",
    "    ft_lst[str(i)] = feature_lst[str(i)]\n",
    "\n",
    "fn_lst=list(set(ft_lst['1']) & set(ft_lst['2']) \n",
    "    & set(ft_lst['3']) & set(ft_lst['4']) &set(ft_lst['5']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48028374754092706,\n",
       " 0.4951138932575604,\n",
       " 0.4806196931036967,\n",
       " 0.4839672582496274,\n",
       " 0.5068215971230547]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_train_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4450312268117735,\n",
       " 0.45779658550738506,\n",
       " 0.49746716339890973,\n",
       " 0.5168472808602099,\n",
       " 0.4414946625587052]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_test_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4893612378549733"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   importance          name\n",
      "1          30  finance_info\n",
      "0          18   person_info\n",
      "2          18   credit_info\n",
      "3          14      act_info\n",
      "4           0      td_score\n",
      "5           0     jxl_score\n",
      "6           0      mj_score\n",
      "7           0      rh_score\n",
      "   importance          name\n",
      "1          73  finance_info\n",
      "0          57   person_info\n",
      "2          56   credit_info\n",
      "3          32      act_info\n",
      "6          32      mj_score\n",
      "5           6     jxl_score\n",
      "7           5      rh_score\n",
      "4           4      td_score\n",
      "   importance          name\n",
      "1          70  finance_info\n",
      "0          63   person_info\n",
      "2          52   credit_info\n",
      "3          33      act_info\n",
      "6          19      mj_score\n",
      "4           9      td_score\n",
      "5           8     jxl_score\n",
      "7           6      rh_score\n",
      "   importance          name\n",
      "1          82  finance_info\n",
      "0          72   person_info\n",
      "2          65   credit_info\n",
      "3          44      act_info\n",
      "6          38      mj_score\n",
      "4          21      td_score\n",
      "7          13      rh_score\n",
      "5          10     jxl_score\n",
      "   importance          name\n",
      "1          88  finance_info\n",
      "2          77   credit_info\n",
      "0          69   person_info\n",
      "3          43      act_info\n",
      "6          41      mj_score\n",
      "4          26      td_score\n",
      "7          18      rh_score\n",
      "5          15     jxl_score\n"
     ]
    }
   ],
   "source": [
    "for feats in features:\n",
    "    print(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    finance_info\n",
       "0     person_info\n",
       "2     credit_info\n",
       "3        act_info\n",
       "4        td_score\n",
       "6        mj_score\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0][feature.importance>=20].name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   importance          name\n",
       " 1          30  finance_info\n",
       " 0          18   person_info\n",
       " 2          18   credit_info\n",
       " 3          14      act_info\n",
       " 4           0      td_score\n",
       " 5           0     jxl_score\n",
       " 6           0      mj_score\n",
       " 7           0      rh_score,    importance          name\n",
       " 1          73  finance_info\n",
       " 0          57   person_info\n",
       " 2          56   credit_info\n",
       " 3          32      act_info\n",
       " 6          32      mj_score\n",
       " 5           6     jxl_score\n",
       " 7           5      rh_score\n",
       " 4           4      td_score,    importance          name\n",
       " 1          70  finance_info\n",
       " 0          63   person_info\n",
       " 2          52   credit_info\n",
       " 3          33      act_info\n",
       " 6          19      mj_score\n",
       " 4           9      td_score\n",
       " 5           8     jxl_score\n",
       " 7           6      rh_score,    importance          name\n",
       " 1          82  finance_info\n",
       " 0          72   person_info\n",
       " 2          65   credit_info\n",
       " 3          44      act_info\n",
       " 6          38      mj_score\n",
       " 4          21      td_score\n",
       " 7          13      rh_score\n",
       " 5          10     jxl_score,    importance          name\n",
       " 1          88  finance_info\n",
       " 2          77   credit_info\n",
       " 0          69   person_info\n",
       " 3          43      act_info\n",
       " 6          41      mj_score\n",
       " 4          26      td_score\n",
       " 7          18      rh_score\n",
       " 5          15     jxl_score]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon = pd.read_csv('coupon.csv',index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>default</th>\n",
       "      <th>returned</th>\n",
       "      <th>loan</th>\n",
       "      <th>coupon_used_in_last6_month</th>\n",
       "      <th>coupon_used_in_last_month</th>\n",
       "      <th>coupon_ind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>technician</td>\n",
       "      <td>divorced</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age         job   marital default returned loan  \\\n",
       "ID                                                    \n",
       "1    43  management   married      no      yes   no   \n",
       "2    42  technician  divorced      no      yes   no   \n",
       "3    47      admin.   married      no      yes  yes   \n",
       "4    28  management    single      no      yes  yes   \n",
       "5    42  technician  divorced      no      yes   no   \n",
       "\n",
       "    coupon_used_in_last6_month  coupon_used_in_last_month  coupon_ind  \n",
       "ID                                                                     \n",
       "1                            2                          0           0  \n",
       "2                            1                          1           0  \n",
       "3                            2                          0           0  \n",
       "4                            2                          0           0  \n",
       "5                            5                          0           0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>coupon_used_in_last6_month</th>\n",
       "      <th>coupon_used_in_last_month</th>\n",
       "      <th>coupon_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25317.000000</td>\n",
       "      <td>25317.000000</td>\n",
       "      <td>25317.000000</td>\n",
       "      <td>25317.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.935379</td>\n",
       "      <td>2.772050</td>\n",
       "      <td>0.292847</td>\n",
       "      <td>0.116957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.634289</td>\n",
       "      <td>3.136097</td>\n",
       "      <td>0.765498</td>\n",
       "      <td>0.321375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  coupon_used_in_last6_month  coupon_used_in_last_month  \\\n",
       "count  25317.000000                25317.000000               25317.000000   \n",
       "mean      40.935379                    2.772050                   0.292847   \n",
       "std       10.634289                    3.136097                   0.765498   \n",
       "min       18.000000                    1.000000                   0.000000   \n",
       "25%       33.000000                    1.000000                   0.000000   \n",
       "50%       39.000000                    2.000000                   0.000000   \n",
       "75%       48.000000                    3.000000                   0.000000   \n",
       "max       95.000000                   55.000000                  15.000000   \n",
       "\n",
       "         coupon_ind  \n",
       "count  25317.000000  \n",
       "mean       0.116957  \n",
       "std        0.321375  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupon.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coupon_used_in_last6_month\n",
       "1     9825\n",
       "2     7009\n",
       "3     3098\n",
       "4     1957\n",
       "5      989\n",
       "6      723\n",
       "7      406\n",
       "8      302\n",
       "9      183\n",
       "10     150\n",
       "11     111\n",
       "12      82\n",
       "13      62\n",
       "14      50\n",
       "15      44\n",
       "16      52\n",
       "17      49\n",
       "18      30\n",
       "19      26\n",
       "20      23\n",
       "21      21\n",
       "22      12\n",
       "23      17\n",
       "24      10\n",
       "25      12\n",
       "26       8\n",
       "27       7\n",
       "28       7\n",
       "29      12\n",
       "30       4\n",
       "31       8\n",
       "32       7\n",
       "33       3\n",
       "34       4\n",
       "35       1\n",
       "36       4\n",
       "37       1\n",
       "41       1\n",
       "43       2\n",
       "44       1\n",
       "50       2\n",
       "51       1\n",
       "55       1\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupon.groupby(['coupon_used_in_last6_month'])['job'].count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
