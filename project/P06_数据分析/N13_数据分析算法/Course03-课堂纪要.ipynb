{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 异常检测问题总结\n",
    "\n",
    "- 对数据没有太多业务认识情况下，要找到异常数据，通常就可以使用异常检测算法\n",
    "- IsolationForest 在异常检测的问题中，使用频率比较高\n",
    "  - 对数据要求比较低（不需要做离散化，不需要数值标准化，不需要考虑特征间的关系（例如共线性）等，不需要额外做特征过滤和筛选）\n",
    "- IsolationForest  对异常点做初步的判断，在结果之上进一步分析规则\n",
    "- 异常检测问题，在线上实时监测都会落到规则上\n",
    "\n",
    "- 要求：\n",
    "  - 知道使用的场景 对数据没有太多业务认识情况下，要找到异常数据，通常就可以使用异常检测算法\n",
    "  - 记住用什么算法  IsolationForest  one-class SVM LOF\n",
    "  - 记住算法的原理\n",
    "    - 孤立森林算法通过对样本点的孤立来检测异常值\n",
    "      - 该算法利用一种名为孤立树iTree的二叉搜索树结构来孤立样本\n",
    "      - 异常值的数量较少且与大部分样本的特征不同\n",
    "      - 异常值会被更早的孤立出来，也即异常值会距离![iTree](https://math.jianshu.com/math?formula=iTree)的根节点更近，而正常值则会距离根节点有更远的距离\n",
    "      - 相较于LOF，K-means等传统算法，孤立森林算法对高纬数据有较好的鲁棒性。\n",
    "    - 假设数据集有N条数据，构建一颗iTree时，从N条数据中均匀抽样(一般是无放回抽样)出ψ个样本出来，作为这颗树的训练样本。在样本中，随机选一个特征，并在这个特征的所有值范围内(最小值与最大值之间)随机选一个值，对样本进行二叉划分，将样本中小于该值的划分到节点的左边，大于等于该值的划分到节点的右边。由此得到一个分裂条件和左、右两边的数据集，然后分别在左右两边的数据集上重复上面的过程，直到数据集只有一条记录或者达到了树的限定高度\n",
    "\n",
    "####  对中文文本的处理\n",
    "\n",
    "- jieba  中文自然语言处理工具包\n",
    "\n",
    "  - 分词  jieba.cut\n",
    "  - 分词 得到词性  import jieba.posseg as pseg\n",
    "    - pair(分词结果,词性) = pseg.cut(string_data)\n",
    "  - 分词 计算权重\n",
    "    - jieba.analyse.extract_tags(数据，topK=取出权重最高的前K个词，withWeight=是否显示权重，allowPOS=分词之后会保留的词性 ，withFlag=结果是否显示词性）\n",
    "\n",
    "- wordcloud 词云\n",
    "\n",
    "  ```python\n",
    "  mask = np.array(Image.open('wordcloud.jpg'))  # 定义词频背景\n",
    "  wc = wordcloud.WordCloud(\n",
    "      font_path='C:/Windows/Fonts/simhei.ttf',  # 设置字体格式，不设置将无法显示中文\n",
    "      mask=mask,  # 设置背景图\n",
    "      max_words=200,  # 设置最大显示的词数\n",
    "      max_font_size=100,  # 设置字体最大值\n",
    "     \n",
    "  )\n",
    "  wc.generate_from_frequencies(word_counts)  # 从字典生成词云\n",
    "  image_colors = wordcloud.ImageColorGenerator(mask)  # 从背景图建立颜色方案\n",
    "  wc.recolor(color_func=image_colors)  # 将词云颜色设置为背景图方案\n",
    "  plt.imshow(wc)  # 显示词云\n",
    "  plt.axis('off')  # 关闭坐标轴\n",
    "  ```\n",
    "\n",
    "  \n",
    "\n",
    "- 金融风控相关业务\n",
    "  - 流程 \n",
    "    - 数据采集 反欺诈 策略 风控模型 催收\n",
    "  - 数据采集\n",
    "    - 会和其它机构合作，购买数据（同盾）\n",
    "    - 人民银行征信报告\n",
    "  - 反欺诈 策略\n",
    "    - 识别骗钱的用户\n",
    "    - 主要还是策略 算法的效果不佳，样本太少，获取样本的代价太高\n",
    "  - 风控模型\n",
    "    - ABC评分卡\n",
    "    - 贷前  申请评分卡 Application score card    A卡可以用客户历史逾期天数最大的天数\n",
    "    - 贷中  行为评分卡 Behavior score card       B卡则可以多期借款中逾期最大的一次\n",
    "    - 贷后   催收评分卡  Collection score card   C卡 是否被内催催回来定义y\n",
    "  - 催收\n",
    "    - 催收是风控的最终手段。这个环节可以产生很多对模型有帮助的数据。比如催收记录的文字描述、触达率、欺诈标签等等。\n",
    "\n",
    "### 特征处理\n",
    "\n",
    "- 反欺诈规则数据来源\n",
    "  - 个人基本特征\n",
    "  - 设备特征\n",
    "  - 文本信息\n",
    "  - 三方数据\n",
    "- 验证是否存在一批用户在上述这些规则中有多条相似的情况，相似的规则越多 这一批用户是欺诈的可能性就越大\n",
    "\n",
    "### 特征工程_特征选择\n",
    "\n",
    "- Filter  过滤 过滤掉无关（和目标关系不大的）特征\n",
    "\n",
    "  - 移除低方差的特征\n",
    "\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "    - VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "    - 传入的参数 方差阈值 每一列都会计算一个方差 如果方差低于这个阈值，这一列就会被删掉\n",
    "\n",
    "  - 验证特征和目标之间是否有关联\n",
    "\n",
    "    - 卡方检验\n",
    "\n",
    "      ```python\n",
    "      from sklearn.feature_selection import SelectKBest\n",
    "      from sklearn.feature_selection import chi2\n",
    "      #chi2 代表使用卡方检验 去找最合适的值\n",
    "      # k = 2 找两个最合适的特征\n",
    "      X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "      X_new.shape\n",
    "      ```\n",
    "\n",
    "      \n",
    "\n",
    "    - 皮尔逊相关系数\n",
    "\n",
    "- Wrapper  \n",
    "\n",
    "  - RFE  递归特征消除\n",
    "\n",
    "    - 指定一个模型，利用数据丢到模型中，找到权重最小的特征（最不重要的），每训练一轮删除一个特征，用剩下的继续训练（递归），一直到达到指定的特征个数为止\n",
    "    - from sklearn.feature_selection import RFE\n",
    "\n",
    "    ```python\n",
    "    from sklearn.feature_selection import RFE\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.datasets import load_iris\n",
    "    \n",
    "    # 使用随机森林最为递归特征筛选的模型\n",
    "    rf = RandomForestClassifier()\n",
    "    iris=load_iris()\n",
    "    X,y=iris.data,iris.target\n",
    "    # 创建RFE对象，传入RFE过程中要使用的模型对象，\n",
    "    #n_features_to_select 最终要选几个特征（剩下几个）\n",
    "    rfe = RFE(estimator=rf, n_features_to_select=2)\n",
    "    X_rfe = rfe.fit_transform(X,y)\n",
    "    ```\n",
    "\n",
    "- embeded\n",
    "\n",
    "  ```python\n",
    "  from sklearn.feature_selection import SelectFromModel\n",
    "  from sklearn.svm import LinearSVC\n",
    "  lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X,y)\n",
    "  model = SelectFromModel(lsvc, prefit=True)\n",
    "  X_embed = model.transform(X)\n",
    "  X_embed.shape\n",
    "  ```\n",
    "\n",
    "### 特征工程\n",
    "\n",
    "- 基础特征构造\n",
    "- 数据预处理\n",
    "  - 数据清洗\n",
    "  - 分类\n",
    "    - one-hot\n",
    "  - 数值\n",
    "    - 离散化 分箱       年龄\n",
    "    - 归一化 标准化    销售数值\n",
    "  - 样本分布是否均衡\n",
    "- 特征衍生\n",
    "  - \n",
    "- 特征筛选\n",
    "  - filter  特征过滤\n",
    "    - 低方差\n",
    "    - 相关性\n",
    "      - 卡方\n",
    "      - 皮尔逊 \n",
    "  - wrapper   RFE 把数据代入到模型中，递归去除无效特征，一次去除一个\n",
    "  - embeded  嵌入到模型中，让模型直接选出有效的\n",
    "\n",
    "### 如何选择套路\n",
    "\n",
    "- 特征重要性（变量必须对模型有贡献，也就是说必须能对客群加以区分）\n",
    "- 共线性 （逻辑回归要求变量之间线性无关）\n",
    "- bivar图 （逻辑回归评分卡也希望变量呈现单调趋势）\n",
    "- 稳定性（PSI） （客群在每个变量上的分布稳定，分布迁移无可避免，但不能波动太大）\n",
    "- **稳定性 和单调性 结合自己的业务考虑**\n",
    "\n",
    "### PSI\n",
    "\n",
    "- 训练一个模型 预测每一个样本最终的bad_rate\n",
    "  - 1000个样本    0.4 ~0.9   针对预测的结果 分成5份\n",
    "    - 0.4~0.5     200          180\n",
    "    - 0.5~0.6      200          180\n",
    "    - 0.6~0.7      200          180\n",
    "    - 0.7~0.8      200          180\n",
    "    - 0.8~0.9     200         180\n",
    "  - 1000个测试数据 代入到同一个模型\n",
    "\n",
    "#### 特征衍生\n",
    "\n",
    "- 利用数值型的变量，根据用户ID去分组\n",
    "\n",
    "  - 分组之后计算每一个变量在当前用户的统计信息\n",
    "\n",
    "    - 平均值\n",
    "\n",
    "    - 方差/标准差\n",
    "\n",
    "    - 最大值\n",
    "\n",
    "    - 最小值\n",
    "\n",
    "    - 条目数量\n",
    "\n",
    "    - 极差（最大值-最小值）\n",
    "\n",
    "    - 计算的时候 可以使用np.nanmin  np.nanmax \n",
    "\n",
    "      - np.nan*** 对缺失值不敏感\n",
    "\n",
    "      \n",
    "\n",
    "### 合规风控业务\n",
    "\n",
    "坏账率不能高于5%\n",
    "\n",
    "需要记住的\n",
    "\n",
    "- 风控业务流程\n",
    "  - 数据采集（爬虫，装了应用之后手机上的数据，买的三方数据，企业内部数据（企业内部其它应用的数据))\n",
    "  -  反欺诈 主要是策略做反欺诈\n",
    "  -  策略 \n",
    "  -  风控模型\n",
    "    - A  贷前  有可能是从合作方买的 买的数据有有效期\n",
    "    - B  贷中   利用现有数据\n",
    "    - C  催收  \n",
    "  -  催收\n",
    "- 特征工程（相关的流程）\n",
    "  - 数据处理\n",
    "    - 数据清洗 重复值，异常值，缺失值\n",
    "    - 分类/数值\n",
    "    - 目标值分类问题\n",
    "      - 样本不均衡的情况\n",
    "      - 过采样 欠采样\n",
    "      - LR 添加权重系数\n",
    "  - 特征衍生\n",
    "    - 数值类型的特征\n",
    "      - 根据用户分组，计算用户在当前特征下，一共有多少条数，所有数据放到一起可以算\n",
    "        - 平均 方差 最大 最小 极差 条目数量\n",
    "    - 分类的特征\n",
    "      - 根据用户分组，计算用户在当前特征下，一共产生了不同取值的情况（有几类记录）\n",
    "    - 时间序列型\n",
    "      - 连续3个月有消费，连续6个月有消费\n",
    "      - 连续3个月有逾期，连续6个有逾期\n",
    "  - 特征筛选（特征选择）\n",
    "    - filter\n",
    "      - 删除低方差特征\n",
    "      - 卡方检验\n",
    "      - 皮尔逊相关系数\n",
    "    - wrapper\n",
    "      - RFE  递归剃除不重要特征\n",
    "        - 把数据丢到模型中，计算特征权重，每一次去掉最不重要的一个\n",
    "    - embeded\n",
    "      - 把数据丢到模型里，看权重，一般用L1正则，不重要的特征直接为0 剩下的就是重要的\n",
    "\n",
    "- IsolationForest  孤立森林\n",
    "  - 记住算法的原理\n",
    "    - 孤立森林算法通过对样本点的孤立来检测异常值\n",
    "      - 该算法利用一种名为孤立树iTree的二叉搜索树结构来孤立样本\n",
    "      - 异常值的数量较少且与大部分样本的特征不同\n",
    "      - 异常值会被更早的孤立出来，也即异常值会距离![iTree](https://math.jianshu.com/math?formula=iTree)的根节点更近，而正常值则会距离根节点有更远的距离\n",
    "      - 相较于LOF，K-means等传统算法，孤立森林算法对高纬数据有较好的鲁棒性。\n",
    "    - 假设数据集有N条数据，构建一颗iTree时，从N条数据中均匀抽样(一般是无放回抽样)出ψ个样本出来，作为这颗树的训练样本。在样本中，随机选一个特征，并在这个特征的所有值范围内(最小值与最大值之间)随机选一个值，对样本进行二叉划分，将样本中小于该值的划分到节点的左边，大于等于该值的划分到节点的右边。由此得到一个分裂条件和左、右两边的数据集，然后分别在左右两边的数据集上重复上面的过程，直到数据集只有一条记录或者达到了树的限定高度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
