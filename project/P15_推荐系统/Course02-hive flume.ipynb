{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hive\n",
    "\n",
    "```\n",
    "将结构化数据映射为一张数据库表\n",
    "结构化数据：\"规整的数据\"，类似于mysql的二维表\n",
    "提供HQL(类似于SQL)查询功能\n",
    "底层数据是存储在 HDFS\n",
    "将SQL语句转换为MapReduce任务运行\n",
    "\n",
    "元数据存储在mysql中\n",
    "\n",
    "hive和mysql的对比\n",
    "hive：\n",
    "只支持插入操作\n",
    "执行延迟高\n",
    "不支持事务\n",
    "处理数据规模大\n",
    "可扩展性强\n",
    "\n",
    "数据类型：\n",
    "简单数据类型：大部分和mysql类似\n",
    "复杂数据类型：array，map，struct\n",
    "\n",
    "表类型：内部表和外部表\n",
    "\n",
    "hive没有专门的数据存储格式\n",
    "在创建表时指定数据中的分隔符\n",
    "数据模型：\n",
    "db：在 hdfs 中表现为 hive.metastore.warehouse.dir(默认为：hdfs:///user/hive/warehourse/*.db) 目录下一个文件夹\n",
    "table：在 hdfs 中表现所属 db 目录下一个文件夹\n",
    "partition(分区)：在 hdfs 中表现为 table 目录下的子目录\n",
    "\n",
    "hive的启动流程：\n",
    "1，启动hdfs\n",
    "2，启动yarn\n",
    "3，启动docker\n",
    "4，启动mysql\n",
    "5，启动hive的元数据服务\n",
    "    hive --service metastore&\n",
    "6，启动hive\n",
    "\n",
    "内部表和外部表：\n",
    "数据管理情况\n",
    "删除元数据是否连带删除数据\n",
    "数据存放位置\n",
    "\n",
    "```\n",
    "\n",
    "### flume：日志收集工具\n",
    "\n",
    "```\n",
    "使用版本：flume-ng\n",
    "\n",
    "三个基本结构：\n",
    "source：从哪里拿数据(数据源)\n",
    "channel：临时的缓存\n",
    "sink：放到哪里去(数据放置位置)\n",
    "\n",
    "外部结构：agent\n",
    "一个agent包含三部分：source、channel、sink\n",
    "\n",
    "flume数据传输的基本单元：event\n",
    "event(byte array)由两部分组成\n",
    "event header：\n",
    "event body：\n",
    "收集文本文件，一个event代表一行数据\n",
    "\n",
    "#定义agent及其三个子组件的名字\n",
    "#agent的名字是：a1\n",
    "#agent的source是r1\n",
    "#agent的channel：c1\n",
    "#agent的sink：k1\n",
    "a1.sources = r1\n",
    "a1.sinks = k1\n",
    "a1.channels = c1\n",
    "\n",
    "#对agent的source进行详细配置\n",
    "a1.sources.r1.type = netcat\n",
    "a1.sources.r1.bind = 192.168.19.137\n",
    "a1.sources.r1.port = 44444\n",
    "\n",
    "#对agent的sink进行详细配置\n",
    "a1.sinks.k1.type = logger\n",
    "\n",
    "#对agent的channel进行详细配置\n",
    "a1.channels.c1.type = memory\n",
    "a1.channels.c1.capacity = 1000\n",
    "a1.channels.c1.transactionCapacity = 100\n",
    "\n",
    "#配置source和channel的关系及其sink和channel的关系\n",
    "a1.sources.r1.channels = c1\n",
    "a1.sinks.k1.channel = c1\n",
    "\n",
    "netcat_memory_logger\n",
    "\n",
    "启动flume：/root/bigdata/flume/bin/flume-ng agent -n a1 -f test.conf\n",
    "\n",
    "作业：\n",
    "从A服务器采集日志文件access.log、nginx.log到C服务器，\n",
    "从B服务器采集目录中新增的文件到C服务器，\n",
    "C服务器的数据最终存储到hdfs。\n",
    "要求：从access.log中获取的数据最终存储到hdfs的access目录中，从nginx.log中获取的数据最终存储到hdfs的nginx目录中，从B服务器中目录采集的数据最终存储到hdfs的spool目录中\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with\n",
    "tmp_detail as\n",
    "(\n",
    "    select\n",
    "        user_id,\n",
    "        sku_id, \n",
    "        sum(sku_num) sku_num,   \n",
    "        count(*) order_count, \n",
    "        sum(od.order_price*sku_num) order_amount\n",
    "    from dwd_order_detail od\n",
    "    where od.dt='2019-02-11'\n",
    "    group by user_id, sku_id\n",
    ")  \n",
    "\n",
    "insert overwrite table dws_sale_detail_daycount partition(dt='2019-02-11')\n",
    "\n",
    "select \n",
    "    tmp_detail.user_id,\n",
    "    tmp_detail.sku_id,\n",
    "    u.gender,\n",
    "    months_between('2019-02-11', u.birthday)/12  age, \n",
    "    u.user_level,\n",
    "    price,\n",
    "    sku_name,\n",
    "    tm_id,\n",
    "    category3_id,\n",
    "    category2_id,\n",
    "    category1_id,\n",
    "    category3_name,\n",
    "    category2_name,\n",
    "    category1_name,\n",
    "    spu_id,\n",
    "    tmp_detail.sku_num,\n",
    "    tmp_detail.order_count,\n",
    "    tmp_detail.order_amount \n",
    "from tmp_detail \n",
    "left join dwd_user_info u on tmp_detail.user_id =u.id and u.dt='2019-02-11'\n",
    "left join dwd_sku_info s on tmp_detail.sku_id =s.id and s.dt='2019-02-11'\n",
    ";\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "export JAVA_HOME=/root/bigdata/jdk\n",
    "export HBASE_MANAGES_ZK=true  --如果你是使用hbase自带的zk就是true，如果使用自己的zk就是false\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
